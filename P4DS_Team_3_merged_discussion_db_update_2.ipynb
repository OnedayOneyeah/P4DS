{"cells":[{"cell_type":"markdown","metadata":{"id":"2XcZntNVzV6d"},"source":["# Install Requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"GUOI6T78XQeI","executionInfo":{"status":"ok","timestamp":1748419074780,"user_tz":-540,"elapsed":177843,"user":{"displayName":"박형진","userId":"05628816051884963880"}},"outputId":"73e9a3a3-e732-4c48-813c-4c65676dbb9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: codeinterpreterapi[all] in /usr/local/lib/python3.11/dist-packages (0.1.20)\n","Requirement already satisfied: codeboxapi==0.1.19 in /usr/local/lib/python3.11/dist-packages (from codeinterpreterapi[all]) (0.1.19)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (from codeinterpreterapi[all]) (0.1.7)\n","Requirement already satisfied: langchain<0.2,>=0.1 in /usr/local/lib/python3.11/dist-packages (from codeinterpreterapi[all]) (0.1.20)\n","Requirement already satisfied: pyzmq==25.1.2 in /usr/local/lib/python3.11/dist-packages (from codeinterpreterapi[all]) (25.1.2)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (from codeinterpreterapi[all]) (1.45.1)\n","Requirement already satisfied: aiohttp>=3.9 in /usr/local/lib/python3.11/dist-packages (from codeboxapi==0.1.19->codeinterpreterapi[all]) (3.11.15)\n","Requirement already satisfied: pydantic-settings>=2 in /usr/local/lib/python3.11/dist-packages (from codeboxapi==0.1.19->codeinterpreterapi[all]) (2.9.1)\n","Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from codeboxapi==0.1.19->codeinterpreterapi[all]) (2.11.4)\n","Requirement already satisfied: requests>=2 in /usr/local/lib/python3.11/dist-packages (from codeboxapi==0.1.19->codeinterpreterapi[all]) (2.32.3)\n","Requirement already satisfied: websockets>=12 in /usr/local/lib/python3.11/dist-packages (from codeboxapi==0.1.19->codeinterpreterapi[all]) (15.0.1)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (2.0.41)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (0.6.7)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (0.0.38)\n","Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (0.1.53)\n","Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (0.0.2)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (0.1.147)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (1.26.4)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi[all]) (8.5.0)\n","Requirement already satisfied: jupyter-kernel-gateway<3,>=2.5 in /usr/local/lib/python3.11/dist-packages (from codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (2.5.2)\n","Requirement already satisfied: pillow>=10 in /usr/local/lib/python3.11/dist-packages (from codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (11.2.1)\n","Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->codeinterpreterapi[all]) (1.81.0)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->codeinterpreterapi[all]) (0.9.0)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (8.2.1)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (23.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (2.2.2)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (5.29.4)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (18.1.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (4.13.2)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (3.1.44)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->codeinterpreterapi[all]) (6.4.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi[all]) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi[all]) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi[all]) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi[all]) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi[all]) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi[all]) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi[all]) (1.20.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->codeinterpreterapi[all]) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->codeinterpreterapi[all]) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->codeinterpreterapi[all]) (1.40.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->codeinterpreterapi[all]) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->codeinterpreterapi[all]) (0.9.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->codeinterpreterapi[all]) (4.0.12)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (5.7.2)\n","Requirement already satisfied: jupyter-client<8.0,>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (6.1.12)\n","Requirement already satisfied: notebook<7.0,>=5.7.6 in /usr/local/lib/python3.11/dist-packages (from jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (6.5.7)\n","Requirement already satisfied: traitlets>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (5.7.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2,>=0.1->codeinterpreterapi[all]) (1.33)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi[all]) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi[all]) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi[all]) (1.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi[all]) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi[all]) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi[all]) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi[all]) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi[all]) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->codeinterpreterapi[all]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->codeinterpreterapi[all]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->codeinterpreterapi[all]) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->codeboxapi==0.1.19->codeinterpreterapi[all]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->codeboxapi==0.1.19->codeinterpreterapi[all]) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->codeboxapi==0.1.19->codeinterpreterapi[all]) (0.4.1)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings>=2->codeboxapi==0.1.19->codeinterpreterapi[all]) (1.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2->codeboxapi==0.1.19->codeinterpreterapi[all]) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2->codeboxapi==0.1.19->codeinterpreterapi[all]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2->codeboxapi==0.1.19->codeinterpreterapi[all]) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2->codeboxapi==0.1.19->codeinterpreterapi[all]) (2025.4.26)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2,>=0.1->codeinterpreterapi[all]) (3.2.2)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai->codeinterpreterapi[all]) (2024.11.6)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->codeinterpreterapi[all]) (5.0.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi[all]) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi[all]) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit->codeinterpreterapi[all]) (3.0.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2,>=0.1->codeinterpreterapi[all]) (3.0.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->codeinterpreterapi[all]) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->codeinterpreterapi[all]) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->codeinterpreterapi[all]) (0.25.1)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.4.0->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (4.3.8)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (23.1.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.2.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (7.16.6)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.6.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (6.17.1)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.22.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit->codeinterpreterapi[all]) (1.17.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->codeinterpreterapi[all]) (1.1.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (4.13.4)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (3.1.3)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.10.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.5.1)\n","Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (2.19.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (2.21.1)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.7.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (21.2.0)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.8.0)\n","Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (7.34.0)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.1.7)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (5.9.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.4.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (75.2.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (3.0.51)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (4.9.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.16.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (2.7)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (2.22)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.8.4)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (1.8.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->notebook<7.0,>=5.7.6->jupyter-kernel-gateway<3,>=2.5->codeboxapi[all]; extra == \"all\"->codeinterpreterapi[all]) (0.2.13)\n","Collecting chromadb\n","  Using cached chromadb-1.0.11-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.4)\n","Collecting fastapi==0.115.9 (from chromadb)\n","  Using cached fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n","Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n","Collecting posthog>=2.4.0 (from chromadb)\n","  Using cached posthog-4.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n","Collecting onnxruntime>=1.14.1 (from chromadb)\n","  Using cached onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb)\n","  Using cached opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n","  Using cached opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n","  Using cached opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n","  Using cached opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n","Collecting pypika>=0.48.9 (from chromadb)\n","  Using cached PyPika-0.48.9.tar.gz (67 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n","Collecting overrides>=7.3.1 (from chromadb)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n","Collecting mmh3>=4.0.1 (from chromadb)\n","  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n","Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n","Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n","  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (23.2)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n","  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n","Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n","  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n","Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n","  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n","Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.31.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n","Downloading chromadb-1.0.11-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n","Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n","Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n","Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-4.2.0-py2.py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n","Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n","Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n","Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=905547ef927aff2e48816295299627bab73fae4213fd3ee08607c09e7580f9e9\n","  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n","Successfully built pypika\n","Installing collected packages: pypika, durationpy, uvloop, uvicorn, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, importlib-metadata, humanfriendly, httptools, deprecated, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 8.7.0\n","    Uninstalling importlib_metadata-8.7.0:\n","      Successfully uninstalled importlib_metadata-8.7.0\n","Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.11 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.10 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.6.1 kubernetes-32.0.1 mmh3-5.1.0 onnxruntime-1.22.0 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 overrides-7.7.0 posthog-4.2.0 pypika-0.48.9 starlette-0.45.3 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["importlib_metadata"]},"id":"50ab91286aef479f97fb9d7a950440b5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n","Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed PyPDF2-3.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.0.38)\n","Collecting langchain-community\n","  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n","Collecting langchain-core<1.0.0,>=0.3.59 (from langchain-community)\n","  Downloading langchain_core-0.3.62-py3-none-any.whl.metadata (5.8 kB)\n","Collecting langchain<1.0.0,>=0.3.25 (from langchain-community)\n","  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.1.147)\n","Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.25->langchain-community)\n","  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (23.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n","Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.62-py3-none-any.whl (438 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.4/438.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n","Installing collected packages: httpx-sse, langchain-core, langchain-text-splitters, langchain, langchain-community\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.1.53\n","    Uninstalling langchain-core-0.1.53:\n","      Successfully uninstalled langchain-core-0.1.53\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.0.2\n","    Uninstalling langchain-text-splitters-0.0.2:\n","      Successfully uninstalled langchain-text-splitters-0.0.2\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.1.20\n","    Uninstalling langchain-0.1.20:\n","      Successfully uninstalled langchain-0.1.20\n","  Attempting uninstall: langchain-community\n","    Found existing installation: langchain-community 0.0.38\n","    Uninstalling langchain-community-0.0.38:\n","      Successfully uninstalled langchain-community-0.0.38\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","codeinterpreterapi 0.1.20 requires langchain<0.2,>=0.1, but you have langchain 0.3.25 which is incompatible.\n","langchain-openai 0.1.7 requires langchain-core<0.3,>=0.1.46, but you have langchain-core 0.3.62 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed httpx-sse-0.4.0 langchain-0.3.25 langchain-community-0.3.24 langchain-core-0.3.62 langchain-text-splitters-0.3.8\n","Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.62)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.147)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (23.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n","Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.11.0\n","Collecting pypdf\n","  Using cached pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n","Using cached pypdf-5.5.0-py3-none-any.whl (303 kB)\n","Installing collected packages: pypdf\n","Successfully installed pypdf-5.5.0\n","Collecting tavily-python\n","  Downloading tavily_python-0.7.3-py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n","Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.9.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.4.26)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n","Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (4.13.2)\n","Downloading tavily_python-0.7.3-py3-none-any.whl (15 kB)\n","Installing collected packages: tavily-python\n","Successfully installed tavily-python-0.7.3\n","Collecting PyMuPDF\n","  Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n","Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyMuPDF\n","Successfully installed PyMuPDF-1.26.0\n"]}],"source":["!pip install \"codeinterpreterapi[all]\"\n","!pip install chromadb\n","#!conda install -c conda-forge faiss-cpu\n","!pip install sentence-transformers PyPDF2\n","!pip install -U langchain-community\n","!pip install langchain faiss-cpu\n","!pip install pypdf\n","!pip install tavily-python\n","!pip install PyMuPDF"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oB6kTlRVnMgI","executionInfo":{"status":"ok","timestamp":1748419110654,"user_tz":-540,"elapsed":21064,"user":{"displayName":"박형진","userId":"05628816051884963880"}},"outputId":"8d6a0e6d-8499-45e1-d72d-8bc8b3ed0335"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"XHz6d4QX8Oyu"},"source":["# Stanford AI Index PDF Parser"]},{"cell_type":"code","source":["import os\n","import torch\n","from langchain.document_loaders import PyMuPDFLoader  # 더 나은 PDF 처리\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings.base import Embeddings\n","from sentence_transformers import SentenceTransformer\n","from typing import List"],"metadata":{"id":"rOVjqYduo05D"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LTka4jiL8Nzr"},"outputs":[],"source":["class SentenceTransformerEmbeddings(Embeddings):\n","    \"\"\"LangChain용 Embeddings 래퍼: sentence-transformers 모델을 사용.\"\"\"\n","    def __init__(self, model_name: str = \"BAAI/bge-m3\"):\n","        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.model = SentenceTransformer(model_name).to(device)\n","\n","    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n","        return self.model.encode(texts, show_progress_bar=True, convert_to_numpy=True).tolist()\n","\n","    def embed_query(self, text: str) -> List[float]:\n","        return self.model.encode(text, convert_to_numpy=True).tolist()\n","\n","\n","def ingest_pdf_to_faiss(\n","    pdf_path: str,\n","    index_dir: str = \"faiss_index\",\n","    chunk_size: int = 1000,\n","    chunk_overlap: int = 200,\n","):\n","    \"\"\"\n","    1. PDF 로드 → 페이지별 Document 생성\n","    2. 텍스트 청크 분할\n","    3. SentenceTransformer로 임베딩\n","    4. FAISS 인덱스 생성 및 저장\n","    \"\"\"\n","    print(f\"[1] PDF 로드 중: {pdf_path}\")\n","    loader = PyMuPDFLoader(pdf_path)\n","    docs = loader.load()\n","\n","    print(f\"[2] 텍스트 청크 분할 중 (chunk_size={chunk_size}, overlap={chunk_overlap})\")\n","    splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=chunk_size,\n","        chunk_overlap=chunk_overlap\n","    )\n","    chunks = splitter.split_documents(docs)\n","\n","    print(f\"[3] 임베딩 모델 준비 중...\")\n","    embeddings = SentenceTransformerEmbeddings(\"BAAI/bge-m3\")\n","\n","    print(f\"[4] FAISS 인덱스 생성 중...\")\n","    vector_store = FAISS.from_documents(chunks, embeddings)\n","\n","    print(f\"[5] 로컬 디렉토리에 인덱스 저장: {index_dir}\")\n","    os.makedirs(index_dir, exist_ok=True)\n","    vector_store.save_local(index_dir)\n","    print(f\"\\n✅ 완료: '{index_dir}'에 FAISS 인덱스 저장됨.\")"]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    ingest_pdf_to_faiss(\n","        pdf_path=\"/content/drive/MyDrive/P4DS/hai_ai_index_report_2025.pdf\",\n","        index_dir=\"/content/drive/MyDrive/P4DS\",\n","        chunk_size=1200,\n","        chunk_overlap=200\n","    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":567},"id":"dJ2jxwx2q34N","executionInfo":{"status":"error","timestamp":1748416948155,"user_tz":-540,"elapsed":10804,"user":{"displayName":"박형진","userId":"05628816051884963880"}},"outputId":"ff9f7f68-d1e1-4883-a4e6-8f8f02645705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1] PDF 로드 중: /content/drive/MyDrive/P4DS/hai_ai_index_report_2025.pdf\n","[2] 텍스트 청크 분할 중 (chunk_size=1200, overlap=200)\n","[3] 임베딩 모델 준비 중...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-1283feca70a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     ingest_pdf_to_faiss(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mpdf_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/P4DS/hai_ai_index_report_2025.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mindex_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/P4DS\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-6315f8899123>\u001b[0m in \u001b[0;36mingest_pdf_to_faiss\u001b[0;34m(pdf_path, index_dir, chunk_size, chunk_overlap)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[3] 임베딩 모델 준비 중...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformerEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BAAI/bge-m3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[4] FAISS 인덱스 생성 중...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-6315f8899123>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"BAAI/bge-m3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             ):\n\u001b[0;32m--> 309\u001b[0;31m                 modules, self.module_kwargs = self._load_sbert_model(\n\u001b[0m\u001b[1;32m    310\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1806\u001b[0m                 \u001b[0;31m# Otherwise we fall back to the load method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1808\u001b[0;31m                     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1809\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m                     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"model_max_length\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_mt5_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 self.auto_model = AutoModel.from_pretrained(\n\u001b[0m\u001b[1;32m    182\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         trust_remote_code = resolve_trust_remote_code(\n\u001b[1;32m    549\u001b[0m             \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_local_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_remote_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         mapping_keys = [\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         mapping_keys = [\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;31m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/timm_wrapper/configuration_timm_wrapper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_timm_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageNetInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_imagenet_subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mset_exportable\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mset_exportable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m from .models import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcreate_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlist_models\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlist_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbeit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbyoanet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbyobnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcait\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/models/beit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMAGENET_DEFAULT_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_DEFAULT_STD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPatchEmbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSwiGLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_normal_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fused_attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresample_patch_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample_abs_pos_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_rel_pos_bias_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresolve_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve_model_data_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterableImageDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAugMixDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset_info\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCustomDatasetInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/data/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0m_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/data/readers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreader_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimg_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/data/readers/reader_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreader_image_folder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReaderImageFolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreader_image_in_tar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReaderImageInTar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/data/readers/reader_image_folder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnatural_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclass_map\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_class_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_ema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelEma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelEmaV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelEmaV3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupdate_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_outdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/timm/utils/summary.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Configure the logger as early as possible for consistent behavior.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwb_logging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_wb_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0m_wb_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_wandb_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb_helper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArtifact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwandb_alerts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlertLevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwandb_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/artifacts/artifact.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArtifactCollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArtifactFiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRetryingClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/data_types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchableMedia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMedia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwb_value\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWBValue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/audio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMEDIA_TMP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchableMedia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/base_types/media.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogicalPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwb_value\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWBValue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/base_types/wb_value.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb_setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb_settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_settings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb_settings_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapikey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgitlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGitRepo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_moment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunMoment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murl_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/apis/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mreset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvendor_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mInternalApi\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpublic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPublicApi\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/internal/internal_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_internal_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mServerFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_artifact_registry_project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generated\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSERVER_FEATURES_QUERY_GQL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServerFeaturesQuery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_local_settings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_thread_local_api_settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/artifacts/_validators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from wandb.sdk.artifacts._generated.fragments import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mArtifactPortfolioTypeFields\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mArtifactSequenceTypeFields\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/artifacts/_generated/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mProjectArtifactsProjectArtifactTypeArtifactCollection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m )\n\u001b[0;32m--> 131\u001b[0;31m from .run_input_artifacts import (\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mRunInputArtifacts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mRunInputArtifactsProject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/artifacts/_generated/run_input_artifacts.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRunInputArtifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGQLBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRunInputArtifactsProject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_model_construction.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mns_resolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNsResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_namespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent_namespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mset_model_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_wrapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_resolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns_resolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;31m# This is also set in `complete_model_class()`, after schema gen because they are recreated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_model_construction.py\u001b[0m in \u001b[0;36mset_model_fields\u001b[0;34m(cls, config_wrapper, ns_resolver)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \"\"\"\n\u001b[1;32m    543\u001b[0m     \u001b[0mtypevars_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_typevars_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m     \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_model_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_resolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypevars_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtypevars_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_fields__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_fields.py\u001b[0m in \u001b[0;36mcollect_model_fields\u001b[0;34m(cls, config_wrapper, ns_resolver, typevars_map)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attribute_docstrings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0m_update_fields_from_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_fields.py\u001b[0m in \u001b[0;36m_update_fields_from_docstrings\u001b[0;34m(cls, fields, use_inspect)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_update_fields_from_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFieldInfo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_inspect\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mfields_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_docstrings_from_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_inspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_inspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mann_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mann_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields_docs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_docs_extraction.py\u001b[0m in \u001b[0;36mextract_docstrings_from_cls\u001b[0;34m(cls, use_inspect)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_source_from_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_docs_extraction.py\u001b[0m in \u001b[0;36m_extract_source_from_frame\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_lineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;31m# Copy sys.modules in order to cope with changes while iterating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_filesbymodname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":701,"referenced_widgets":["600a415037314e06b57a0ce798d6c230","a964feab52ab484d8db68b692851ad06","bea59c5b734f479c8dcfd75a421d796a","13032c0ec45c40869a7fec4be505c4ea","549babcffdb948d4961aeeaab252574a","3a714065b1424b739ecce86766713f61","96b4378d18bb4a0fbdb6e6155d1d7549","8d9b8450507c47cbb28370ea49091f58","96fb8c04f70f4d1ea1c3f9883b50bbbe","6fb583241fa2477c96d613a21d590f55","a15877064f8947dd93220f40a135ffe0","cfb8ab675222413e97503120fdf4c4a8","10732e41b9e74460b3d7c629fa8c2428","66ba54017d134eb48ba2bd01290b1ec0","6dc6dcf5d50c45eab81bdd4c667ae967","6cf0fa949272497c869905740793efe4","209fc913d1cf4cf0a933f2f3921c81ee","107f9642d5754bcda7db3662e6840637","6373f3939b5d4e5b97b470a0fde58891","6ebce95b471d49709c8c41fceaa8501a","0c58a0284c024affb86c55b7304df860","50f1bea04c1742468fd95fb8bb8c6fd1","d32875fa422d453d9359c29b1b4c3b51","1a51e7b3be914e13add06625fe7f5862","b54d4fcc34ba4678af4ffad182a7d29a","d2b045525b3647f3822906e1112a6322","2a3a009b94ef41c6a19f239d59353c00","2ce767769b8045588c08aa94447f232e","69d9022d0d2e406f8338d6cf48e99f28","34576fc5fe6e482f9b5ed20013cbbd09","7e79e9438d5d4eeea84ed998d07c29d4","28a57afb183346989ab43757b1f330fd","8a8ab708014e4f92842da6ed1b6df811","b93c818fa16943f48dbc2bb697c4d68f","3eee72c85b3a4445b81c04477acc2ab5","06496abade2d4113b1d88882364c47f2","d781412b81c647b59f8eec098b0eb422","8c361b7d66d64157a7fd1eb0421085c9","e09eede46450481893fc4da57cdb4508","c4ba87b9de804275859c028862fc2887","51c4677992d94d1d8ee601830f98c518","4d32ff55266a4e3d93f33c6ec9961ea2","55a5362f8d144a14aaad4d6692755fb4","af6070c0d9bc40dcb8546360cc22231c","682aea7658f24dc69067d4de961cfc7e","ac2230fbda0f453ea527c08b86cc2bae","d8cda96a50c94ec8ba3774d31489e7d1","911dbd53be164db794854ea25fb452ff","584721cb54ca470587ee032eb5ba8285","95326724267b40ba9add71f9c6afb760","c25f390997d64ab88bb0d67ad0711973","8693c69003e7449289f2b17c2dce3064","1fc256b861c04dcc8df2253e6c070c5b","8b7ebc4116f54c4488cd12876c2d66de","a7536997d0c84c9aa3265ba6d1c96ef2","bacf922848af4214a64a45c2f16f1a69","196dac5c6cd04bb3b63a001c98f44c6b","3821ff647e624ee3b0381458b589339c","20e08ec731ff4129b5726c4892ba8abc","ea8116ee2d2543cdb1dc62a6df6b50c6","be7eaa152bbe4f0d97e140f6327ba0c4","01f70fdc29e845299b0f0639e314ec34","5ab1a20770ad4d9fa096779a3086a2c0","9cb18950529444bb9d522612a1bb7fe3","cf1e9f36a0a2404fb60a5501ee925baf","3022f1b3818d47618b9e5562eaf77fe0","99f701cc642945dc92be7a6218f78b0e","06c3c4fda16546b3bd53ed1d68b86f01","9f7d2fbe32ef4633a44220473ecc86bf","0730afe82a934e958996ff26ea75e456","a1e13bd0c0de4b088c7a51d81b9e2f1e","ebcb34cbb8d441d2a424668a2eea992d","25d1dcb6c2804059a3254607366f3974","35b405e0b3c54e2aa047efe40106c60d","3ad2f43cc1fc426fbaf4e01456e67a42","beb532ce3dec451f926cb617df3d63d3","3350c00e5b274b5e9a15e70bacb41a39","57a97049ed3b4f4d8cd80f5f3ce33625","079fcfa333104468b974d2636c7794b0","236d698924564772984776cea6db5f70","ccc39d22d8654482ae74c51c0e6155d1","09639dc6736748e8ad0bb7b9c05eee34","9a2f0f5599664bb48d8511bf6ae1bad6","e47727ea25fa44fcab234a29332d5212","e93675ff17e54f86842c3a47b104c054","ddb6cfa3c74848be8fb7f1b4a176e820","70d21346a31f4d198178e08e3eddc4ad","4bad9f9c0cb84047886618d81512a5b3","46e2338f2edc4fb5b0ef0ae0023332c2","53dfae37e831462fa96a0a21902580dd","f09b8832ec0e426e8faa9d88038cf30b","f38743f75a1145e19ccd44024bfbc3c4","b7231c6485094e0084a3825b7acb3380","a2a9f693eb034d719a6e233673abe3ac","3a08bcfcea5c420c9db964aad265915d","b8c49f454c6f4bdbbb84350873a2d520","3503fafed90641f7a3abcca7711f8d03","58c3a91580fa46e2902a8cded6e5e0c8","09b13975cc40493a818a9c0f30c23b45","bc1638308cff4af5a67df68b157d06e2","92e75ea54c8248488f6b5743bd2a8686","922fa5285a9548c8b552ee2eb3ed4b69","24e5c86c2e40417dabc7306373b0a53e","c3de7c693d804b8197946488381b2f78","fd223aa252684546a8165a21540b3117","2addf02dac7b483fbd9d3693866c12d4","195796649ddb493d90d5a9c008fcdabd","ed6c640129504941bc713974eb8e10dd","02101deb982842d6a84ac0e8f76d71cc","ffd3d8a79ba34d879871ef0ebd92ab69","a232eb8786b84588922d2f50eaf7dc8e","3df8ae4189b346a3960d289a14c92625","3062e4036cc0458284f2807a4ec4d308","46cbf87b50284858948cbff18a56c6fa","da710d0c043f412ea84c6c0c737198ad","9154af3d3ccd49bdafd3451f38c7b68e","2731be6c9d5d4fc8b8ce20cad842fb25","ad3a437ac0914ccaab22cbb387400e67","ad06b23dfb2e47cab9c8085c8d233ae3","ef2d371de1944008bbdde1853d7bb4d2","492b24417394472191f936e57e711f6f","697b291a7b93457c98810c30329640aa","33b0f6edf5d34c8ea412dc01b4618637","de9b24c40c444f198bddefbb42471142","3765cd38ae49473ba923c73a551344af","0b324b226e424289a347a40ea4a2623d","0122e33fbb5749f9a19a00c2916847c1","a886a7cfa76e44e7a984c5644bafca34","8760fa60cfa645a4986b79f84165df61","31533a6c192d4fb0ab910b5e1aa7cc4d","b65ba6ef8dc94155894055cab4a581c7","1d2c86f07f264bc385e6e6a86f401a4c"]},"id":"3LACQ16omhLx","outputId":"5d056b93-29d0-47d5-f316-64dfdfbd386c","executionInfo":{"status":"ok","timestamp":1748419187070,"user_tz":-540,"elapsed":36769,"user":{"displayName":"박형진","userId":"05628816051884963880"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"600a415037314e06b57a0ce798d6c230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfb8ab675222413e97503120fdf4c4a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/15.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d32875fa422d453d9359c29b1b4c3b51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93c818fa16943f48dbc2bb697c4d68f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"682aea7658f24dc69067d4de961cfc7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bacf922848af4214a64a45c2f16f1a69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99f701cc642945dc92be7a6218f78b0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57a97049ed3b4f4d8cd80f5f3ce33625"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46e2338f2edc4fb5b0ef0ae0023332c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc1638308cff4af5a67df68b157d06e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a232eb8786b84588922d2f50eaf7dc8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697b291a7b93457c98810c30329640aa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","[검색 결과] \"What is trend of AI Research in 2025?\" (top-5)\n","================================================================================\n"," 1. score=0.5729 | Artificial Intelligence Index Report 2025...\n"," 2. score=0.6445 | Table of Contents 38 Artificial Intelligence Index Report 2025 Chapter 1 Preview By Topic Machine learning was the most prevalent research topic in  AI publications in 2023, comprising 75.7% of public...\n"," 3. score=0.6808 | Table of Contents 30 Artificial Intelligence Index Report 2025 Chapter 1 Preview publications more than doubled, rising from approximately  102,000 in 2013 to more than 242,000 in 2023. The increase  ...\n"," 4. score=0.6824 | 225 Artificial Intelligence Index Report 2025 Table of Contents Chapter 4 Preview 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 0.00% 0.20% 0.40% 0.60% 0.80% 1.00% AI job ...\n"," 5. score=0.6842 | Artificial Intelligence Index Report 2025 1 Welcome to the eighth edition of the AI Index report. The 2025 Index is our most comprehensive to date and arrives at an  important moment, as AI’s influenc...\n","================================================================================\n"]}],"source":["def load_faiss_and_query(index_dir: str, query: str, top_k: int = 5):\n","    \"\"\"저장된 FAISS 인덱스를 로드한 뒤 `query`로 검색해 결과를 출력 (테스트용).\"\"\"\n","    embeddings = SentenceTransformerEmbeddings(\"BAAI/bge-m3\")\n","    vector_store = FAISS.load_local(\n","        index_dir,\n","        embeddings,\n","        allow_dangerous_deserialization=True  # ← 핵심 수정\n","    )\n","\n","    docs_and_scores = vector_store.similarity_search_with_score(query, k=top_k)\n","\n","    print(f\"\\n[검색 결과] \\\"{query}\\\" (top-{top_k})\")\n","    print(\"=\" * 80)\n","    for rank, (doc, score) in enumerate(docs_and_scores, 1):\n","        snippet = doc.page_content.replace(\"\\n\", \" \")[:200] + \"...\"\n","        print(f\"{rank:>2}. score={score:.4f} | {snippet}\")\n","    print(\"=\" * 80)\n","\n","\n","if __name__ == \"__main__\":\n","    PDF_PATH = \"/content/hai_ai_index_report_2025.pdf\"\n","    INDEX_DIR = \"/content/drive/MyDrive/P4DS\"\n","\n","    # 인덱스 없으면 새로 생성\n","    if not os.path.isdir(INDEX_DIR):\n","        ingest_pdf_to_faiss(\n","            pdf_path=PDF_PATH,\n","            index_dir=INDEX_DIR,\n","            chunk_size=1200,\n","            chunk_overlap=200,\n","        )\n","\n","    # 간단 질의\n","    for q in [\n","        \"What is trend of AI Research in 2025?\"\n","    ]:\n","        load_faiss_and_query(INDEX_DIR, q, top_k=5)\n"]},{"cell_type":"code","source":["def get_faiss_results(index_dir: str, query: str, top_k: int = 5) -> dict:\n","    \"\"\"FAISS 인덱스를 로드하여 검색 결과를 반환합니다.\"\"\"\n","    embeddings = SentenceTransformerEmbeddings(\"BAAI/bge-m3\")\n","    vector_store = FAISS.load_local(\n","        index_dir,\n","        embeddings,\n","        allow_dangerous_deserialization=True\n","    )\n","\n","    docs_and_scores = vector_store.similarity_search_with_score(query, k=top_k)\n","\n","    return {\n","        \"documents\": [doc.page_content for doc, _ in docs_and_scores],\n","        \"scores\": [score for _, score in docs_and_scores]\n","    }\n"],"metadata":{"id":"SHCZglnfgEdK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Aj-olK4sHzj"},"source":["# Initialize"]},{"cell_type":"markdown","source":["밑 from codeinterpreterapi import CodeInterpreterSession, settings 에서 오류가 날 경우 실행"],"metadata":{"id":"8gQuQu-rAdQa"}},{"cell_type":"code","source":["# 충돌 패키지 제거\n","!pip uninstall -y pydantic pydantic-settings pydantic-core langchain langchain-core langchain-community\n","\n","# pydantic v1 및 langchain 안정 버전 재설치\n","!pip install \"pydantic<2.0\"\n","!pip install \"pydantic-settings<2.0\"\n","!pip install \"langchain==0.0.350\"\n","!pip install codeinterpreterapi==0.1.20\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RMeQeWgG69K2","executionInfo":{"status":"ok","timestamp":1748419512025,"user_tz":-540,"elapsed":44599,"user":{"displayName":"박형진","userId":"05628816051884963880"}},"outputId":"f1c4f2fc-1724-4ce2-9919-544f19e781c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: pydantic 1.10.22\n","Uninstalling pydantic-1.10.22:\n","  Successfully uninstalled pydantic-1.10.22\n","Found existing installation: pydantic-settings 2.9.1\n","Uninstalling pydantic-settings-2.9.1:\n","  Successfully uninstalled pydantic-settings-2.9.1\n","Found existing installation: pydantic_core 2.33.2\n","Uninstalling pydantic_core-2.33.2:\n","  Successfully uninstalled pydantic_core-2.33.2\n","Found existing installation: langchain 0.3.25\n","Uninstalling langchain-0.3.25:\n","  Successfully uninstalled langchain-0.3.25\n","Found existing installation: langchain-core 0.3.62\n","Uninstalling langchain-core-0.3.62:\n","  Successfully uninstalled langchain-core-0.3.62\n","Found existing installation: langchain-community 0.3.24\n","Uninstalling langchain-community-0.3.24:\n","  Successfully uninstalled langchain-community-0.3.24\n","Collecting pydantic<2.0\n","  Using cached pydantic-1.10.22-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (154 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.0) (4.13.2)\n","Using cached pydantic-1.10.22-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","Installing collected packages: pydantic\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","codeboxapi 0.1.19 requires pydantic-settings>=2, which is not installed.\n","codeboxapi 0.1.19 requires pydantic>=2, but you have pydantic 1.10.22 which is incompatible.\n","google-genai 1.16.1 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n","albumentations 2.0.7 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.10.22\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydantic"]},"id":"ade532d112324a9186ab881fc68c681c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting pydantic-settings<2.0\n","  Downloading pydantic_settings-1.99-py3-none-any.whl.metadata (3.8 kB)\n","Collecting pydantic==v2.0a3 (from pydantic-settings<2.0)\n","  Downloading pydantic-2.0a3-py3-none-any.whl.metadata (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<2.0) (1.1.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==v2.0a3->pydantic-settings<2.0) (0.7.0)\n","Collecting pydantic-core==0.25.0 (from pydantic==v2.0a3->pydantic-settings<2.0)\n","  Downloading pydantic_core-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==v2.0a3->pydantic-settings<2.0) (4.13.2)\n","Downloading pydantic_settings-1.99-py3-none-any.whl (9.4 kB)\n","Downloading pydantic-2.0a3-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.8/193.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_core-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydantic-core, pydantic, pydantic-settings\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.22\n","    Uninstalling pydantic-1.10.22:\n","      Successfully uninstalled pydantic-1.10.22\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","codeboxapi 0.1.19 requires pydantic>=2, but you have pydantic 2.0a3 which is incompatible.\n","codeboxapi 0.1.19 requires pydantic-settings>=2, but you have pydantic-settings 1.99 which is incompatible.\n","google-genai 1.16.1 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 2.0a3 which is incompatible.\n","albumentations 2.0.7 requires pydantic>=2.9.2, but you have pydantic 2.0a3 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 2.0a3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-2.0a3 pydantic-core-0.25.0 pydantic-settings-1.99\n","Collecting langchain==0.0.350\n","  Downloading langchain-0.0.350-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (2.0.41)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (3.11.15)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (0.6.7)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (1.33)\n","Collecting langchain-community<0.1,>=0.0.2 (from langchain==0.0.350)\n","  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n","Collecting langchain-core<0.2,>=0.1 (from langchain==0.0.350)\n","  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n","Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.350)\n","  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (2.0a3)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.20.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.350) (3.0.0)\n","INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n","Collecting langchain-community<0.1,>=0.0.2 (from langchain==0.0.350)\n","  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n","  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n","  Downloading langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n","  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n","  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n","  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n","  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n","INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n","  Downloading langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n","  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n","  Downloading langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n","  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n","  Downloading langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n","  Downloading langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n","  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n","  Downloading langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n","INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n","Collecting langchain-core<0.2,>=0.1 (from langchain==0.0.350)\n","  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n","INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n","  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n","  Downloading langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (4.9.0)\n","  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n","  Downloading langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n","Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.350)\n","  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (23.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.0.350) (0.7.0)\n","Requirement already satisfied: pydantic-core==0.25.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.0.350) (0.25.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.0.350) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.0.350) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.0.350) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.0.350) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.0.350) (2025.4.26)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.350) (3.2.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain==0.0.350) (1.3.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (1.1.0)\n","Downloading langchain-0.0.350-py3-none-any.whl (809 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: langsmith, langchain-core, langchain-community, langchain\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.1.147\n","    Uninstalling langsmith-0.1.147:\n","      Successfully uninstalled langsmith-0.1.147\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","codeinterpreterapi 0.1.20 requires langchain<0.2,>=0.1, but you have langchain 0.0.350 which is incompatible.\n","langchain-openai 0.1.7 requires langchain-core<0.3,>=0.1.46, but you have langchain-core 0.1.23 which is incompatible.\n","langchain-text-splitters 0.3.8 requires langchain-core<1.0.0,>=0.3.51, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-0.0.350 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87\n","Requirement already satisfied: codeinterpreterapi==0.1.20 in /usr/local/lib/python3.11/dist-packages (0.1.20)\n","Requirement already satisfied: codeboxapi==0.1.19 in /usr/local/lib/python3.11/dist-packages (from codeinterpreterapi==0.1.20) (0.1.19)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (from codeinterpreterapi==0.1.20) (0.1.7)\n","Collecting langchain<0.2,>=0.1 (from codeinterpreterapi==0.1.20)\n","  Using cached langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: pyzmq==25.1.2 in /usr/local/lib/python3.11/dist-packages (from codeinterpreterapi==0.1.20) (25.1.2)\n","Requirement already satisfied: aiohttp>=3.9 in /usr/local/lib/python3.11/dist-packages (from codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (3.11.15)\n","Collecting pydantic-settings>=2 (from codeboxapi==0.1.19->codeinterpreterapi==0.1.20)\n","  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n","Collecting pydantic>=2 (from codeboxapi==0.1.19->codeinterpreterapi==0.1.20)\n","  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2 in /usr/local/lib/python3.11/dist-packages (from codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (2.32.3)\n","Requirement already satisfied: websockets>=12 in /usr/local/lib/python3.11/dist-packages (from codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (15.0.1)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (2.0.41)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (0.6.7)\n","Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20)\n","  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n","Collecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20)\n","  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n","Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20)\n","  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20)\n","  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (1.26.4)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (8.5.0)\n","Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->codeinterpreterapi==0.1.20) (1.81.0)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->codeinterpreterapi==0.1.20) (0.9.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (1.20.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (0.9.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (1.33)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (23.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (1.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi==0.1.20) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi==0.1.20) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi==0.1.20) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi==0.1.20) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi==0.1.20) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai->codeinterpreterapi==0.1.20) (4.13.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (0.7.0)\n","Collecting pydantic-core==2.33.2 (from pydantic>=2->codeboxapi==0.1.19->codeinterpreterapi==0.1.20)\n","  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (0.4.1)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings>=2->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (1.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2->codeboxapi==0.1.19->codeinterpreterapi==0.1.20) (2025.4.26)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (3.2.2)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai->codeinterpreterapi==0.1.20) (2024.11.6)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (3.0.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2,>=0.1->codeinterpreterapi==0.1.20) (1.1.0)\n","Using cached langchain-0.1.20-py3-none-any.whl (1.0 MB)\n","Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n","Using cached langchain_core-0.1.53-py3-none-any.whl (303 kB)\n","Using cached langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n","Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n","Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.2/444.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n","Installing collected packages: pydantic-core, pydantic, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n","  Attempting uninstall: pydantic-core\n","    Found existing installation: pydantic_core 0.25.0\n","    Uninstalling pydantic_core-0.25.0:\n","      Successfully uninstalled pydantic_core-0.25.0\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.0a3\n","    Uninstalling pydantic-2.0a3:\n","      Successfully uninstalled pydantic-2.0a3\n","  Attempting uninstall: pydantic-settings\n","    Found existing installation: pydantic-settings 1.99\n","    Uninstalling pydantic-settings-1.99:\n","      Successfully uninstalled pydantic-settings-1.99\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.0.87\n","    Uninstalling langsmith-0.0.87:\n","      Successfully uninstalled langsmith-0.0.87\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.1.23\n","    Uninstalling langchain-core-0.1.23:\n","      Successfully uninstalled langchain-core-0.1.23\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.3.8\n","    Uninstalling langchain-text-splitters-0.3.8:\n","      Successfully uninstalled langchain-text-splitters-0.3.8\n","  Attempting uninstall: langchain-community\n","    Found existing installation: langchain-community 0.0.20\n","    Uninstalling langchain-community-0.0.20:\n","      Successfully uninstalled langchain-community-0.0.20\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.0.350\n","    Uninstalling langchain-0.0.350:\n","      Successfully uninstalled langchain-0.0.350\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langsmith-0.1.147 pydantic-2.11.5 pydantic-core-2.33.2 pydantic-settings-2.9.1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XcoEabAtBae3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bQMzDzfzYWM"},"outputs":[],"source":["# === OpenAI & Tavily 설정 ===\n","from openai import OpenAI\n","from tavily import TavilyClient\n","\n","import os\n","\n","# ChromaDB (RAG) 예시\n","import chromadb\n","import chromadb.utils.embedding_functions as embedding_functions\n","\n","# ------------------------------\n","# 환경 변수에서 OPENAI_API_KEY 읽기 (로컬/Colab 등에 맞게 설정)\n","openai_api_key = os.environ.get(\"OPENAI_API_KEY\", \"sk-proj-\")\n","client = OpenAI(api_key=openai_api_key)\n","\n","# Tavily API 키\n","TAVILY_API_KEY = os.environ.get(\"TAVILY_API_KEY\", \"tvly-dev-\")\n","tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n","\n","# === ChromaDB 초기화 (예시) ===\n","DB_PATH = \"my_chromadb_folder\"  # 예: \"./db\" 또는 Google Drive 경로 등\n","client_chroma = chromadb.PersistentClient(path=DB_PATH)\n","\n","# 임베딩 함수 설정 (OpenAI Embedding 사용 예시)\n","openai_embedding = embedding_functions.OpenAIEmbeddingFunction(\n","    api_key=openai_api_key,\n","    model_name=\"text-embed\\ding-ada-002\"\n",")\n","\n","# 'startup_collection' 컬렉션 준비\n","collection = client_chroma.get_or_create_collection(\n","    name=\"startup_collection\",\n","    embedding_function=openai_embedding\n",")\n","\n","# === Visualization 초기화 (예시) ===\n","import os\n","from codeinterpreterapi import CodeInterpreterSession, settings # validation error가 뜬다면 커널을 재시작 한 후 기다렸다가 다시 시도\n","\n","#openai_api_key = os.environ.get(\"OPENAI_API_KEY\", \"sk-proj-...\")\n","settings.OPENAI_API_KEY=openai_api_key\n","settings.MODEL = \"gpt-4.1-mini\""]},{"cell_type":"markdown","metadata":{"id":"BFpc2cY3qlSI"},"source":["# CSV 파일 db 저장\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"get-rt_LqkVg","executionInfo":{"status":"ok","timestamp":1748419582295,"user_tz":-540,"elapsed":37877,"user":{"displayName":"박형진","userId":"05628816051884963880"}},"colab":{"base_uri":"https://localhost:8080/","height":557,"referenced_widgets":["a8e4b0b268c6462c95024eab93844efa","49bbce6130854d3ea82bb158562ea588","3e753c39ddc147baafe1bcb381f66f27","f132677b8ae04b56b809db9edf19ec54","5964ae21869b4b87831826aaee2bd739","60c95f81ef8243eba4b12ace0260d6f9","19c0ad5f1e6a4d2eaabcd83e3e888043","97dd08acbde84953b4fcf0025484fa03","cb054039739a4abeac863f8518908aa0","2bfea9c67a444b71aa657cecdd63cd3b","0173dad867174005bafc569383ec68cc","de607847cc3a4b7aacd49129a4a532ba","fbb7a93252f247cfa75beb450339dd1a","4938771c20b042c39b83e5566d48b077","83ee5df64bf043b4a9ac6b277312522b","536e38d5bcb64346a9b35518e942ca7f","ec78480c66664736a7504f4ecb32de74","9c0b87ccafae4dedb8e4b03a71c34bf3","b1b14b304353498dade828a808c45df4","ce8c0c7412234cff9a35102baf8d090c","db498a271dac49ffa676cbb3fc68a548","e8e2bae919f64039be2e00ebd8871ddf","5fa713deaed34c13acaa89f558fd199c","a58ea755e95c4a1fa61000c0ba8679fa","c5971b43cfbc47a1822f4226d8e95916","09d4456beacd44f081fe7da9401a23d8","69dc2b866fb94ec2a3e2b1e5fe978fd4","25d5a435fc974e54aa6ff6772ac5982a","3944351120e249ce84b8dc64b007f18e","6500a9a7661448049508a1345c6584f8","14332a2c2bf84f56b6a1e311134e3657","39d49c573d3944229d5a8390132ee36b","29c54104927649f3b873670fd9317f79","2e9392e958f54763bc2f880c3d82ca7b","93506fead32744f4afd3ffdfed454ffb","7b873f1b92924963aad1c32a31f1af96","30c25c383135433e8e94d84caf469419","00467c718ffd4ecabb0e182faf385190","94588c33dbfa4076b9f56362883fc614","22b0262c358f487e9e0f3724b46a0bf5","fc37c0165e6e434cabe637720241c73b","8c5b6229fe524233b48ceb001fce682f","749306b4180a48d9b68dcca70ff9cdda","a109d619acfd48739b610164317c5fe4","6ef214cdfdfd4948b05d1b3d00750b88","3bf35574dff24294b1e097d05d4ffe83","f3ebe700028d44738afd42e60579946f","e131e607c3a7441da7bb027ea782e1ef","5b640e74783347e1b71ee555ee6b4273","d10cdd4f1e6f4fe9a3df73e84b52d4e3","d45f086a682d4e69b45b6ccafb363005","c8242e3bae84446dacbcfea979c5b546","84fca0f42197466eaa91963b9b05f9af","a69e5fd040f54cd5b07be74cb377c5eb","8a0da1e5fb2143dca16b11a087c27524","76690654f15a44e3bda95df1c1f5dde9","e914951b8a4c4db796b7e22b6db9bcca","a80100061cdf4dcb9abad3b6afa45b6c","f02180284cf441ab9c7d8ef0119f4598","574544b666ea4cffb67f5440b43cc9fa","4678528eb7934cd782cfee05556ab817","689766776a6647fb8dbc5a324c0777da","bdbd8c0c565a4f27b4eaf477dc3c4c0f","2944679d747f45c7bf7c48dc9a83fc2a","cf974ea5b15a4699a4fd9a56f6434e66","edb3d62b0bb34738bcbd39afb91dad4a","c4f8bfd68fbb4bbea1bed959938c957c","2bf7a92dfbdd4cdf811f4422e3afbfc9","8e2debd91e4e44a2b83859aa9f699c42","76ae63113e544f96869e81891fb04153","982dee3b79ed4f96862d8855d110cdf0","d57f197a66c2476c8958851790525412","36a7e0b876684505b20a253a08e56f13","ab2e830286a14cd2a7b268979e9c1761","3091079acc3a4fb8bd69ef4a936109ae","a00d541272894ef0a5daab97abe78110","1a92d8edde99407f837af82605af67e8","d3919ee8426943198b2ebb8027a56204","1497fbdd9b4d4d30b08b3e75323cb08d","56ffa058eb0246d8bee875648ba479d9","9bf1a11d04334f8d986a94c73bdf3e76","24f27c4cab7a476eb13745fa49f3f907","c6ce522161f7493190b12a17f8d0bb2b","a7a41f1add5f47f39bc396a6762c484d","708c3420f7f94183938d380910920325","141b57505f894d218870f00a7a08532a","fe5b3c8dd6e54d3fa470158d2587b248","b2d9cd973db748489153aeaddb0f0a16","1bba247ce27340eb974b0644b54b9541","323a5ff41ee84c6c94b18617a286a5e7","f927c05df487440086e405ed3e06e8ef","1c866d8d48ab411bab2a8af3804b4f20","11ab8ad795b34b10bdb28bec7bdf006c","ac5fb21b49cc4d77973d5eed53d07dfa","5f156cd8ec5443f3be2b216a31d5e434","b9a0336c86b5480ea49085d354591a3b","ddd70bffd1d740f4b4fa50faab5b14ef","b86687df81cd4344922af7f1508e52a7","81859edea6d34af08dc92ce87d0e920c","13a1d1d09e6d407983ca2105b8b033ca","f73ac20ebced4c14bf60c360a0a78f8c","f3cc392af7ee46eb8b327c9b94241488","e8c639eb5764481ea6aed86000907b87","cb13a609f7c74f30896fe7c68f85671a","3184856d838146ca8b86fd0b6064be64","f37ed3a74ff44947b53a9bc3dd26e906","248571dc2e274686bc91969b8ed1ecb1","07c20504fb9c455cb2e7d84147a91229","2f18d991480542daaf56e3cd3df00aa6","a29a330ab1d94b6aa4e7f5dae70b7dea","4c633a8f5086401598f7a3b3fcd0f9b6","01046a9aea914ecbbc70faec5b26ce8f","c0609d899c884d549789af893e782304","1da74bb74ac646cdbba5cbced3e91466","5f62395af92b48988b587d416f9f50cc","766a04e932d14a6683e9734bae571744","bec64fa3dd474de195d6d4dc8da52c04","c9842cc780224862a4ab56ceb88880f3","40dedde4649f4cce8b9b4a263aace889","dfbac477137e48e098011df1e9207e5e","bc87044dab6c463392b1f736268e07d0"]},"outputId":"9b354a86-51e5-497f-f2ef-2bb051265e7d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8e4b0b268c6462c95024eab93844efa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de607847cc3a4b7aacd49129a4a532ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fa713deaed34c13acaa89f558fd199c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e9392e958f54763bc2f880c3d82ca7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ef214cdfdfd4948b05d1b3d00750b88"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76690654f15a44e3bda95df1c1f5dde9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f8bfd68fbb4bbea1bed959938c957c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3919ee8426943198b2ebb8027a56204"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bba247ce27340eb974b0644b54b9541"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a1d1d09e6d407983ca2105b8b033ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c633a8f5086401598f7a3b3fcd0f9b6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Saved to ChromaDB (using local embedding)\n"]}],"source":["import os\n","import pandas as pd\n","import chromadb\n","import chromadb.utils.embedding_functions as embedding_functions\n","from sentence_transformers import SentenceTransformer\n","\n","openai_api_key = os.environ.get(\"OPENAI_API_KEY\", \"sk-proj-...\")\n","\n","DB_PATH = \"/content/drive/MyDrive/my_chromadb_folder\"\n","#DB_PATH=\"./my_chromadb_folder\"\n","\n","client_chroma = chromadb.PersistentClient(path=DB_PATH)\n","\n","local_embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n","\n","collection = client_chroma.get_or_create_collection(\n","    name=\"startup_collection\",\n","    embedding_function=local_embedding_fn\n",")\n","\n","db_path = \"/content/drive/MyDrive/P4DS/new_DB.xlsx\"\n","#db_path = \"./new_DB.xlsx\"\n","df = pd.read_excel(db_path)\n","\n","documents = []\n","metadatas = []\n","\n","for idx, row in df.iterrows():\n","    description = str(row['설명']) if pd.notna(row['설명']) else \"\"\n","    proposal = str(row['제안서']) if pd.notna(row['제안서']) else \"\"\n","    summary = str(row['요약']) if pd.notna(row['요약']) else \"\"\n","    document_text = description + \" \" + summary\n","\n","    metadata = row.to_dict()\n","\n","    documents.append(document_text)\n","    metadatas.append(metadata)\n","\n","collection.add(\n","    documents=documents,\n","    metadatas=metadatas,\n","    ids=[str(i) for i in range(len(documents))]\n",")\n","\n","print(\"✅ Saved to ChromaDB (using local embedding)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTF1Y6uiqz7L","executionInfo":{"status":"ok","timestamp":1748419593978,"user_tz":-540,"elapsed":155,"user":{"displayName":"박형진","userId":"05628816051884963880"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"521ed570-2ca1-44cd-9b58-7da654c85300"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7ad494f23950>"],"text/html":["<style type=\"text/css\">\n","#T_1e68a th {\n","  text-align: left;\n","}\n","#T_1e68a_row0_col0, #T_1e68a_row0_col1, #T_1e68a_row0_col2, #T_1e68a_row0_col3, #T_1e68a_row0_col4, #T_1e68a_row0_col5, #T_1e68a_row0_col6, #T_1e68a_row0_col7, #T_1e68a_row1_col0, #T_1e68a_row1_col1, #T_1e68a_row1_col2, #T_1e68a_row1_col3, #T_1e68a_row1_col4, #T_1e68a_row1_col5, #T_1e68a_row1_col6, #T_1e68a_row1_col7, #T_1e68a_row2_col0, #T_1e68a_row2_col1, #T_1e68a_row2_col2, #T_1e68a_row2_col3, #T_1e68a_row2_col4, #T_1e68a_row2_col5, #T_1e68a_row2_col6, #T_1e68a_row2_col7, #T_1e68a_row3_col0, #T_1e68a_row3_col1, #T_1e68a_row3_col2, #T_1e68a_row3_col3, #T_1e68a_row3_col4, #T_1e68a_row3_col5, #T_1e68a_row3_col6, #T_1e68a_row3_col7, #T_1e68a_row4_col0, #T_1e68a_row4_col1, #T_1e68a_row4_col2, #T_1e68a_row4_col3, #T_1e68a_row4_col4, #T_1e68a_row4_col5, #T_1e68a_row4_col6, #T_1e68a_row4_col7, #T_1e68a_row5_col0, #T_1e68a_row5_col1, #T_1e68a_row5_col2, #T_1e68a_row5_col3, #T_1e68a_row5_col4, #T_1e68a_row5_col5, #T_1e68a_row5_col6, #T_1e68a_row5_col7, #T_1e68a_row6_col0, #T_1e68a_row6_col1, #T_1e68a_row6_col2, #T_1e68a_row6_col3, #T_1e68a_row6_col4, #T_1e68a_row6_col5, #T_1e68a_row6_col6, #T_1e68a_row6_col7, #T_1e68a_row7_col0, #T_1e68a_row7_col1, #T_1e68a_row7_col2, #T_1e68a_row7_col3, #T_1e68a_row7_col4, #T_1e68a_row7_col5, #T_1e68a_row7_col6, #T_1e68a_row7_col7, #T_1e68a_row8_col0, #T_1e68a_row8_col1, #T_1e68a_row8_col2, #T_1e68a_row8_col3, #T_1e68a_row8_col4, #T_1e68a_row8_col5, #T_1e68a_row8_col6, #T_1e68a_row8_col7, #T_1e68a_row9_col0, #T_1e68a_row9_col1, #T_1e68a_row9_col2, #T_1e68a_row9_col3, #T_1e68a_row9_col4, #T_1e68a_row9_col5, #T_1e68a_row9_col6, #T_1e68a_row9_col7, #T_1e68a_row10_col0, #T_1e68a_row10_col1, #T_1e68a_row10_col2, #T_1e68a_row10_col3, #T_1e68a_row10_col4, #T_1e68a_row10_col5, #T_1e68a_row10_col6, #T_1e68a_row10_col7, #T_1e68a_row11_col0, #T_1e68a_row11_col1, #T_1e68a_row11_col2, #T_1e68a_row11_col3, #T_1e68a_row11_col4, #T_1e68a_row11_col5, #T_1e68a_row11_col6, #T_1e68a_row11_col7, #T_1e68a_row12_col0, #T_1e68a_row12_col1, #T_1e68a_row12_col2, #T_1e68a_row12_col3, #T_1e68a_row12_col4, #T_1e68a_row12_col5, #T_1e68a_row12_col6, #T_1e68a_row12_col7, #T_1e68a_row13_col0, #T_1e68a_row13_col1, #T_1e68a_row13_col2, #T_1e68a_row13_col3, #T_1e68a_row13_col4, #T_1e68a_row13_col5, #T_1e68a_row13_col6, #T_1e68a_row13_col7, #T_1e68a_row14_col0, #T_1e68a_row14_col1, #T_1e68a_row14_col2, #T_1e68a_row14_col3, #T_1e68a_row14_col4, #T_1e68a_row14_col5, #T_1e68a_row14_col6, #T_1e68a_row14_col7, #T_1e68a_row15_col0, #T_1e68a_row15_col1, #T_1e68a_row15_col2, #T_1e68a_row15_col3, #T_1e68a_row15_col4, #T_1e68a_row15_col5, #T_1e68a_row15_col6, #T_1e68a_row15_col7, #T_1e68a_row16_col0, #T_1e68a_row16_col1, #T_1e68a_row16_col2, #T_1e68a_row16_col3, #T_1e68a_row16_col4, #T_1e68a_row16_col5, #T_1e68a_row16_col6, #T_1e68a_row16_col7, #T_1e68a_row17_col0, #T_1e68a_row17_col1, #T_1e68a_row17_col2, #T_1e68a_row17_col3, #T_1e68a_row17_col4, #T_1e68a_row17_col5, #T_1e68a_row17_col6, #T_1e68a_row17_col7, #T_1e68a_row18_col0, #T_1e68a_row18_col1, #T_1e68a_row18_col2, #T_1e68a_row18_col3, #T_1e68a_row18_col4, #T_1e68a_row18_col5, #T_1e68a_row18_col6, #T_1e68a_row18_col7, #T_1e68a_row19_col0, #T_1e68a_row19_col1, #T_1e68a_row19_col2, #T_1e68a_row19_col3, #T_1e68a_row19_col4, #T_1e68a_row19_col5, #T_1e68a_row19_col6, #T_1e68a_row19_col7, #T_1e68a_row20_col0, #T_1e68a_row20_col1, #T_1e68a_row20_col2, #T_1e68a_row20_col3, #T_1e68a_row20_col4, #T_1e68a_row20_col5, #T_1e68a_row20_col6, #T_1e68a_row20_col7, #T_1e68a_row21_col0, #T_1e68a_row21_col1, #T_1e68a_row21_col2, #T_1e68a_row21_col3, #T_1e68a_row21_col4, #T_1e68a_row21_col5, #T_1e68a_row21_col6, #T_1e68a_row21_col7, #T_1e68a_row22_col0, #T_1e68a_row22_col1, #T_1e68a_row22_col2, #T_1e68a_row22_col3, #T_1e68a_row22_col4, #T_1e68a_row22_col5, #T_1e68a_row22_col6, #T_1e68a_row22_col7, #T_1e68a_row23_col0, #T_1e68a_row23_col1, #T_1e68a_row23_col2, #T_1e68a_row23_col3, #T_1e68a_row23_col4, #T_1e68a_row23_col5, #T_1e68a_row23_col6, #T_1e68a_row23_col7, #T_1e68a_row24_col0, #T_1e68a_row24_col1, #T_1e68a_row24_col2, #T_1e68a_row24_col3, #T_1e68a_row24_col4, #T_1e68a_row24_col5, #T_1e68a_row24_col6, #T_1e68a_row24_col7 {\n","  text-align: left;\n","}\n","</style>\n","<table id=\"T_1e68a\" class=\"dataframe\">\n","  <caption>스타트업 DB (요약 보기)</caption>\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_1e68a_level0_col0\" class=\"col_heading level0 col0\" >회사명</th>\n","      <th id=\"T_1e68a_level0_col1\" class=\"col_heading level0 col1\" >설명</th>\n","      <th id=\"T_1e68a_level0_col2\" class=\"col_heading level0 col2\" >제안서</th>\n","      <th id=\"T_1e68a_level0_col3\" class=\"col_heading level0 col3\" >요약</th>\n","      <th id=\"T_1e68a_level0_col4\" class=\"col_heading level0 col4\" >교육</th>\n","      <th id=\"T_1e68a_level0_col5\" class=\"col_heading level0 col5\" >AI/딥테크/블록체인</th>\n","      <th id=\"T_1e68a_level0_col6\" class=\"col_heading level0 col6\" >콘텐츠/예술</th>\n","      <th id=\"T_1e68a_level0_col7\" class=\"col_heading level0 col7\" >음악</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_1e68a_row0_col0\" class=\"data row0 col0\" >퀄슨</td>\n","      <td id=\"T_1e68a_row0_col1\" class=\"data row0 col1\" >기업명: 퀄슨\n","설명: 모바일 기반 영어회화 콘텐츠 플랫폼 '리얼클래스' '슈퍼팬' 등을 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2012-06-18\n","웹사이트: qualson.co...</td>\n","      <td id=\"T_1e68a_row0_col2\" class=\"data row0 col2\" >회사명: 퀄슨 (QUALSON)\n","\n","설립연도: 2012년 6월, 서울 강남구\n","\n","비전: “모바일에서 누구나 실생활 영어회화를 자유롭게 익히도록.”\n","퀄슨은 모바일 기반 영어회화 콘텐츠 ...</td>\n","      <td id=\"T_1e68a_row0_col3\" class=\"data row0 col3\" >퀄슨은 2012년 6월에 설립된 모바일 기반 영어회화 콘텐츠 플랫폼 '리얼클래스' '슈퍼팬' 등을 운영하는 ...</td>\n","      <td id=\"T_1e68a_row0_col4\" class=\"data row0 col4\" >✅</td>\n","      <td id=\"T_1e68a_row0_col5\" class=\"data row0 col5\" >✅</td>\n","      <td id=\"T_1e68a_row0_col6\" class=\"data row0 col6\" >✅</td>\n","      <td id=\"T_1e68a_row0_col7\" class=\"data row0 col7\" >✅</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_1e68a_row1_col0\" class=\"data row1 col0\" >에이치투케이</td>\n","      <td id=\"T_1e68a_row1_col1\" class=\"data row1 col1\" >기업명: 에이치투케이\n","설명: AI 기반 아동 대상 한글 교육 플랫폼 '소중한글'을 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2017-07-14\n","웹사이트: sojunghangeul...</td>\n","      <td id=\"T_1e68a_row1_col2\" class=\"data row1 col2\" >회사명: 에이치투케이 (H2K)\n","\n","설립연도: 2017년 7월, 대전 유성구\n","\n","비전: “AI로 유아의 한글 교육을 혁신한다.”\n","에이치투케이는 인공지능 기반 유아 한글 교육 플랫폼 ‘...</td>\n","      <td id=\"T_1e68a_row1_col3\" class=\"data row1 col3\" >에이치투케이는 2017년 7월에 설립된 AI 기반 아동 대상 한글 교육 플랫폼 '소중한글'을 운영하는 기업 ...</td>\n","      <td id=\"T_1e68a_row1_col4\" class=\"data row1 col4\" >✅</td>\n","      <td id=\"T_1e68a_row1_col5\" class=\"data row1 col5\" >✅</td>\n","      <td id=\"T_1e68a_row1_col6\" class=\"data row1 col6\" >✅</td>\n","      <td id=\"T_1e68a_row1_col7\" class=\"data row1 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_1e68a_row2_col0\" class=\"data row2 col0\" >플랭</td>\n","      <td id=\"T_1e68a_row2_col1\" class=\"data row2 col1\" >기업명: 플랭\n","설명: AI 기반 영어회화 트레이닝 플랫폼 '플랭'을 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2019-06-21\n","웹사이트: plang.ai\n","주소: 서울 서초구 방...</td>\n","      <td id=\"T_1e68a_row2_col2\" class=\"data row2 col2\" >회사명: 플랭 (PLANG)\n","\n","설립연도: 2019년 6월, 서울 서초구\n","\n","비전: “AI로 영어 말하기 학습을 일상화한다.”\n","플랭은 AI 기반 영어회화 트레이닝 플랫폼으로, 사용자의...</td>\n","      <td id=\"T_1e68a_row2_col3\" class=\"data row2 col3\" >플랭은 2019년 6월에 설립된 AI 기반 영어회화 트레이닝 플랫폼 '플랭'을 운영하는 기업 비즈니스다. 비...</td>\n","      <td id=\"T_1e68a_row2_col4\" class=\"data row2 col4\" >✅</td>\n","      <td id=\"T_1e68a_row2_col5\" class=\"data row2 col5\" >✅</td>\n","      <td id=\"T_1e68a_row2_col6\" class=\"data row2 col6\" >✅</td>\n","      <td id=\"T_1e68a_row2_col7\" class=\"data row2 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_1e68a_row3_col0\" class=\"data row3 col0\" >비브리지</td>\n","      <td id=\"T_1e68a_row3_col1\" class=\"data row3 col1\" >기업명: 비브리지\n","설명: AI 기반 미디어/콘텐츠 기업 대상 AI 더빙 제작 대행 서비스 '비브리지AI' 및 AI 기반 동영상 강의용 필기 소프트웨어 '슬리드'를 제공하는 기업\n","상...</td>\n","      <td id=\"T_1e68a_row3_col2\" class=\"data row3 col2\" >회사명: 비브리지 (BeBridge)\n","\n","설립연도: 2020년 8월, 서울 강남구\n","\n","비전: “AI로 콘텐츠 제작과 학습 기록을 자동화한다.”\n","비브리지는 미디어 및 교육 콘텐츠 제작을...</td>\n","      <td id=\"T_1e68a_row3_col3\" class=\"data row3 col3\" >비브리지는 2020년 8월에 설립된 AI 기반 미디어/콘텐츠 기업 대상 AI 더빙 제작 대행 서비스 '비브리...</td>\n","      <td id=\"T_1e68a_row3_col4\" class=\"data row3 col4\" >✅</td>\n","      <td id=\"T_1e68a_row3_col5\" class=\"data row3 col5\" >✅</td>\n","      <td id=\"T_1e68a_row3_col6\" class=\"data row3 col6\" >✅</td>\n","      <td id=\"T_1e68a_row3_col7\" class=\"data row3 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n","      <td id=\"T_1e68a_row4_col0\" class=\"data row4 col0\" >베스핀글로벌</td>\n","      <td id=\"T_1e68a_row4_col1\" class=\"data row4 col1\" >기업명: 베스핀글로벌\n","설명: 머신러닝·AI 기반 기업대상으로 클라우드 서비스를 제공하는 기업\n","상장 여부: 비상장\n","창립일: 2015-10-19\n","웹사이트: www.bespingloba...</td>\n","      <td id=\"T_1e68a_row4_col2\" class=\"data row4 col2\" >회사명: 베스핀글로벌 (Bespin Global)\n","\n","설립연도: 2015년 10월, 서울 서초구\n","\n","비전: “AI로 기업의 클라우드 운영을 지능화한다.”\n","베스핀글로벌은 머신러닝과 AI...</td>\n","      <td id=\"T_1e68a_row4_col3\" class=\"data row4 col3\" >베스핀글로벌은 2015년 10월에 설립된 머신러닝·AI 기반 기업대상으로 클라우드 서비스를 제공하는 기업 비...</td>\n","      <td id=\"T_1e68a_row4_col4\" class=\"data row4 col4\" ></td>\n","      <td id=\"T_1e68a_row4_col5\" class=\"data row4 col5\" >✅</td>\n","      <td id=\"T_1e68a_row4_col6\" class=\"data row4 col6\" ></td>\n","      <td id=\"T_1e68a_row4_col7\" class=\"data row4 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n","      <td id=\"T_1e68a_row5_col0\" class=\"data row5 col0\" >메가존클라우드</td>\n","      <td id=\"T_1e68a_row5_col1\" class=\"data row5 col1\" >기업명: 메가존클라우드\n","설명: 클라우드 관리 서비스를 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2018-07-03\n","웹사이트: megazone.com\n","주소: 서울 강남구 논현로85...</td>\n","      <td id=\"T_1e68a_row5_col2\" class=\"data row5 col2\" >회사명: 메가존클라우드 (Megazone Cloud)\n","\n","설립연도: 2018년 7월, 서울 강남구\n","\n","비전: “클라우드 인프라의 표준을 이끄는 MSP 선도 기업.”\n","메가존클라우드는 클...</td>\n","      <td id=\"T_1e68a_row5_col3\" class=\"data row5 col3\" >메가존클라우드는 2018년 7월에 설립된 클라우드 관리 서비스를 운영하는 기업 비즈니스다. 비상장 상태이다....</td>\n","      <td id=\"T_1e68a_row5_col4\" class=\"data row5 col4\" ></td>\n","      <td id=\"T_1e68a_row5_col5\" class=\"data row5 col5\" ></td>\n","      <td id=\"T_1e68a_row5_col6\" class=\"data row5 col6\" ></td>\n","      <td id=\"T_1e68a_row5_col7\" class=\"data row5 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n","      <td id=\"T_1e68a_row6_col0\" class=\"data row6 col0\" >클루커스</td>\n","      <td id=\"T_1e68a_row6_col1\" class=\"data row6 col1\" >기업명: 클루커스\n","설명: 클라우드 서비스 기반 고객 컨설팅 및 관리서비스를 제공하는 기업\n","상장 여부: 비상장\n","창립일: 2018-12-21\n","웹사이트: www.cloocus.com\n","주...</td>\n","      <td id=\"T_1e68a_row6_col2\" class=\"data row6 col2\" >회사명: 클루커스 (Cloocus)\n","\n","설립연도: 2018년 12월, 서울 강남구\n","\n","비전: “클라우드 전환의 복잡함을 고객 중심 컨설팅으로 단순화하다.”\n","클루커스는 클라우드 인프라 ...</td>\n","      <td id=\"T_1e68a_row6_col3\" class=\"data row6 col3\" >클루커스는 2018년 12월에 설립된 클라우드 서비스 기반 고객 컨설팅 및 관리서비스를 제공하는 기업 비즈니...</td>\n","      <td id=\"T_1e68a_row6_col4\" class=\"data row6 col4\" ></td>\n","      <td id=\"T_1e68a_row6_col5\" class=\"data row6 col5\" ></td>\n","      <td id=\"T_1e68a_row6_col6\" class=\"data row6 col6\" ></td>\n","      <td id=\"T_1e68a_row6_col7\" class=\"data row6 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n","      <td id=\"T_1e68a_row7_col0\" class=\"data row7 col0\" >마음에이아이</td>\n","      <td id=\"T_1e68a_row7_col1\" class=\"data row7 col1\" >기업명: 마음에이아이\n","설명: AI모델 생성 플랫폼 '마음AI'를 운영하는 기업\n","상장 여부: 상장\n","창립일: 2014-01-08\n","웹사이트: maum.ai\n","주소: 경기 성남시 분당구 대...</td>\n","      <td id=\"T_1e68a_row7_col2\" class=\"data row7 col2\" >회사명: 마음에이아이 (Maum AI)\n","\n","설립연도: 2014년 1월, 경기 성남시 분당구\n","\n","비전: “누구나 AI를 직접 만들 수 있도록.”\n","마음에이아이는 사용자가 직접 AI 모델을...</td>\n","      <td id=\"T_1e68a_row7_col3\" class=\"data row7 col3\" >마음에이아이는 2014년 1월에 설립된 AI모델 생성 플랫폼 '마음AI'를 운영하는 기업 비즈니스다. 상장 ...</td>\n","      <td id=\"T_1e68a_row7_col4\" class=\"data row7 col4\" ></td>\n","      <td id=\"T_1e68a_row7_col5\" class=\"data row7 col5\" >✅</td>\n","      <td id=\"T_1e68a_row7_col6\" class=\"data row7 col6\" ></td>\n","      <td id=\"T_1e68a_row7_col7\" class=\"data row7 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n","      <td id=\"T_1e68a_row8_col0\" class=\"data row8 col0\" >씨유박스</td>\n","      <td id=\"T_1e68a_row8_col1\" class=\"data row8 col1\" >기업명: 씨유박스\n","설명: AI 기반 생체 보안 시스템 및 솔루션을 제공하는 기업\n","유사 기업: 컴퓨터메이트, 씨앤알테크, 에어콕, 에이엘아이, 엘텍코리아, 이노비드\n","소비자 성별 및 ...</td>\n","      <td id=\"T_1e68a_row8_col2\" class=\"data row8 col2\" >회사명: 씨유박스 (CUBOX)\n","\n","비전: “AI 기반 생체 보안으로 사람과 공간의 안전을 혁신하다.”\n","씨유박스는 안면인식, 지문인식, 복합 생체 인증 기술을 활용해 비접촉 보안 시...</td>\n","      <td id=\"T_1e68a_row8_col3\" class=\"data row8 col3\" >씨유박스는 2010년 6월에 설립된 AI 기반 생체 보안 시스템 및 솔루션을 제공하는 기업 비즈니스다. 상장...</td>\n","      <td id=\"T_1e68a_row8_col4\" class=\"data row8 col4\" ></td>\n","      <td id=\"T_1e68a_row8_col5\" class=\"data row8 col5\" >✅</td>\n","      <td id=\"T_1e68a_row8_col6\" class=\"data row8 col6\" ></td>\n","      <td id=\"T_1e68a_row8_col7\" class=\"data row8 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n","      <td id=\"T_1e68a_row9_col0\" class=\"data row9 col0\" >딥핑소스</td>\n","      <td id=\"T_1e68a_row9_col1\" class=\"data row9 col1\" >기업명: 딥핑소스\n","설명: 머신러닝 기반 데이터 수집 및 보안 기술을 개발하는 기업\n","상장 여부: 비상장\n","창립일: 2018-06-01\n","웹사이트: www.deepingsource.io\n","...</td>\n","      <td id=\"T_1e68a_row9_col2\" class=\"data row9 col2\" >회사명: 딥핑소스 (Deeping Source)\n","\n","설립연도: 2018년 6월, 서울 강남구\n","\n","비전: “데이터 보호와 활용을 동시에 실현하는 AI 보안 기술의 표준.”\n","딥핑소스는 머...</td>\n","      <td id=\"T_1e68a_row9_col3\" class=\"data row9 col3\" >딥핑소스는 2018년 6월에 설립된 머신러닝 기반 데이터 수집 및 보안 기술을 개발하는 기업 비즈니스다. 비...</td>\n","      <td id=\"T_1e68a_row9_col4\" class=\"data row9 col4\" ></td>\n","      <td id=\"T_1e68a_row9_col5\" class=\"data row9 col5\" >✅</td>\n","      <td id=\"T_1e68a_row9_col6\" class=\"data row9 col6\" ></td>\n","      <td id=\"T_1e68a_row9_col7\" class=\"data row9 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n","      <td id=\"T_1e68a_row10_col0\" class=\"data row10 col0\" >라이너</td>\n","      <td id=\"T_1e68a_row10_col1\" class=\"data row10 col1\" >기업명: 라이너\n","설명: 개인화 정보 큐레이션 플랫폼 '라이너'를 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2012-09-27\n","웹사이트: getliner.com\n","주소: 서울 마포구...</td>\n","      <td id=\"T_1e68a_row10_col2\" class=\"data row10 col2\" >회사명: 라이너 (LINER)\n","\n","설립연도: 2012년 9월, 서울 마포구\n","\n","비전: “과잉 정보 시대에, 정말 중요한 정보만 눈앞에 보여주는 것.”\n","라이너는 개인화 정보 큐레이션 플...</td>\n","      <td id=\"T_1e68a_row10_col3\" class=\"data row10 col3\" >라이너는 2012년 9월에 설립된 개인화 정보 큐레이션 플랫폼 '라이너'를 운영하는 기업 비즈니스다. 비상장...</td>\n","      <td id=\"T_1e68a_row10_col4\" class=\"data row10 col4\" ></td>\n","      <td id=\"T_1e68a_row10_col5\" class=\"data row10 col5\" >✅</td>\n","      <td id=\"T_1e68a_row10_col6\" class=\"data row10 col6\" ></td>\n","      <td id=\"T_1e68a_row10_col7\" class=\"data row10 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n","      <td id=\"T_1e68a_row11_col0\" class=\"data row11 col0\" >파이온코퍼레이션</td>\n","      <td id=\"T_1e68a_row11_col1\" class=\"data row11 col1\" >기업명: 파이온코퍼레이션\n","설명: AI 기반 영상 자동 제작 솔루션 '브이캣'을 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2019-02-12\n","웹사이트: pioncorp.com\n","주소...</td>\n","      <td id=\"T_1e68a_row11_col2\" class=\"data row11 col2\" >회사명: 파이온코퍼레이션 (Pion Corporation)\n","\n","설립연도: 2019년 2월, 서울 강남구\n","\n","비전: “누구나 AI로 손쉽게 고품질 영상을 만들 수 있도록.”\n","파이온코퍼레...</td>\n","      <td id=\"T_1e68a_row11_col3\" class=\"data row11 col3\" >파이온코퍼레이션은 2019년 2월에 설립된 AI 기반 영상 자동 제작 솔루션 '브이캣'을 운영하는 기업 비즈...</td>\n","      <td id=\"T_1e68a_row11_col4\" class=\"data row11 col4\" ></td>\n","      <td id=\"T_1e68a_row11_col5\" class=\"data row11 col5\" >✅</td>\n","      <td id=\"T_1e68a_row11_col6\" class=\"data row11 col6\" >✅</td>\n","      <td id=\"T_1e68a_row11_col7\" class=\"data row11 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n","      <td id=\"T_1e68a_row12_col0\" class=\"data row12 col0\" >루나소프트</td>\n","      <td id=\"T_1e68a_row12_col1\" class=\"data row12 col1\" >기업명: 루나소프트\n","설명: AI 기반 이커머스 챗봇 구축 솔루션 제공 및 고객상담 플랫폼 '루나플러스'를 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2016-03-30\n","웹사이트: ...</td>\n","      <td id=\"T_1e68a_row12_col2\" class=\"data row12 col2\" >회사명: 루나소프트 (Lunasoft)\n","\n","설립연도: 2016년 3월, 서울 강남구\n","\n","비전: “AI로 고객상담의 효율을 재정의한다.”\n","루나소프트는 이커머스에 최적화된 AI 기반 챗봇...</td>\n","      <td id=\"T_1e68a_row12_col3\" class=\"data row12 col3\" >루나소프트는 2016년 3월에 설립된 AI 기반 이커머스 챗봇 구축 솔루션 제공 및 고객상담 플랫폼 '루나플...</td>\n","      <td id=\"T_1e68a_row12_col4\" class=\"data row12 col4\" ></td>\n","      <td id=\"T_1e68a_row12_col5\" class=\"data row12 col5\" >✅</td>\n","      <td id=\"T_1e68a_row12_col6\" class=\"data row12 col6\" ></td>\n","      <td id=\"T_1e68a_row12_col7\" class=\"data row12 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n","      <td id=\"T_1e68a_row13_col0\" class=\"data row13 col0\" >에이아이닷엠</td>\n","      <td id=\"T_1e68a_row13_col1\" class=\"data row13 col1\" >기업명: 에이아이닷엠\n","설명: AI 기반 이커머스 솔루션 '마켓위자드' 등을 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2019-04-02\n","웹사이트: aimlabs.ai\n","주소: 경기...</td>\n","      <td id=\"T_1e68a_row13_col2\" class=\"data row13 col2\" >회사명: 에이아이닷엠 (AI.M)\n","\n","설립연도: 2019년 4월, 경기 수원시\n","\n","비전: “AI로 이커머스 운영의 모든 과정을 자동화한다.”\n","에이아이닷엠은 AI 기반 이커머스 솔루션 ...</td>\n","      <td id=\"T_1e68a_row13_col3\" class=\"data row13 col3\" >에이아이닷엠은 2019년 4월에 설립된 AI 기반 이커머스 솔루션 '마켓위자드' 등을 운영하는 기업 비즈니스...</td>\n","      <td id=\"T_1e68a_row13_col4\" class=\"data row13 col4\" ></td>\n","      <td id=\"T_1e68a_row13_col5\" class=\"data row13 col5\" >✅</td>\n","      <td id=\"T_1e68a_row13_col6\" class=\"data row13 col6\" ></td>\n","      <td id=\"T_1e68a_row13_col7\" class=\"data row13 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n","      <td id=\"T_1e68a_row14_col0\" class=\"data row14 col0\" >하이퍼엑셀</td>\n","      <td id=\"T_1e68a_row14_col1\" class=\"data row14 col1\" >기업명: 하이퍼엑셀\n","설명: 생성형 AI 반도체 딥테크 기업\n","상장 여부: 비상장\n","창립일: 2023-01-12\n","웹사이트: hyperaccel.ai\n","주소: 경기 화성시 동탄역로 160 ...</td>\n","      <td id=\"T_1e68a_row14_col2\" class=\"data row14 col2\" >회사명: 하이퍼엑셀 (HyperAccel)\n","\n","설립연도: 2023년 1월, 경기 화성시\n","\n","비전: “차세대 생성형 AI를 위한 반도체 기술의 기반이 되다.”\n","하이퍼엑셀은 생성형 AI ...</td>\n","      <td id=\"T_1e68a_row14_col3\" class=\"data row14 col3\" >하이퍼엑셀은 2023년 1월에 설립된 생성형 AI 반도체 딥테크 기업 비즈니스다. 비상장 상태이다. 누적 투...</td>\n","      <td id=\"T_1e68a_row14_col4\" class=\"data row14 col4\" ></td>\n","      <td id=\"T_1e68a_row14_col5\" class=\"data row14 col5\" >✅</td>\n","      <td id=\"T_1e68a_row14_col6\" class=\"data row14 col6\" ></td>\n","      <td id=\"T_1e68a_row14_col7\" class=\"data row14 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n","      <td id=\"T_1e68a_row15_col0\" class=\"data row15 col0\" >커먼컴퓨터</td>\n","      <td id=\"T_1e68a_row15_col1\" class=\"data row15 col1\" >기업명: 커먼컴퓨터\n","설명: A I기반 블록체인 클라우드 서비스 'AI네트워크' 및 '아이나이즈'를 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2018-05-10\n","웹사이트: comc...</td>\n","      <td id=\"T_1e68a_row15_col2\" class=\"data row15 col2\" >회사명: 커먼컴퓨터 (Common Computer)\n","\n","설립연도: 2018년 5월, 서울 서초구\n","\n","비전: “탈중앙 AI 클라우드를 통해 누구나 AI를 자유롭게 쓰는 세상을 만든다.”...</td>\n","      <td id=\"T_1e68a_row15_col3\" class=\"data row15 col3\" >커먼컴퓨터는 2018년 5월에 설립된 A I기반 블록체인 클라우드 서비스 'AI네트워크' 및 '아이나이즈'를...</td>\n","      <td id=\"T_1e68a_row15_col4\" class=\"data row15 col4\" >✅</td>\n","      <td id=\"T_1e68a_row15_col5\" class=\"data row15 col5\" >✅</td>\n","      <td id=\"T_1e68a_row15_col6\" class=\"data row15 col6\" ></td>\n","      <td id=\"T_1e68a_row15_col7\" class=\"data row15 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n","      <td id=\"T_1e68a_row16_col0\" class=\"data row16 col0\" >슈퍼브에이아이</td>\n","      <td id=\"T_1e68a_row16_col1\" class=\"data row16 col1\" >기업명: 슈퍼브에이아이\n","설명: AI 기반 데이터 구축 플랫폼 '슈퍼브에이아이'를 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2018-04-23\n","웹사이트: superb-ai.com\n","...</td>\n","      <td id=\"T_1e68a_row16_col2\" class=\"data row16 col2\" >회사명: 슈퍼브에이아이 (Superb AI)\n","\n","설립연도: 2018년 4월, 서울 강남구\n","\n","비전: “AI 학습에 필요한 데이터를 더 빠르고 정밀하게.”\n","슈퍼브에이아이는 AI 개발을 ...</td>\n","      <td id=\"T_1e68a_row16_col3\" class=\"data row16 col3\" >슈퍼브에이아이는 2018년 4월에 설립된 AI 기반 데이터 구축 플랫폼 '슈퍼브에이아이'를 운영하는 기업 비...</td>\n","      <td id=\"T_1e68a_row16_col4\" class=\"data row16 col4\" ></td>\n","      <td id=\"T_1e68a_row16_col5\" class=\"data row16 col5\" >✅</td>\n","      <td id=\"T_1e68a_row16_col6\" class=\"data row16 col6\" ></td>\n","      <td id=\"T_1e68a_row16_col7\" class=\"data row16 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n","      <td id=\"T_1e68a_row17_col0\" class=\"data row17 col0\" >노타</td>\n","      <td id=\"T_1e68a_row17_col1\" class=\"data row17 col1\" >기업명: 노타\n","설명: 딥러닝 모델 경량화 기술 기반 AI 모델 압축 플랫폼 '넷츠프레소'를 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2015-04-24\n","웹사이트: nota.ai\n","...</td>\n","      <td id=\"T_1e68a_row17_col2\" class=\"data row17 col2\" >회사명: 노타 (NOTA)\n","\n","설립연도: 2015년 4월, 대전 유성구\n","\n","비전: “딥러닝 경량화를 통해 AI의 대중화를 앞당긴다.”\n","노타는 경량화된 AI 모델을 다양한 디바이스에 탑...</td>\n","      <td id=\"T_1e68a_row17_col3\" class=\"data row17 col3\" >노타는 2015년 4월에 설립된 딥러닝 모델 경량화 기술 기반 AI 모델 압축 플랫폼 '넷츠프레소'를 운영하...</td>\n","      <td id=\"T_1e68a_row17_col4\" class=\"data row17 col4\" ></td>\n","      <td id=\"T_1e68a_row17_col5\" class=\"data row17 col5\" ></td>\n","      <td id=\"T_1e68a_row17_col6\" class=\"data row17 col6\" ></td>\n","      <td id=\"T_1e68a_row17_col7\" class=\"data row17 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n","      <td id=\"T_1e68a_row18_col0\" class=\"data row18 col0\" >시큐리티플랫폼</td>\n","      <td id=\"T_1e68a_row18_col1\" class=\"data row18 col1\" >기업명: 시큐리티플랫폼\n","설명: IOT 사물 연결 디바이스에 적용하는 보안 솔루션을 개발하는 기업\n","상장 여부: 비상장\n","창립일: 2015-07-01\n","웹사이트: www.securityp...</td>\n","      <td id=\"T_1e68a_row18_col2\" class=\"data row18 col2\" >회사명: 시큐리티플랫폼 (SecurityPlatform)\n","\n","설립연도: 2015년 7월, 서울 강남구\n","\n","비전: “모든 사물인터넷 기기를 안전하게 연결한다.”\n","시큐리티플랫폼은 IoT ...</td>\n","      <td id=\"T_1e68a_row18_col3\" class=\"data row18 col3\" >시큐리티플랫폼은 2015년 7월에 설립된 IOT 사물 연결 디바이스에 적용하는 보안 솔루션을 개발하는 기업 ...</td>\n","      <td id=\"T_1e68a_row18_col4\" class=\"data row18 col4\" ></td>\n","      <td id=\"T_1e68a_row18_col5\" class=\"data row18 col5\" >✅</td>\n","      <td id=\"T_1e68a_row18_col6\" class=\"data row18 col6\" ></td>\n","      <td id=\"T_1e68a_row18_col7\" class=\"data row18 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n","      <td id=\"T_1e68a_row19_col0\" class=\"data row19 col0\" >노르마</td>\n","      <td id=\"T_1e68a_row19_col1\" class=\"data row19 col1\" >기업명: 노르마\n","설명: IoT 보안 솔루션과 컨설팅 서비스를 제공하는 기업\n","상장 여부: 비상장\n","창립일: 2011-10-12\n","웹사이트: norma.co.kr\n","주소: 서울 성동구 뚝섬...</td>\n","      <td id=\"T_1e68a_row19_col2\" class=\"data row19 col2\" >회사명: 노르마 (NORMA)\n","\n","설립연도: 2011년 10월, 서울 성동구\n","\n","비전: “모든 IoT 환경에 기본이 되는 보안을 구축한다.”\n","노르마는 IoT 환경에 최적화된 보안 솔루...</td>\n","      <td id=\"T_1e68a_row19_col3\" class=\"data row19 col3\" >노르마는 2011년 10월에 설립된 IoT 보안 솔루션과 컨설팅 서비스를 제공하는 기업 비즈니스다. 비상장 ...</td>\n","      <td id=\"T_1e68a_row19_col4\" class=\"data row19 col4\" ></td>\n","      <td id=\"T_1e68a_row19_col5\" class=\"data row19 col5\" >✅</td>\n","      <td id=\"T_1e68a_row19_col6\" class=\"data row19 col6\" ></td>\n","      <td id=\"T_1e68a_row19_col7\" class=\"data row19 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n","      <td id=\"T_1e68a_row20_col0\" class=\"data row20 col0\" >자이냅스</td>\n","      <td id=\"T_1e68a_row20_col1\" class=\"data row20 col1\" >기업명: 자이냅스\n","설명: NLU AI기반 챗봇 서비스 듀얼톡 및 영상 음성 합성 콘텐츠 솔루션을 제공하는 기업\n","상장 여부: 비상장\n","창립일: 2017-02-08\n","웹사이트: xinap...</td>\n","      <td id=\"T_1e68a_row20_col2\" class=\"data row20 col2\" >회사명: 자이냅스 (XINAPSE)\n","\n","설립연도: 2017년 2월, 서울 강남구\n","\n","비전: “자연어와 음성, 영상을 융합해 인간처럼 소통하는 AI를 만든다.”\n","자이냅스는 자연어 이해(...</td>\n","      <td id=\"T_1e68a_row20_col3\" class=\"data row20 col3\" >자이냅스는 2017년 2월에 설립된 NLU AI기반 챗봇 서비스 듀얼톡 및 영상 음성 합성 콘텐츠 솔루션을 ...</td>\n","      <td id=\"T_1e68a_row20_col4\" class=\"data row20 col4\" ></td>\n","      <td id=\"T_1e68a_row20_col5\" class=\"data row20 col5\" >✅</td>\n","      <td id=\"T_1e68a_row20_col6\" class=\"data row20 col6\" ></td>\n","      <td id=\"T_1e68a_row20_col7\" class=\"data row20 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n","      <td id=\"T_1e68a_row21_col0\" class=\"data row21 col0\" >업스테이지</td>\n","      <td id=\"T_1e68a_row21_col1\" class=\"data row21 col1\" >기업명: 업스테이지\n","설명: AI 챗봇 서비스 아숙업을 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2020-10-05\n","웹사이트: upstage.ai\n","주소: 경기 용인시 수지구 광교중...</td>\n","      <td id=\"T_1e68a_row21_col2\" class=\"data row21 col2\" >회사명: 업스테이지 (Upstage)\n","\n","설립연도: 2020년 10월, 경기 용인시\n","\n","비전: “모든 기업이 AI로 성장할 수 있도록.”\n","업스테이지는 AI 챗봇 서비스 ‘아숙업’을 중...</td>\n","      <td id=\"T_1e68a_row21_col3\" class=\"data row21 col3\" >업스테이지는 2020년 10월에 설립된 AI 챗봇 서비스 아숙업을 운영하는 기업 비즈니스다. 비상장 상태이다...</td>\n","      <td id=\"T_1e68a_row21_col4\" class=\"data row21 col4\" ></td>\n","      <td id=\"T_1e68a_row21_col5\" class=\"data row21 col5\" ></td>\n","      <td id=\"T_1e68a_row21_col6\" class=\"data row21 col6\" ></td>\n","      <td id=\"T_1e68a_row21_col7\" class=\"data row21 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n","      <td id=\"T_1e68a_row22_col0\" class=\"data row22 col0\" >뤼튼테크놀로지스</td>\n","      <td id=\"T_1e68a_row22_col1\" class=\"data row22 col1\" >기업명: 뤼튼테크놀로지스\n","설명: 생성 AI 플랫폼 '뤼튼'을 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2021-04-13\n","웹사이트: wrtn.io\n","주소: 서울 서초구 서초대로77...</td>\n","      <td id=\"T_1e68a_row22_col2\" class=\"data row22 col2\" >회사명: 뤼튼테크놀로지스 (Wrtn Technologies)\n","\n","설립연도: 2021년 4월, 서울 서초구\n","\n","비전: “누구나 창작자가 되는 세상.”\n","뤼튼테크놀로지스는 생성형 AI 기반...</td>\n","      <td id=\"T_1e68a_row22_col3\" class=\"data row22 col3\" >뤼튼테크놀로지스는 2021년 4월에 설립된 생성 AI 플랫폼 '뤼튼'을 운영하는 기업 비즈니스다. 비상장 상...</td>\n","      <td id=\"T_1e68a_row22_col4\" class=\"data row22 col4\" ></td>\n","      <td id=\"T_1e68a_row22_col5\" class=\"data row22 col5\" >✅</td>\n","      <td id=\"T_1e68a_row22_col6\" class=\"data row22 col6\" ></td>\n","      <td id=\"T_1e68a_row22_col7\" class=\"data row22 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n","      <td id=\"T_1e68a_row23_col0\" class=\"data row23 col0\" >원프레딕트</td>\n","      <td id=\"T_1e68a_row23_col1\" class=\"data row23 col1\" >기업명: 원프레딕트\n","설명: 산업용 AI/IoT 기반 산업설비 상태 예측 및 진단 솔루션을 제공하는 기업\n","상장 여부: 비상장\n","창립일: 2016-10-26\n","웹사이트: onepredic...</td>\n","      <td id=\"T_1e68a_row23_col2\" class=\"data row23 col2\" >회사명: 원프레딕트 (OnePredict)\n","\n","설립연도: 2016년 10월, 서울 강남구\n","\n","비전: “AI 기반 산업설비 예지보전의 글로벌 표준이 되다.”\n","원프레딕트는 산업용 AI 및...</td>\n","      <td id=\"T_1e68a_row23_col3\" class=\"data row23 col3\" >원프레딕트는 2016년 10월에 설립된 산업용 AI/IoT 기반 산업설비 상태 예측 및 진단 솔루션을 제공하...</td>\n","      <td id=\"T_1e68a_row23_col4\" class=\"data row23 col4\" >✅</td>\n","      <td id=\"T_1e68a_row23_col5\" class=\"data row23 col5\" >✅</td>\n","      <td id=\"T_1e68a_row23_col6\" class=\"data row23 col6\" >✅</td>\n","      <td id=\"T_1e68a_row23_col7\" class=\"data row23 col7\" ></td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_1e68a_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n","      <td id=\"T_1e68a_row24_col0\" class=\"data row24 col0\" >엠비아이솔루션</td>\n","      <td id=\"T_1e68a_row24_col1\" class=\"data row24 col1\" >기업명: 엠비아이솔루션\n","설명: 고객상담 챗봇 및 채팅 서비스 '해피톡'을 운영하는 기업\n","상장 여부: 비상장\n","창립일: 2016-02-18\n","웹사이트: happytalk.io\n","주소: 서...</td>\n","      <td id=\"T_1e68a_row24_col2\" class=\"data row24 col2\" >회사명: 엠비아이솔루션 (MBI Solution)\n","\n","설립연도: 2016년 2월, 서울 마포구\n","\n","비전: “모든 비즈니스에 고객과의 더 나은 대화를.”\n","엠비아이솔루션은 고객상담 챗봇 ...</td>\n","      <td id=\"T_1e68a_row24_col3\" class=\"data row24 col3\" >엠비아이솔루션은 2016년 2월에 설립된 고객상담 챗봇 및 채팅 서비스 '해피톡'을 운영하는 기업 비즈니스다...</td>\n","      <td id=\"T_1e68a_row24_col4\" class=\"data row24 col4\" ></td>\n","      <td id=\"T_1e68a_row24_col5\" class=\"data row24 col5\" >✅</td>\n","      <td id=\"T_1e68a_row24_col6\" class=\"data row24 col6\" ></td>\n","      <td id=\"T_1e68a_row24_col7\" class=\"data row24 col7\" ></td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}}],"source":["from IPython.display import display\n","\n","# 설명과 요약을 일정 길이로 축약\n","def shorten(text, max_len=80):\n","    if pd.isna(text):\n","        return \"\"\n","    return text[:max_len] + \"...\" if len(text) > max_len else text\n","\n","df_view = df.copy()\n","df_view['설명'] = df_view['설명'].apply(lambda x: shorten(str(x), 100))\n","df_view['제안서'] = df_view['제안서'].apply(lambda x: shorten(str(x), 100))\n","df_view['요약'] = df_view['요약'].apply(lambda x: shorten(str(x), 60))\n","\n","# 보기 좋은 열 순서 선택\n","selected_columns = [\n","    '회사명', '설명', '제안서', '요약',\n","    '교육', 'AI/딥테크/블록체인', '콘텐츠/예술', '음악'\n","]\n","\n","# 숫자 태그(0, 1)를 \"✅\" or \"\" 로 바꾸기\n","def bool_icon(val):\n","    return \"✅\" if val == 1 else \"\"\n","\n","for col in ['교육', 'AI/딥테크/블록체인', '콘텐츠/예술', '음악']:\n","    if col in df_view.columns:\n","        df_view[col] = df_view[col].apply(bool_icon)\n","\n","# 스타일 지정해서 보기 좋게 표시\n","styled = df_view[selected_columns].style \\\n","    .set_properties(**{'text-align': 'left'}) \\\n","    .set_table_styles([{'selector': 'th', 'props': [('text-align', 'left')]}]) \\\n","    .set_caption(\"스타트업 DB (요약 보기)\")\n","\n","display(styled)"]},{"cell_type":"markdown","metadata":{"id":"1T1szwAiGUzz"},"source":["# Main Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RbZw4HHuGV4N","executionInfo":{"status":"ok","timestamp":1748420176389,"user_tz":-540,"elapsed":334149,"user":{"displayName":"박형진","userId":"05628816051884963880"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5e1f6200-8c41-443a-d42a-892fd04eed6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["초기 스타트업 정보를 간략히 입력하세요: > Company: MediTalk AI >  >  > **Founded:** 2022, Seoul, Korea >  > **Vision:** *\"We want to make hospital appointments easier.\"* >  > **Problem & Product-Market Fit:** >  > Making a hospital appointment is inconvenient, so we built an app that makes it easier. >  > **Competitive Advantage:** >  > Nicely designed app with a large list of hospitals. >  > **Team Competency:** >  > CEO studied computer science. 5 total team members. >  > **Go-to-Market Strategy:** >  > Launch on app stores and hope users download it. >  > **Customer Understanding:** >  > Targeting people who find going to the hospital annoying. >  > **Financial Readiness:** >  > No funding received yet. >  > **Scalability Potential:** >  > Plan to add hospitals nationwide. >  > **Traction & KPIs:** >  > 3,000 downloads, 100 daily active users. >  > **Fundraising Preparedness:** >  > Looking to raise investment. >\n","[generate_business_report] Raw JSON from LLM:\n"," {\n","  \"Clarity of Vision\": {\"score\": 3, \"confidence\": 90},\n","  \"Product-Market Fit\": {\"score\": 3, \"confidence\": 80},\n","  \"Competitive Advantage\": {\"score\": 2, \"confidence\": 70},\n","  \"Team Competency\": {\"score\": 3, \"confidence\": 75},\n","  \"Go-to-Market Strategy\": {\"score\": 2, \"confidence\": 80},\n","  \"Customer Understanding\": {\"score\": 3, \"confidence\": 80},\n","  \"Financial Readiness\": {\"score\": 1, \"confidence\": 95},\n","  \"Scalability Potential\": {\"score\": 3, \"confidence\": 75},\n","  \"Traction & KPIs\": {\"score\": 3, \"confidence\": 85},\n","  \"Fundraising Preparedness\": {\"score\": 2, \"confidence\": 80}\n","}\n","[초기 보고서]\n"," # Startup Diagnostic Report\n","\n","## Introduction\n","MediTalk AI, founded in 2022 in Seoul, Korea, is developing a mobile application designed to simplify hospital appointment scheduling. The startup targets the common inconvenience faced by many in accessing healthcare by providing a user-friendly platform that aggregates a wide selection of hospitals. While initial traction shows promise, the company faces challenges around fundraising, team expansion, and go-to-market strategies as it aims for nationwide scaling.\n","\n","## 3C Analysis\n","\n","### Company\n","MediTalk AI’s founding team consists of five members led by a CEO with a computer science background, providing a solid foundation for technical development. However, the current team size and expertise may need to be broadened to cover business operations, marketing, and strategic partnerships to support scaling efforts. Financial resources are currently limited, posing constraints on growth initiatives.\n","\n","### Competitors\n","The competitive landscape includes traditional hospital appointment systems and emerging digital health platforms. MediTalk AI’s broad hospital network within a single app is a key differentiator, but competitive advantage is modest due to the lack of strong proprietary features or partnerships. Competitors with established marketing channels and funding could pose significant challenges.\n","\n","### Customers\n","The primary customers are individuals who find hospital appointment scheduling cumbersome and inconvenient. The startup has a basic understanding of this segment’s needs but would benefit from deeper insights into user behavior and preferences to tailor product features and marketing messages more effectively. Early user metrics indicate interest but highlight the need for improved engagement and retention.\n","\n","## Criteria Evaluation\n","\n","### Clarity of Vision\n","- Score: 3/5\n","- Confidence: 90%\n","- Rationale: The vision to simplify hospital appointments addresses a clear and relatable pain point, but it could be articulated more distinctly with a long-term strategic perspective.\n","\n","### Product-Market Fit\n","- Score: 3/5\n","- Confidence: 80%\n","- Rationale: The app meets a real user need with a comprehensive hospital list, yet user engagement metrics suggest there is room to better align product features with customer expectations.\n","\n","### Competitive Advantage\n","- Score: 2/5\n","- Confidence: 70%\n","- Rationale: While MediTalk AI offers a wide hospital network, it currently lacks strong differentiators such as exclusive partnerships or unique technology that would secure a sustainable competitive edge.\n","\n","### Team Competency\n","- Score: 3/5\n","- Confidence: 75%\n","- Rationale: The founding team has technical expertise but needs additional skills in marketing, business development, and scaling to fully support growth plans.\n","\n","### Go-to-Market Strategy\n","- Score: 2/5\n","- Confidence: 80%\n","- Rationale: The current reliance on organic app store discovery is insufficient for rapid adoption; proactive marketing and partnership initiatives are needed to accelerate user acquisition.\n","\n","### Customer Understanding\n","- Score: 3/5\n","- Confidence: 80%\n","- Rationale: There is a basic understanding of customer pain points, but deeper insights into user behavior and preferences are necessary to optimize product development and messaging.\n","\n","### Financial Readiness\n","- Score: 1/5\n","- Confidence: 95%\n","- Rationale: MediTalk AI has not yet secured funding, which significantly limits its ability to invest in key growth areas such as marketing, product enhancement, and scaling infrastructure.\n","\n","### Scalability Potential\n","- Score: 3/5\n","- Confidence: 75%\n","- Rationale: The plan to expand hospital coverage nationwide shows promise, but successful scaling will depend on securing financial resources and expanding operational capacity.\n","\n","### Traction & KPIs\n","- Score: 3/5\n","- Confidence: 85%\n","- Rationale: Initial traction with 3,000 downloads and 100 daily active users indicates market interest, though growth and retention must improve to demonstrate sustainable momentum.\n","\n","### Fundraising Preparedness\n","- Score: 2/5\n","- Confidence: 80%\n","- Rationale: The company is exploring fundraising but needs a more detailed business plan, clear growth strategies, and stronger performance data to attract investors effectively.\n","\n","## Conclusion\n","MediTalk AI addresses a genuine and widespread problem with a straightforward, accessible solution. The startup has laid a solid foundation with its technical team and initial user traction. To progress effectively, MediTalk AI should prioritize strengthening its go-to-market strategy, deepening customer insights, expanding team capabilities, and securing necessary funding. These steps will be critical to unlocking scalability potential and achieving sustained growth in the competitive healthcare technology landscape.\n","\n","## Relevant References\n","- **User Input #1**: Provides comprehensive foundational information on MediTalk AI’s founding, vision, product-market fit, competitive advantages, team composition, go-to-market strategy, customer understanding, financial status, scalability plans, traction metrics, and fundraising preparedness. This single reference is fully relevant as it supplies all critical details necessary to understand and support the final report’s content.\n","\n","=== [Iteration 1] ===\n","\n","===== 현재 스타트업 진단 보고서 =====\n","1. Clarity of Vision: 3 / 5점 (Confidence: 90%)\n","2. Product-Market Fit: 3 / 5점 (Confidence: 80%)\n","3. Competitive Advantage: 2 / 5점 (Confidence: 70%)\n","4. Team Competency: 3 / 5점 (Confidence: 75%)\n","5. Go-to-Market Strategy: 2 / 5점 (Confidence: 80%)\n","6. Customer Understanding: 3 / 5점 (Confidence: 80%)\n","7. Financial Readiness: 1 / 5점 (Confidence: 95%)\n","8. Scalability Potential: 3 / 5점 (Confidence: 75%)\n","9. Traction & KPIs: 3 / 5점 (Confidence: 85%)\n","10. Fundraising Preparedness: 2 / 5점 (Confidence: 80%)\n","==================================\n","\n","[ask_llm_for_next_action] Raw LLM Output:\n"," {\n","  \"criterion\": \"Financial Readiness\",\n","  \"action\": \"AskUser\",\n","  \"rationale\": \"Financial Readiness is the lowest scoring criterion with high confidence, indicating a critical gap; more details on funding plans or financial strategy are needed to improve this area.\"\n","}\n","[LLM 결정] 다음에 집중할 항목: Financial Readiness\n","[LLM 결정] 선택된 액션: AskUser\n","[LLM 결정] 사유(rationale): Financial Readiness is the lowest scoring criterion with high confidence, indicating a critical gap; more details on funding plans or financial strategy are needed to improve this area.\n","\n","[LLM Generated Questions]\n","- What is your current monthly burn rate and runway (how many months can you operate without funding)?  \n","- Have you prepared detailed financial projections for the next 12-24 months (revenue, expenses, cash flow)?  \n","- What is your expected funding requirement, and how will the raised capital be allocated?  \n","- Do you have any revenue streams currently, or plans to monetize the app soon?  \n","- Have you considered potential financial risks or contingency plans if initial growth is slower than expected?  \n","- Are there any existing financial partnerships, grants, or loans aside from equity funding?\n","\n","아래 질문에 대한 답을 입력해주세요.\n","Your Answer: i dont know..\n","[Action 결과] USER_INPUT: (User Provided Info about Financial Readiness)\n","Questions:\n","- What is your current monthly burn rate and runway (how many months can you operate without funding)?  \n","- Have you prepared detailed financial projections for the next 12-24 months (revenue, expenses, cash flow)?  \n","- What is your expected funding requirement, and how will the raised capital be allocated?  \n","- Do you have any revenue streams currently, or plans to monetize the app soon?  \n","- Have you considered potential financial risks or contingency plans if initial growth is slower than expected?  \n","- Are there any existing financial partnerships, grants, or loans aside from equity funding?\n","User's Answer:\n","i dont know..\n","[generate_business_report] Raw JSON from LLM:\n"," {\n","  \"Clarity of Vision\": {\"score\": 3, \"confidence\": 80},\n","  \"Product-Market Fit\": {\"score\": 3, \"confidence\": 70},\n","  \"Competitive Advantage\": {\"score\": 2, \"confidence\": 70},\n","  \"Team Competency\": {\"score\": 3, \"confidence\": 75},\n","  \"Go-to-Market Strategy\": {\"score\": 2, \"confidence\": 60},\n","  \"Customer Understanding\": {\"score\": 3, \"confidence\": 70},\n","  \"Financial Readiness\": {\"score\": 1, \"confidence\": 90},\n","  \"Scalability Potential\": {\"score\": 3, \"confidence\": 70},\n","  \"Traction & KPIs\": {\"score\": 3, \"confidence\": 75},\n","  \"Fundraising Preparedness\": {\"score\": 2, \"confidence\": 60}\n","}\n","[LLM 최종 보고서(마크다운)]\n"," # Startup Diagnostic Report\n","\n","## Introduction\n","MediTalk AI is a Seoul-based startup founded in 2022 with a clear vision to simplify hospital appointment scheduling via a user-friendly app. The company has identified a genuine pain point among users and achieved early traction with 3,000 downloads and 100 daily active users. While the product demonstrates reasonable market fit and scalability potential, the startup faces challenges in financial readiness, competitive advantage, and go-to-market execution that must be addressed to sustain growth.\n","\n","## 3C Analysis\n","\n","### Company\n","The founding team comprises five members, including a CEO with a computer science background, which supports product development. However, the team currently lacks depth in marketing, finance, and strategic partnerships, which are critical for scaling. Resources are focused on app development and hospital listings, but financial planning and fundraising preparedness remain weak. The company culture appears focused and mission-driven but would benefit from expanded competencies.\n","\n","### Competitors\n","MediTalk AI operates in a competitive market with several players offering similar hospital appointment solutions. Its moderate competitive advantage stems from a well-designed interface and comprehensive hospital coverage, but these factors are not sufficiently differentiated. The reliance on organic discovery limits visibility, and more aggressive or innovative marketing approaches are needed to establish a stronger market position.\n","\n","### Customers\n","The target segment includes users who find hospital visits inconvenient and cumbersome. The startup has a solid understanding of this pain point and has tailored its app accordingly. However, deeper insights into user behavior and preferences could enhance user engagement and retention. Current user metrics indicate initial validation but also highlight the need for improved customer acquisition and loyalty strategies.\n","\n","## Criteria Evaluation\n","\n","### Clarity of Vision\n","- Score: 3/5  \n","- Confidence: 80%  \n","- Rationale: The startup has a clear and focused vision centered on simplifying hospital appointments, which resonates with a real user need.\n","\n","### Product-Market Fit\n","- Score: 3/5  \n","- Confidence: 70%  \n","- Rationale: The product addresses a genuine pain point with early traction validating demand, though ongoing refinement is required for wider adoption.\n","\n","### Competitive Advantage\n","- Score: 2/5  \n","- Confidence: 70%  \n","- Rationale: While the app’s design and hospital coverage provide some differentiation, competition is strong and the advantage is moderate rather than distinct.\n","\n","### Team Competency\n","- Score: 3/5  \n","- Confidence: 75%  \n","- Rationale: The founding team has technical strength but lacks broader expertise in marketing, finance, and partnerships needed to scale.\n","\n","### Go-to-Market Strategy\n","- Score: 2/5  \n","- Confidence: 60%  \n","- Rationale: Current reliance on organic app store discovery limits growth potential; a more proactive marketing plan is necessary.\n","\n","### Customer Understanding\n","- Score: 3/5  \n","- Confidence: 70%  \n","- Rationale: The team understands the core user pain point but would benefit from deeper behavioral insights to enhance product and marketing effectiveness.\n","\n","### Financial Readiness\n","- Score: 1/5  \n","- Confidence: 90%  \n","- Rationale: Lack of fundraising, financial projections, and monetization strategy poses significant risk to sustainability and growth.\n","\n","### Scalability Potential\n","- Score: 3/5  \n","- Confidence: 70%  \n","- Rationale: Plans to expand hospital listings nationwide align well with core value proposition and show promise for growth once foundational issues are resolved.\n","\n","### Traction & KPIs\n","- Score: 3/5  \n","- Confidence: 75%  \n","- Rationale: Early traction with downloads and daily users is encouraging but KPIs indicate room for improvement in engagement and retention.\n","\n","### Fundraising Preparedness\n","- Score: 2/5  \n","- Confidence: 60%  \n","- Rationale: Limited fundraising efforts and unclear financial strategy reduce readiness to attract investors and support scaling initiatives.\n","\n","## Conclusion\n","MediTalk AI presents a compelling value proposition with a clear vision and a product addressing real user needs. Early market validation through downloads and active users is promising. However, to advance, the startup must strengthen its competitive positioning by developing a more aggressive go-to-market strategy and expanding team expertise in critical areas such as marketing and finance. Most urgently, MediTalk AI needs to establish comprehensive financial planning and fundraising preparedness to ensure operational sustainability and enable scalable growth. Addressing these key gaps will position the company for successful expansion and increased market penetration.\n","\n","## Relevant References\n","- **User Input #1:** This source provides the core information on MediTalk AI’s founding, vision, product-market fit, team composition, competitive advantage, go-to-market strategy, customer understanding, scalability plans, traction metrics, and fundraising intentions. It forms the foundational data supporting all key points in the report.\n","\n","- **User Input #2:** The detailed financial readiness questions and the startup’s inability to provide clear answers highlight the financial challenges and risks discussed in the report, supporting the need for improved financial planning and fundraising preparedness.\n","\n","=== [Iteration 2] ===\n","\n","===== 현재 스타트업 진단 보고서 =====\n","1. Clarity of Vision: 3 / 5점 (Confidence: 80%)\n","2. Product-Market Fit: 3 / 5점 (Confidence: 70%)\n","3. Competitive Advantage: 2 / 5점 (Confidence: 70%)\n","4. Team Competency: 3 / 5점 (Confidence: 75%)\n","5. Go-to-Market Strategy: 2 / 5점 (Confidence: 60%)\n","6. Customer Understanding: 3 / 5점 (Confidence: 70%)\n","7. Financial Readiness: 1 / 5점 (Confidence: 90%)\n","8. Scalability Potential: 3 / 5점 (Confidence: 70%)\n","9. Traction & KPIs: 3 / 5점 (Confidence: 75%)\n","10. Fundraising Preparedness: 2 / 5점 (Confidence: 60%)\n","==================================\n","\n","[ask_llm_for_next_action] Raw LLM Output:\n"," {\n","  \"criterion\": \"Financial Readiness\",\n","  \"action\": \"AskUser\",\n","  \"rationale\": \"Financial Readiness remains the lowest scoring criterion with high confidence, and the user lacks detailed financial information, so further specific financial details are needed to improve this critical area.\"\n","}\n","[LLM 결정] 다음에 집중할 항목: Financial Readiness\n","[LLM 결정] 선택된 액션: AskUser\n","[LLM 결정] 사유(rationale): Financial Readiness remains the lowest scoring criterion with high confidence, and the user lacks detailed financial information, so further specific financial details are needed to improve this critical area.\n","\n","[LLM Generated Questions]\n","- Can you estimate your current monthly expenses, including salaries, development costs, marketing, and other operational costs?  \n","- How many months can your current cash reserves cover these expenses without any new income?  \n","- Have you attempted to create a simple budget or financial plan outlining expected costs and revenues over the next year?  \n","- How much money do you think you would need to raise to sustain and grow the business for at least the next 12 months?  \n","- What percentage of the raised funds do you plan to use for product development, marketing, hiring, or other specific areas?  \n","- Are you currently generating any income from the app or have plans to introduce paid features or advertising soon?  \n","- Have you identified any risks that could increase your costs or delay revenue, and do you have ideas to manage these risks financially?  \n","- Do you have any agreements or discussions with potential investors, partners, or lenders regarding financial support?\n","\n","아래 질문에 대한 답을 입력해주세요.\n","Your Answer: i do not know please teach me example of startup\n","[Action 결과] USER_INPUT: (User Provided Info about Financial Readiness)\n","Questions:\n","- Can you estimate your current monthly expenses, including salaries, development costs, marketing, and other operational costs?  \n","- How many months can your current cash reserves cover these expenses without any new income?  \n","- Have you attempted to create a simple budget or financial plan outlining expected costs and revenues over the next year?  \n","- How much money do you think you would need to raise to sustain and grow the business for at least the next 12 months?  \n","- What percentage of the raised funds do you plan to use for product development, marketing, hiring, or other specific areas?  \n","- Are you currently generating any income from the app or have plans to introduce paid features or advertising soon?  \n","- Have you identified any risks that could increase your costs or delay revenue, and do you have ideas to manage these risks financially?  \n","- Do you have any agreements or discussions with potential investors, partners, or lenders regarding financial support?\n","User's Answer:\n","i do not know please teach me example of startup\n","[generate_business_report] Raw JSON from LLM:\n"," {\n","  \"Clarity of Vision\": {\"score\": 3, \"confidence\": 80},\n","  \"Product-Market Fit\": {\"score\": 3, \"confidence\": 75},\n","  \"Competitive Advantage\": {\"score\": 3, \"confidence\": 70},\n","  \"Team Competency\": {\"score\": 3, \"confidence\": 70},\n","  \"Go-to-Market Strategy\": {\"score\": 2, \"confidence\": 60},\n","  \"Customer Understanding\": {\"score\": 3, \"confidence\": 70},\n","  \"Financial Readiness\": {\"score\": 1, \"confidence\": 90},\n","  \"Scalability Potential\": {\"score\": 3, \"confidence\": 70},\n","  \"Traction & KPIs\": {\"score\": 3, \"confidence\": 75},\n","  \"Fundraising Preparedness\": {\"score\": 1, \"confidence\": 90}\n","}\n","[LLM 최종 보고서(마크다운)]\n"," # Startup Diagnostic Report\n","\n","## Introduction\n","MediTalk AI is an emerging startup focused on simplifying hospital appointment scheduling, a common pain point for many users. The product has achieved moderate early traction with 3,000 downloads and 100 daily active users. While the vision is clear and the core team competent, the company faces challenges in financial readiness, go-to-market strategy, and competitive differentiation that must be addressed to scale successfully and attract investment.\n","\n","## 3C Analysis\n","\n","### Company\n","MediTalk AI is led by a small team of five members, including a CEO with a computer science background. The team demonstrates adequate competency to develop and maintain the product but may need to expand or bring in additional skills to accelerate growth, marketing, and financial planning. Resources are currently limited, particularly in financial management and fundraising preparedness, which are critical areas for the startup’s next phase.\n","\n","### Competitors\n","The competitive landscape includes other hospital appointment booking solutions, some of which may offer similar features. MediTalk AI’s main competitive advantage lies in its user-friendly design and comprehensive hospital listings. However, this advantage is moderate and at risk as competitors enhance their offerings or new entrants join the market. Strengthening differentiation and establishing strategic partnerships will be important to maintain a competitive edge.\n","\n","### Customers\n","The target customer segment includes individuals who find hospital visits and appointment scheduling inconvenient. The startup shows a reasonable understanding of this segment, but deeper user research and segmentation could improve product-market fit and marketing effectiveness. Early user adoption indicates a product-market fit at a moderate level, with potential to grow if the team better leverages customer insights.\n","\n","## Criteria Evaluation\n","\n","### Clarity of Vision\n","- Score: 3/5\n","- Confidence: 80%\n","- Rationale: The startup has a clear and focused vision to simplify hospital appointment processes, which addresses a real user pain point.\n","\n","### Product-Market Fit\n","- Score: 3/5\n","- Confidence: 75%\n","- Rationale: Early traction with 3,000 downloads and 100 daily active users suggests a moderate product-market fit, though further validation and refinement are needed.\n","\n","### Competitive Advantage\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The app’s user-friendly design and comprehensive hospital listings provide a solid but not strong differentiation in a potentially competitive space.\n","\n","### Team Competency\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The small team has relevant technical skills and leadership, but may require additional expertise, especially in marketing and financial management.\n","\n","### Go-to-Market Strategy\n","- Score: 2/5\n","- Confidence: 60%\n","- Rationale: Current strategy relies heavily on app store presence without targeted marketing or user acquisition plans, limiting growth potential.\n","\n","### Customer Understanding\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The startup understands its core user segment but would benefit from deeper research and segmentation to tailor features and messaging.\n","\n","### Financial Readiness\n","- Score: 1/5\n","- Confidence: 90%\n","- Rationale: There is a critical lack of financial planning, with unclear burn rate, runway, projections, and no monetization strategy in place.\n","\n","### Scalability Potential\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: Plans to expand hospital coverage nationwide indicate scalability potential, but this requires operational capacity and partnerships.\n","\n","### Traction & KPIs\n","- Score: 3/5\n","- Confidence: 75%\n","- Rationale: Early traction metrics such as downloads and active users are promising but need to improve through enhanced marketing and engagement.\n","\n","### Fundraising Preparedness\n","- Score: 1/5\n","- Confidence: 90%\n","- Rationale: Fundraising plans are limited and lack detailed strategy beyond seeking investment, requiring urgent development to attract investors.\n","\n","## Conclusion\n","MediTalk AI has established a meaningful vision and demonstrated early product validation with moderate traction. However, critical gaps exist in financial readiness and fundraising preparedness, which pose risks to sustainable growth. The go-to-market strategy needs significant refinement with targeted marketing efforts to boost user acquisition and retention. Additionally, building a more robust competitive advantage through differentiation and partnerships is essential to withstand market challenges.\n","\n","Next steps should focus on developing a comprehensive financial plan including budgets, forecasts, and defined funding needs. Enhancing market research and customer segmentation will improve product-market fit and marketing effectiveness. Strengthening the team with skills in marketing and finance, alongside refining the go-to-market approach, will support scaling efforts and increase investor confidence. Addressing these areas will position MediTalk AI for sustainable growth and successful fundraising.\n","\n","## Relevant References\n","- **User Input #1:** This comprehensive initial company profile provides the foundational details on MediTalk AI’s vision, product-market fit, team, competitive advantage, go-to-market strategy, customer understanding, scalability, traction, and fundraising preparedness, directly supporting all sections of the report.\n","\n","- **User Input #2:** The financial readiness questions and the founder’s admitted lack of knowledge highlight critical gaps in financial planning and preparedness, reinforcing the report’s emphasis on the need for detailed financial projections, budgeting, and funding strategies.\n","\n","- **User Input #3:** Further probing on financial metrics and the founder’s request for examples of startup financial planning exemplify the current financial unpreparedness and underscore the recommendation for developing financial literacy, budgeting, and risk management practices in the report.\n","\n","=== [Iteration 3] ===\n","\n","===== 현재 스타트업 진단 보고서 =====\n","1. Clarity of Vision: 3 / 5점 (Confidence: 80%)\n","2. Product-Market Fit: 3 / 5점 (Confidence: 75%)\n","3. Competitive Advantage: 3 / 5점 (Confidence: 70%)\n","4. Team Competency: 3 / 5점 (Confidence: 70%)\n","5. Go-to-Market Strategy: 2 / 5점 (Confidence: 60%)\n","6. Customer Understanding: 3 / 5점 (Confidence: 70%)\n","7. Financial Readiness: 1 / 5점 (Confidence: 90%)\n","8. Scalability Potential: 3 / 5점 (Confidence: 70%)\n","9. Traction & KPIs: 3 / 5점 (Confidence: 75%)\n","10. Fundraising Preparedness: 1 / 5점 (Confidence: 90%)\n","==================================\n","\n","[ask_llm_for_next_action] Raw LLM Output:\n"," {\n","  \"criterion\": \"Financial Readiness\",\n","  \"action\": \"SearchDB_startup\",\n","  \"rationale\": \"User lacks financial knowledge and requests examples of startups; providing real-world startup financial examples will help improve understanding and address the critical Financial Readiness gap.\"\n","}\n","[LLM 결정] 다음에 집중할 항목: Financial Readiness\n","[LLM 결정] 선택된 액션: SearchDB_startup\n","[LLM 결정] 사유(rationale): User lacks financial knowledge and requests examples of startups; providing real-world startup financial examples will help improve understanding and address the critical Financial Readiness gap.\n","[Action 결과] DB_SUMMARY: [DB 검색 결과 - startup] '\"financial readiness\" AND (\"startup example\" OR \"startup case study\") AND (\"monthly burn rate\" OR \"financial projections\" OR \"funding requirements\" OR \"revenue streams\" OR \"financial risks\" OR \"financial planning\") AND Korea AND startup' 관련 문서가 없습니다.\n","[generate_business_report] Raw JSON from LLM:\n"," {\n","  \"Clarity of Vision\": {\"score\": 3, \"confidence\": 80},\n","  \"Product-Market Fit\": {\"score\": 3, \"confidence\": 70},\n","  \"Competitive Advantage\": {\"score\": 3, \"confidence\": 70},\n","  \"Team Competency\": {\"score\": 3, \"confidence\": 70},\n","  \"Go-to-Market Strategy\": {\"score\": 2, \"confidence\": 60},\n","  \"Customer Understanding\": {\"score\": 3, \"confidence\": 70},\n","  \"Financial Readiness\": {\"score\": 1, \"confidence\": 90},\n","  \"Scalability Potential\": {\"score\": 3, \"confidence\": 70},\n","  \"Traction & KPIs\": {\"score\": 3, \"confidence\": 80},\n","  \"Fundraising Preparedness\": {\"score\": 1, \"confidence\": 90}\n","}\n","[LLM 최종 보고서(마크다운)]\n"," # Startup Diagnostic Report\n","\n","## Introduction\n","MediTalk AI is at a pivotal stage in its development, showing a solid foundation with a clear vision and promising early traction. The startup is addressing a practical problem—simplifying hospital appointment scheduling—and has begun to gain initial user interest. However, critical gaps in financial readiness and go-to-market strategy must be addressed to ensure sustainable growth and successful fundraising.\n","\n","## 3C Analysis\n","\n","### Company\n","MediTalk AI benefits from a competent team with moderate expertise, a focused vision, and a scalable product concept. The culture appears aligned around solving a clear user problem with a straightforward app. However, the company currently lacks robust financial planning and a comprehensive go-to-market strategy, which are essential for operational sustainability and expansion.\n","\n","### Competitors\n","The competitive landscape in healthcare scheduling apps is moderately crowded, with several players offering partial solutions. MediTalk AI holds a competitive advantage by aiming for simplicity and user-friendly design, but this advantage is not yet fully leveraged due to limited marketing efforts and financial resources. Strengthening these areas will be key to standing out.\n","\n","### Customers\n","Target customers are hospital patients who require efficient appointment scheduling. User needs center around convenience, reliability, and time-saving features. The current user base of 3,000 downloads and 100 daily active users indicates initial product-market fit, but deeper customer understanding and engagement strategies are necessary to drive growth and loyalty.\n","\n","## Criteria Evaluation\n","\n","### Clarity of Vision\n","- Score: 3/5\n","- Confidence: 80%\n","- Rationale:\n","  MediTalk AI has a clearly defined mission to simplify hospital appointment scheduling, which resonates with a tangible user problem. The vision is understandable but could benefit from further refinement and communication to stakeholders.\n","\n","### Product-Market Fit\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale:\n","  The product shows moderate alignment with market needs, demonstrated by initial user adoption rates. However, more validation and feedback loops are needed to deepen fit and expand the user base.\n","\n","### Competitive Advantage\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale:\n","  MediTalk AI’s focus on user-friendly scheduling provides a competitive edge, but this advantage is not fully exploited due to limited differentiation efforts and marketing.\n","\n","### Team Competency\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale:\n","  The team possesses adequate skills to develop and maintain the product but requires enhancement in areas such as financial management and strategic marketing.\n","\n","### Go-to-Market Strategy\n","- Score: 2/5\n","- Confidence: 60%\n","- Rationale:\n","  The current strategy relies mainly on app store presence, lacking proactive marketing, partnerships, or user acquisition plans. This limits growth potential and market penetration.\n","\n","### Customer Understanding\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale:\n","  The startup has identified key customer segments and needs but should deepen insights through data analytics, user interviews, and engagement to tailor offerings better.\n","\n","### Financial Readiness\n","- Score: 1/5\n","- Confidence: 90%\n","- Rationale:\n","  There is a critical lack of clarity around financial metrics such as burn rate, runway, and projections. This poses a significant risk to sustainability and investor confidence.\n","\n","### Scalability Potential\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale:\n","  The app’s digital nature and service model have inherent scalability, but execution depends on improved marketing, financial planning, and operational resources.\n","\n","### Traction & KPIs\n","- Score: 3/5\n","- Confidence: 80%\n","- Rationale:\n","  Early traction indicators, including downloads and daily active users, are promising but require acceleration through targeted growth strategies.\n","\n","### Fundraising Preparedness\n","- Score: 1/5\n","- Confidence: 90%\n","- Rationale:\n","  The absence of detailed financial plans, funding requirements, and monetization strategies severely limits fundraising capabilities and investor appeal.\n","\n","## Conclusion\n","MediTalk AI demonstrates a promising vision and initial market traction within a clear problem space. However, the startup faces significant challenges in financial management and go-to-market execution. Addressing these areas by developing a comprehensive financial plan, including burn rate estimates, runway calculations, and detailed projections, alongside a proactive marketing and user acquisition strategy, is essential. These steps will enhance operational sustainability and improve readiness for fundraising, positioning MediTalk AI for scalable growth and competitive success. Immediate focus on these priorities will be critical for the next phase of development.\n","\n","## Relevant References\n","- **User Input #1:** Provides comprehensive foundational details about MediTalk AI’s vision, product-market fit, competitive advantage, team competency, go-to-market strategy, customer understanding, scalability potential, traction, and fundraising preparedness.  \n","  *Relevance:* This input forms the core factual basis for the business readiness assessment and supports all key points made in the report.\n","\n","- **User Input #2:** Contains targeted questions about financial readiness and fundraising preparedness with the founder’s responses indicating lack of knowledge.  \n","  *Relevance:* Directly highlights the critical gap in financial understanding and preparedness, underpinning the report’s emphasis on urgent need for financial planning.\n","\n","- **User Input #3:** Further probes on financial specifics and requests startup examples, again showing the founder’s need for guidance on financial metrics and planning.  \n","  *Relevance:* Supports the recommendation for teaching basic financial planning and illustrates the founder’s current limitations, reinforcing the report’s financial readiness findings.\n","\n","- **DB Ref #1:** Search result showing no relevant documents found on financial readiness for Korean startups.  \n","  *Relevance:* Confirms the absence of external case studies or examples, justifying the need for basic financial instruction within the report rather than relying on external references.\n","\n","=== [Iteration 4] ===\n","\n","===== 현재 스타트업 진단 보고서 =====\n","1. Clarity of Vision: 3 / 5점 (Confidence: 80%)\n","2. Product-Market Fit: 3 / 5점 (Confidence: 70%)\n","3. Competitive Advantage: 3 / 5점 (Confidence: 70%)\n","4. Team Competency: 3 / 5점 (Confidence: 70%)\n","5. Go-to-Market Strategy: 2 / 5점 (Confidence: 60%)\n","6. Customer Understanding: 3 / 5점 (Confidence: 70%)\n","7. Financial Readiness: 1 / 5점 (Confidence: 90%)\n","8. Scalability Potential: 3 / 5점 (Confidence: 70%)\n","9. Traction & KPIs: 3 / 5점 (Confidence: 80%)\n","10. Fundraising Preparedness: 1 / 5점 (Confidence: 90%)\n","==================================\n","\n","[ask_llm_for_next_action] Raw LLM Output:\n"," {\n","  \"criterion\": \"Financial Readiness\",\n","  \"action\": \"SearchInternet\",\n","  \"rationale\": \"No relevant startup financial examples found in the database, so searching the internet for real-world Korean startup financial readiness examples will help provide the user with concrete examples to improve understanding.\"\n","}\n","[LLM 결정] 다음에 집중할 항목: Financial Readiness\n","[LLM 결정] 선택된 액션: SearchInternet\n","[LLM 결정] 사유(rationale): No relevant startup financial examples found in the database, so searching the internet for real-world Korean startup financial readiness examples will help provide the user with concrete examples to improve understanding.\n","[Action 결과] INTERNET_SUMMARY: (Internet Search Query: 'startup financial readiness example monthly burn rate financial projections funding requirements revenue streams financial risks financial planning')\n","{'query': 'startup financial readiness example monthly burn rate financial projections funding requirements revenue streams financial risks financial planning', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'How to Calculate Burn Rate for Your Startup | TRUiC - Startup Savant', 'url': 'https://startupsavant.com/startup-finance/how-to-calculate-burn-rate', 'content': \"Burn Rate Example. Let's say a startup just secured $1 million in seed funding. Their projections show: Monthly operating expenses: $80,000. Projected timeline to break even or reach positive cash flow: 14 months; To calculate the startup's burn rate, we take the monthly operating expenses and divide it by the projected months to break even:\", 'score': 0.6227582, 'raw_content': None}, {'title': 'Financial Analysis for Startups: Financial KPIs and Examples', 'url': 'https://fiscra.com/financial-analysis-for-startups', 'content': \"Burn Rate measures the rate at which a startup expends its venture capital before generating a positive cash flow. It indicates the startup's cash consumption rate and is critical for assessing financial sustainability. Example Calculation: If a startup has monthly operational costs of $50,000, its burn rate is $50,000 per month. 2.\", 'score': 0.6139086, 'raw_content': None}, {'title': 'Financial Forecasting for Startups: A Step-by-Step Guide - Fuel Finance', 'url': 'https://fuelfinance.me/blog/financial-forecasting-for-startups/', 'content': 'What is financial forecasting for startups? Financial forecasting predicts the upcoming cash flow your startup needs to handle its operating costs. Startup financial projections: How can they help you? Financial forecasting is an ongoing process that requires startups to review and update their projections as new information emerges regularly. How to make financial forecasts for startups easier Financial forecasting for startups can be entirely automated and well-organized by integrating real-time financial data, using AI projections and eliminating manual spreadsheet updates. A financial projection example is predicting a startup’s future net income and expenses, typically using past financial data and market trends to estimate the financial future. How to do a simple financial forecast for a startup business owner?', 'score': 0.4718322, 'raw_content': None}, {'title': 'Estimating Funding Requirements in Financial Projections', 'url': 'https://fastercapital.com/content/Estimating-Funding-Requirements-in-Financial-Projections.html', 'content': '5. Projecting Operating Expenses and Cash Flow. projecting operating expenses and cash flow is a critical component of any financial projection, as it directly impacts the funding requirements of a business.This process involves estimating both the costs associated with running the business and the timing of cash inflows and outflows. A thorough understanding of operating expenses and cash', 'score': 0.29477343, 'raw_content': None}, {'title': 'How to Create Financial Projections for Startups', 'url': 'https://www.efinancialmodels.com/knowledge-base/planning/financial-plan/how-to-create-financial-projections-for-startups/', 'content': 'Financial modeling spreadsheets and templates in Excel & Google Sheets Latest Financial Modeling Excel Templates Startup Financial Model Financial Modeling Financial Modeling by Financial Models Hotel Financial Model Excel Template SaaS Startup Financial Model – Enterprise and User *   \\xa0Excel Financial Model - Standard Version\\xa0–\\xa0$99.00 Version 2 *   \\xa0Excel Financial Model - Premium Version\\xa0–\\xa0$149.00 Version 2 *   \\xa0Excel Financial Model\\xa0–\\xa0$149.00 Version 1 Subscription Business – 10 Year Financial Model *   \\xa0Excel Financial Model\\xa0–\\xa0$129.00 Version 1 Bundle – Business Financial Forecasting Models *   \\xa0Financial Model - Standard Version\\xa0–\\xa0$99.00 Version 1 *   \\xa0Financial Model - Premium Version\\xa0–\\xa0$129.00 Version 1 B2C Financial Model Excel Template Metal Mining Business Financial Model Excel Template', 'score': 0.24558719, 'raw_content': None}], 'response_time': 5.16}\n","[generate_business_report] Raw JSON from LLM:\n"," {\n","  \"Clarity of Vision\": {\"score\": 3, \"confidence\": 80},\n","  \"Product-Market Fit\": {\"score\": 3, \"confidence\": 75},\n","  \"Competitive Advantage\": {\"score\": 3, \"confidence\": 70},\n","  \"Team Competency\": {\"score\": 3, \"confidence\": 70},\n","  \"Go-to-Market Strategy\": {\"score\": 2, \"confidence\": 60},\n","  \"Customer Understanding\": {\"score\": 3, \"confidence\": 70},\n","  \"Financial Readiness\": {\"score\": 1, \"confidence\": 90},\n","  \"Scalability Potential\": {\"score\": 3, \"confidence\": 70},\n","  \"Traction & KPIs\": {\"score\": 3, \"confidence\": 75},\n","  \"Fundraising Preparedness\": {\"score\": 1, \"confidence\": 90}\n","}\n","[LLM 최종 보고서(마크다운)]\n"," # Startup Diagnostic Report\n","\n","## Introduction\n","MediTalk AI, founded in 2022 in Seoul, is focused on simplifying the hospital appointment process through an easy-to-use mobile application. The startup demonstrates a clear vision and early product-market fit by addressing a common patient pain point. While initial traction shows promise, critical gaps remain in the go-to-market strategy and financial readiness, which are essential for sustainable growth and fundraising preparedness.\n","\n","## 3C Analysis\n","\n","### Company\n","MediTalk AI is led by a CEO with a computer science background and supported by a small team of five members. The team shows moderate competency suitable for early-stage development. Resources are currently limited, and the company culture appears focused on user convenience and scalability. However, there is a need to enhance financial planning capabilities and strategic marketing execution to support growth.\n","\n","### Competitors\n","The competitive landscape includes various healthcare and hospital appointment apps. MediTalk AI’s competitive advantage lies in its user-friendly design and comprehensive hospital listings, positioning it well for nationwide scalability. Nonetheless, competitors with more aggressive marketing strategies and stronger financial backing may pose challenges. Differentiation through enhanced features and targeted outreach will be crucial.\n","\n","### Customers\n","The primary target segment includes individuals who find hospital visits inconvenient and seek a streamlined appointment process. Customer understanding is moderate, with a focus on general user needs but limited segmentation or deep user insights. Further research and segmentation could help refine product messaging and feature development to better match user expectations.\n","\n","## Criteria Evaluation\n","\n","### Clarity of Vision\n","- Score: 3/5\n","- Confidence: 80%\n","- Rationale: The startup has a clear mission to improve patient convenience by simplifying hospital appointments. This vision aligns well with their product offering and future scalability goals.\n","\n","### Product-Market Fit\n","- Score: 3/5\n","- Confidence: 75%\n","- Rationale: MediTalk AI addresses a widespread pain point with an easy-to-use app, evidenced by early user adoption. However, more validation and user feedback are needed to solidify fit.\n","\n","### Competitive Advantage\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The app’s comprehensive hospital database and user-friendly interface provide differentiation, but more distinctive features and stronger market positioning could enhance advantage.\n","\n","### Team Competency\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The founding team, led by a technically proficient CEO, shows adequate skills for early development but would benefit from additional expertise in marketing and financial management.\n","\n","### Go-to-Market Strategy\n","- Score: 2/5\n","- Confidence: 60%\n","- Rationale: The strategy relies mainly on organic app store discovery without targeted marketing or user acquisition plans, limiting growth potential and market penetration.\n","\n","### Customer Understanding\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The team understands the general needs of users seeking easier hospital appointments but lacks deeper segmentation and structured user research to tailor the product further.\n","\n","### Financial Readiness\n","- Score: 1/5\n","- Confidence: 90%\n","- Rationale: There is a significant gap in financial planning, with unclear burn rate, runway, and projections. This lack of financial insight hinders operational sustainability and investment appeal.\n","\n","### Scalability Potential\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The app’s design and hospital coverage support nationwide expansion, though scaling will require stronger marketing and financial frameworks.\n","\n","### Traction & KPIs\n","- Score: 3/5\n","- Confidence: 75%\n","- Rationale: Early traction includes 3,000 downloads and 100 daily active users, indicating initial market interest but requiring growth acceleration.\n","\n","### Fundraising Preparedness\n","- Score: 1/5\n","- Confidence: 90%\n","- Rationale: The absence of a financial roadmap and contingency plans significantly impairs fundraising readiness, necessitating immediate improvements in financial strategy.\n","\n","## Conclusion\n","MediTalk AI shows promising potential with a clear vision and an app that addresses a genuine user problem, supported by early traction. However, to progress effectively, the startup must prioritize developing a robust go-to-market strategy and establish solid financial planning and management practices. Enhancing these areas will improve their fundraising preparedness, enable sustainable scaling, and strengthen competitive positioning in the healthcare app market. Immediate next steps include conducting deeper customer segmentation, building targeted marketing initiatives, and creating detailed financial projections and burn rate analyses.\n","\n","## Relevant References\n","- User Input #1: Provides detailed foundational information about MediTalk AI’s founding, vision, product-market fit, team competency, go-to-market strategy, traction, scalability plan, and fundraising status. This is directly relevant to understand the startup’s current state and challenges.\n","\n","- User Input #2 & #3: Contain the user's explicit responses indicating lack of financial readiness and understanding, highlighting the gaps in burn rate knowledge, financial projections, funding requirements, and risk planning. These inputs support the report’s emphasis on MediTalk AI’s financial planning deficiencies and need for guidance.\n","\n","- Internet Reference #1 (\"How to Calculate Burn Rate for Your Startup | TRUiC - Startup Savant\"): Offers a clear example of calculating burn rate and projecting cash flow timelines, which directly addresses MediTalk AI’s need to estimate monthly expenses and runway.\n","\n","- Internet Reference #2 (\"Financial Analysis for Startups: Financial KPIs and Examples\"): Explains burn rate and its importance for startup sustainability, reinforcing the report’s recommendation for MediTalk AI to understand and monitor their cash consumption.\n","\n","- Internet Reference #3 (\"Financial Forecasting for Startups: A Step-by-Step Guide - Fuel Finance\"): Provides practical guidance on creating and updating financial forecasts, relevant for MediTalk AI’s need to develop detailed financial projections and planning.\n","\n","- Internet Reference #4 (\"Estimating Funding Requirements in Financial Projections\"): Discusses projecting operating expenses and cash flow to determine funding needs, supporting the report’s advice on outlining capital requirements and allocation.\n","\n","These references collectively provide both the factual basis about MediTalk AI and practical, actionable examples and frameworks for improving financial readiness and fundraising preparedness, aligning well with the final report’s analysis and recommendations.\n","\n","=== [Iteration 5] ===\n","\n","===== 현재 스타트업 진단 보고서 =====\n","1. Clarity of Vision: 3 / 5점 (Confidence: 80%)\n","2. Product-Market Fit: 3 / 5점 (Confidence: 75%)\n","3. Competitive Advantage: 3 / 5점 (Confidence: 70%)\n","4. Team Competency: 3 / 5점 (Confidence: 70%)\n","5. Go-to-Market Strategy: 2 / 5점 (Confidence: 60%)\n","6. Customer Understanding: 3 / 5점 (Confidence: 70%)\n","7. Financial Readiness: 1 / 5점 (Confidence: 90%)\n","8. Scalability Potential: 3 / 5점 (Confidence: 70%)\n","9. Traction & KPIs: 3 / 5점 (Confidence: 75%)\n","10. Fundraising Preparedness: 1 / 5점 (Confidence: 90%)\n","==================================\n","\n","[ask_llm_for_next_action] Raw LLM Output:\n"," {\n","  \"criterion\": \"Financial Readiness\",\n","  \"action\": \"RefineOutput\",\n","  \"rationale\": \"User lacks financial knowledge but has requested examples; since relevant startup examples were not found in the database and internet search results provide useful financial readiness explanations and examples, synthesizing and explaining these findings to the user will best address the critical gap.\"\n","}\n","[LLM 결정] 다음에 집중할 항목: Financial Readiness\n","[LLM 결정] 선택된 액션: RefineOutput\n","[LLM 결정] 사유(rationale): User lacks financial knowledge but has requested examples; since relevant startup examples were not found in the database and internet search results provide useful financial readiness explanations and examples, synthesizing and explaining these findings to the user will best address the critical gap.\n","[Action 결과] REFINED_OUTPUT: (Refined Output about Financial Readiness)\n","Financial Readiness\n","\n","Currently, MediTalk AI demonstrates minimal financial readiness, reflecting a critical gap in understanding and managing the startup’s financial health. The team lacks essential knowledge about their current monthly burn rate—the amount of cash spent each month—and runway, which is how many months the company can sustain operations without additional funding. Without these metrics, it is impossible to gauge the startup’s immediate financial viability or planning horizon.\n","\n","Moreover, there are no detailed financial projections or a comprehensive financial plan for the next 12 to 24 months. Such projections should encompass anticipated revenues, operating expenses (including salaries, development, marketing, and overhead costs), and cash flow forecasts. This absence hampers the ability to make informed strategic decisions and to communicate a clear financial roadmap to potential investors.\n","\n","MediTalk AI has not yet identified or formalized revenue streams or monetization strategies for the app. Without a clear plan for generating income—whether through paid features, subscription models, advertising, or partnerships—it is difficult to project sustainable growth or justify funding needs. Additionally, the startup has not estimated its funding requirements or outlined how any capital raised would be allocated among product development, marketing, hiring, or other critical areas.\n","\n","There is also no evidence of financial risk assessment or contingency planning. Startups commonly face scenarios where growth is slower than expected or costs rise unexpectedly; having risk mitigation and fallback plans is crucial to resilience. Furthermore, MediTalk AI currently reports no existing financial partnerships, grants, loans, or alternative funding sources aside from a general intention to seek equity investment. This lack of diversified funding options increases vulnerability.\n","\n","To improve financial readiness, MediTalk AI should take the following steps:\n","\n","1. **Calculate Current Burn Rate and Runway:** Tally monthly expenses—salaries, development, marketing, office costs—and determine how many months existing cash reserves can cover these costs without new income.\n","\n","2. **Develop Detailed Financial Projections:** Create a budget and forecast for at least 12 months, including projected revenues (based on planned monetization), expenses, and cash flow. This should be revisited regularly as assumptions and market conditions evolve.\n","\n","3. **Define Funding Requirements and Allocation:** Estimate how much capital is necessary to sustain and grow the business over the next year or two, and specify how funds will be used (e.g., 40% product development, 30% marketing, 20% hiring, 10% operational expenses).\n","\n","4. **Establish Monetization Strategies:** Identify potential revenue streams, such as premium app features, subscription plans, partnerships with hospitals, or advertising, and develop timelines for implementation.\n","\n","5. **Assess Financial Risks and Contingencies:** Identify key risks like slower user growth or unexpected expenses and prepare plans to manage these risks, such as cost-cutting measures or alternative financing options.\n","\n","6. **Explore Additional Funding Sources:** Research and pursue grants, loans, or strategic partnerships that could provide non-dilutive capital or other support.\n","\n","7. **Prepare Fundraising Materials:** Build a clear, data-driven financial narrative to present to potential investors, demonstrating understanding of financial metrics, funding needs, and how investment will accelerate growth.\n","\n","By addressing these areas, MediTalk AI will significantly strengthen its financial foundation, improve investor confidence, and enhance its ability to execute its vision of simplifying hospital appointments effectively. Without these improvements, the startup risks financial instability that could hinder growth and sustainability.\n","[generate_business_report] Raw JSON from LLM:\n"," {\n","  \"Clarity of Vision\": {\"score\": 3, \"confidence\": 80},\n","  \"Product-Market Fit\": {\"score\": 3, \"confidence\": 70},\n","  \"Competitive Advantage\": {\"score\": 3, \"confidence\": 60},\n","  \"Team Competency\": {\"score\": 3, \"confidence\": 70},\n","  \"Go-to-Market Strategy\": {\"score\": 2, \"confidence\": 60},\n","  \"Customer Understanding\": {\"score\": 3, \"confidence\": 70},\n","  \"Financial Readiness\": {\"score\": 1, \"confidence\": 90},\n","  \"Scalability Potential\": {\"score\": 3, \"confidence\": 70},\n","  \"Traction & KPIs\": {\"score\": 3, \"confidence\": 70},\n","  \"Fundraising Preparedness\": {\"score\": 1, \"confidence\": 90}\n","}\n","[LLM 최종 보고서(마크다운)]\n"," # Startup Diagnostic Report\n","\n","## Introduction\n","\n","MediTalk AI is positioned as an innovative healthcare app aimed at simplifying hospital appointments. The startup demonstrates moderate progress across several critical dimensions but faces significant challenges in financial readiness and fundraising preparedness. This report evaluates the company’s current status, competitive landscape, customer insights, and key criteria to provide a holistic view and actionable recommendations.\n","\n","## 3C Analysis\n","\n","### Company\n","\n","MediTalk AI’s team exhibits solid competency with relevant skills to develop and scale the product. The culture appears focused on innovation and user-centric design, although resource limitations are evident, particularly in financial planning and strategic funding. The company’s clarity of vision is moderate, indicating room for stronger alignment and communication internally and externally.\n","\n","### Competitors\n","\n","The competitive landscape in healthcare appointment management apps is moderately crowded, with established players offering various scheduling and patient engagement solutions. MediTalk AI has yet to clearly articulate a distinct competitive advantage, which is crucial to differentiate itself and capture market share effectively.\n","\n","### Customers\n","\n","Target customers include patients seeking streamlined hospital appointment experiences and healthcare providers aiming to improve operational efficiency. User needs focus on ease of use, reliability, and integration with existing hospital systems. Current customer understanding is fair but requires deeper insights to tailor product features and marketing efforts.\n","\n","## Criteria Evaluation\n","\n","### Clarity of Vision\n","- Score: 3/5\n","- Confidence: 80%\n","- Rationale: The startup has a defined mission to simplify hospital appointments but needs stronger articulation and alignment of this vision across teams and stakeholders to drive unified progress.\n","\n","### Product-Market Fit\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: Initial product iterations address key user needs, but further validation and adaptation are necessary to ensure a solid market fit and sustained user engagement.\n","\n","### Competitive Advantage\n","- Score: 3/5\n","- Confidence: 60%\n","- Rationale: While the product shows potential, a clear and defensible competitive edge is not yet established, limiting differentiation in a competitive market.\n","\n","### Team Competency\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The team possesses relevant skills and experience, but gaps remain in areas such as financial management and go-to-market execution.\n","\n","### Go-to-Market Strategy\n","- Score: 2/5\n","- Confidence: 60%\n","- Rationale: Current marketing and sales plans are underdeveloped, lacking detailed tactics and channels to effectively reach and convert target users.\n","\n","### Customer Understanding\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: MediTalk AI has a reasonable grasp of user needs and segments; however, more comprehensive research and feedback loops are needed to deepen insights.\n","\n","### Financial Readiness\n","- Score: 1/5\n","- Confidence: 90%\n","- Rationale: Financial planning is a critical weakness. The startup lacks clarity on burn rate, runway, monetization strategy, funding requirements, and risk management, which threatens operational stability and investor confidence.\n","\n","### Scalability Potential\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: The app’s model and technology allow for scalability, but execution risks and resource constraints may hinder rapid growth without strategic improvements.\n","\n","### Traction & KPIs\n","- Score: 3/5\n","- Confidence: 70%\n","- Rationale: Early traction indicators are moderate, with some user adoption and key performance metrics tracked, but stronger growth and measurement systems are needed.\n","\n","### Fundraising Preparedness\n","- Score: 1/5\n","- Confidence: 90%\n","- Rationale: The startup is currently ill-prepared for fundraising due to inadequate financial documentation, unclear funding needs, and lack of investor-ready materials.\n","\n","## Conclusion\n","\n","MediTalk AI demonstrates promising potential in addressing an important healthcare challenge with a capable team and a feasible product concept. However, critical gaps in financial readiness and fundraising preparedness pose significant risks to its sustainability and growth trajectory. Strengthening go-to-market strategies and competitive positioning will also be essential.\n","\n","Key next steps include:\n","\n","- Developing comprehensive financial plans, including burn rate, runway, and monetization strategies.\n","- Preparing detailed and data-driven investor presentations.\n","- Enhancing marketing and sales approaches to accelerate user acquisition.\n","- Deepening customer insights to refine product-market fit.\n","- Defining and articulating a clear competitive advantage.\n","\n","Addressing these areas will improve operational stability, investor confidence, and market traction, positioning MediTalk AI for scalable and sustainable success in the competitive healthcare app space.\n","\n","## Relevant References\n","- User Input #2 and #3: These contain the direct questions and answers from MediTalk AI regarding their financial readiness, highlighting key gaps and unknowns in burn rate, runway, financial projections, funding needs, monetization, and risk management. They provide foundational context for the report’s assessment and recommendations.\n","\n","- Net Ref #1, Source: \"How to Calculate Burn Rate for Your Startup | TRUiC - Startup Savant\" (https://startupsavant.com/startup-finance/how-to-calculate-burn-rate): Offers a practical example of calculating monthly burn rate, supporting the report’s recommendation to quantify expenses and runway.\n","\n","- Net Ref #1, Source: \"Financial Analysis for Startups: Financial KPIs and Examples\" (https://fiscra.com/financial-analysis-for-startups): Explains the importance of burn rate and financial KPIs for startup sustainability, underpinning the report’s emphasis on measuring and managing cash flow.\n","\n","- Net Ref #1, Source: \"Financial Forecasting for Startups: A Step-by-Step Guide - Fuel Finance\" (https://fuelfinance.me/blog/financial-forecasting-for-startups/): Discusses the creation and continuous updating of financial projections, directly relevant to the report’s call for detailed 12–24 month financial planning.\n","\n","- Net Ref #1, Source: \"Estimating Funding Requirements in Financial Projections\" (https://fastercapital.com/content/Estimating-Funding-Requirements-in-Financial-Projections.html): Details how to project operating expenses and cash flow to estimate funding needs, aligning with the report’s recommendation to define funding requirements and capital allocation.\n","\n","These references collectively provide practical guidance and frameworks that directly support the financial readiness issues and improvement steps outlined in the final report. Other user inputs and database references are either redundant or less specific to the financial aspects discussed.\n","\n","=== [Iteration 6] ===\n","\n","===== 현재 스타트업 진단 보고서 =====\n","1. Clarity of Vision: 3 / 5점 (Confidence: 80%)\n","2. Product-Market Fit: 3 / 5점 (Confidence: 70%)\n","3. Competitive Advantage: 3 / 5점 (Confidence: 60%)\n","4. Team Competency: 3 / 5점 (Confidence: 70%)\n","5. Go-to-Market Strategy: 2 / 5점 (Confidence: 60%)\n","6. Customer Understanding: 3 / 5점 (Confidence: 70%)\n","7. Financial Readiness: 1 / 5점 (Confidence: 90%)\n","8. Scalability Potential: 3 / 5점 (Confidence: 70%)\n","9. Traction & KPIs: 3 / 5점 (Confidence: 70%)\n","10. Fundraising Preparedness: 1 / 5점 (Confidence: 90%)\n","==================================\n","\n","[ask_llm_for_next_action] Raw LLM Output:\n"," {\n","  \"criterion\": \"Financial Readiness\",\n","  \"action\": \"NoActionNeeded\",\n","  \"rationale\": \"The financial readiness gap has been thoroughly addressed with clear explanations and actionable steps, so no further immediate action is needed.\"\n","}\n","[LLM 결정] 다음에 집중할 항목: Financial Readiness\n","[LLM 결정] 선택된 액션: NoActionNeeded\n","[LLM 결정] 사유(rationale): The financial readiness gap has been thoroughly addressed with clear explanations and actionable steps, so no further immediate action is needed.\n","LLM이 NoActionNeeded를 선택했습니다. 보고서를 종료합니다.\n","\n","=== 최종 스타트업 보고서 ===\n","\n","===== 현재 스타트업 진단 보고서 =====\n","1. Clarity of Vision: 3 / 5점 (Confidence: 80%)\n","2. Product-Market Fit: 3 / 5점 (Confidence: 70%)\n","3. Competitive Advantage: 3 / 5점 (Confidence: 60%)\n","4. Team Competency: 3 / 5점 (Confidence: 70%)\n","5. Go-to-Market Strategy: 2 / 5점 (Confidence: 60%)\n","6. Customer Understanding: 3 / 5점 (Confidence: 70%)\n","7. Financial Readiness: 1 / 5점 (Confidence: 90%)\n","8. Scalability Potential: 3 / 5점 (Confidence: 70%)\n","9. Traction & KPIs: 3 / 5점 (Confidence: 70%)\n","10. Fundraising Preparedness: 1 / 5점 (Confidence: 90%)\n","==================================\n","\n","보고서 생성이 완료되었습니다. ✅\n","\n","=== [Discussion Mode] ===\n","최종 보고서 및 유저 입력을 바탕으로 자유롭게 대화가 가능합니다.\n","종료하려면 'quit'를 입력하세요.\n","\n","User: quit\n","Discussion 종료.\n"]}],"source":["import json\n","import os\n","\n","# === 10개 항목별 초기 Score/Confidence (None) ===\n","report_card = {\n","    \"Clarity of Vision\":       {\"score\": None, \"confidence\": None},\n","    \"Product-Market Fit\":      {\"score\": None, \"confidence\": None},\n","    \"Competitive Advantage\":   {\"score\": None, \"confidence\": None},\n","    \"Team Competency\":         {\"score\": None, \"confidence\": None},\n","    \"Go-to-Market Strategy\":   {\"score\": None, \"confidence\": None},\n","    \"Customer Understanding\":  {\"score\": None, \"confidence\": None},\n","    \"Financial Readiness\":     {\"score\": None, \"confidence\": None},\n","    \"Scalability Potential\":   {\"score\": None, \"confidence\": None},\n","    \"Traction & KPIs\":         {\"score\": None, \"confidence\": None},\n","    \"Fundraising Preparedness\":{\"score\": None, \"confidence\": None},\n","}\n","\n","CONFIDENCE_THRESHOLD = 80\n","\n","def collection_query(query_texts, n_results, db_type=\"startup\"):\n","    \"\"\"\n","    db_type에 따라 startup(Chroma) 또는 stanford(FAISS)에서 유사 문서 검색.\n","    반환: dict - documents, scores (optional)\n","    \"\"\"\n","    if db_type == \"startup\":\n","        # ChromaDB 검색\n","        import chromadb\n","        import chromadb.utils.embedding_functions as embedding_functions\n","\n","        client_chroma = chromadb.PersistentClient(path=\"./my_chromadb_folder\")\n","        embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n","            model_name=\"all-MiniLM-L6-v2\"\n","        )\n","\n","        collection = client_chroma.get_collection(\n","            name=\"startup_collection\",\n","            embedding_function=embedding_fn\n","        )\n","\n","        results = collection.query(\n","            query_texts=query_texts,\n","            n_results=n_results\n","        )\n","\n","        return {\n","            \"documents\": results[\"documents\"],\n","            \"metadatas\": results[\"metadatas\"],\n","            \"distances\": results.get(\"distances\", [])\n","        }\n","\n","    elif db_type == \"stanford\":\n","        faiss_result = get_faiss_results(\n","            index_dir=\"./faiss_index\",  # 인덱스 저장 경로\n","            query=query_texts[0],\n","            top_k=n_results\n","        )\n","        return {\n","            \"documents\": [faiss_result[\"documents\"]],  # 통일된 리스트 형태\n","            \"scores\": faiss_result[\"scores\"]\n","        }\n","\n","    else:\n","        raise ValueError(f\"Unknown db_type: {db_type}\")\n","\n","\n","def all_criteria_above_threshold(report: dict, threshold: int) -> bool:\n","    \"\"\"\n","    모든 항목의 confidence가 threshold 이상인지 체크.\n","    None이면 threshold를 달성했다고 볼 수 없으므로 False.\n","    \"\"\"\n","    for _, v in report.items():\n","        if v['confidence'] is None or v['confidence'] < threshold:\n","            return False\n","    return True\n","\n","def print_report(report: dict):\n","    \"\"\"\n","    report_card를 사람이 읽기 좋게 프린트.\n","    None이면 'N/A'로 표시\n","    \"\"\"\n","    print(\"\\n===== 현재 스타트업 진단 보고서 =====\")\n","    i = 1\n","    for criteria, data in report.items():\n","        score_str = data['score'] if data['score'] is not None else \"N/A\"\n","        conf_str = data['confidence'] if data['confidence'] is not None else \"N/A\"\n","        print(f\"{i}. {criteria}: {score_str} / 5점 (Confidence: {conf_str}%)\")\n","        i += 1\n","    print(\"==================================\\n\")\n","\n","\n","def llm_call(system_prompt: str, user_prompt: str, temperature: float = 0.7) -> str:\n","    \"\"\"\n","    OpenAI API를 호출해 system+user 프롬프트로부터 답변을 생성.\n","    \"\"\"\n","    completion = client.chat.completions.create(\n","        model=\"gpt-4.1-mini\",  # 모델명은 예시 (적절히 교체 가능)\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_prompt},\n","            {\"role\": \"user\", \"content\": user_prompt}\n","        ],\n","        temperature=temperature\n","    )\n","    return completion.choices[0].message.content.strip()\n","\n","\n","def parse_report_card_json(json_str: str) -> dict:\n","    \"\"\"\n","    LLM이 준 JSON을 파싱해, 10개 키가 모두 있는지, 각 value에 \"score\",\"confidence\"가 있는지 검사.\n","    \"\"\"\n","    try:\n","        data = json.loads(json_str)\n","    except json.JSONDecodeError:\n","        return None\n","\n","    if not isinstance(data, dict):\n","        return None\n","\n","    required_keys = list(report_card.keys())\n","    if len(data.keys()) != 10:\n","        return None\n","    for k in required_keys:\n","        if k not in data:\n","            return None\n","        if not isinstance(data[k], dict):\n","            return None\n","        if \"score\" not in data[k] or \"confidence\" not in data[k]:\n","            return None\n","\n","    return data\n","\n","\n","def update_report_card(report: dict, new_data: dict):\n","    \"\"\"\n","    report_card의 score/confidence를 new_data로 갱신\n","    \"\"\"\n","    for criterion in report.keys():\n","        report[criterion][\"score\"] = new_data[criterion][\"score\"]\n","        report[criterion][\"confidence\"] = new_data[criterion][\"confidence\"]\n","\n","\n","def search_internet(query: str) -> str:\n","    response = tavily_client.search(query)\n","    if response:\n","        return response\n","    else:\n","        return f\"[Internet] '{query}'에 대한 검색 결과가 없습니다.\"\n","\n","def search_db(query: str, db_type: str) -> str:\n","    \"\"\"\n","    ChromaDB에서 query_texts=[query]로 검색\n","    db_type에 맞추어 검색\n","    \"\"\"\n","    results = collection_query(query_texts=[query], n_results=3, db_type=db_type)\n","    docs = results.get(\"documents\", [[]])[0]\n","    if docs:\n","        joined_docs = \"\\n\".join([f\"- {d}\" for d in docs])\n","        return f\"[DB 검색 결과 - {db_type}]\\n{joined_docs}\"\n","    else:\n","        return f\"[DB 검색 결과 - {db_type}] '{query}' 관련 문서가 없습니다.\"\n","\n","def refine_criterion_output(criterion: str, all_context: str) -> str:\n","    \"\"\"\n","    'criterion' 항목에 대해 보완할 점을 먼저 추출한 뒤,\n","    그 보완점을 반영하여 다시 작성된 텍스트를 최종 반환한다.\n","    \"\"\"\n","\n","    # 1) LLM으로부터 개선(보완) 포인트를 먼저 받아온다.\n","    system_prompt_1 = (\n","        \"You are an AI assistant analyzing a specific section of a startup business report.\\n\"\n","        \"Your task is to identify any weaknesses or areas for improvement in the text related to this criterion.\\n\"\n","        \"List them clearly so we can address them in the next step.\\n\\n\"\n","        \"Return these suggested improvements in plain text (e.g., bullet points).\"\n","    )\n","    user_prompt_1 = (\n","        f\"Criterion to refine: '{criterion}'\\n\\n\"\n","        f\"Here is all the context collected so far:\\n{all_context}\\n\\n\"\n","        \"Please list the points or areas that should be improved, clarified, or expanded upon for this criterion.\"\n","    )\n","    improvement_points = llm_call(system_prompt_1, user_prompt_1, temperature=0.7)\n","\n","    # 2) LLM에게, 위에서 받은 개선 포인트를 반영해 더 깊고 구체적인 텍스트로 다시 작성해달라고 요청한다.\n","    system_prompt_2 = (\n","        \"You are an AI assistant refining a specific section of a startup business report.\\n\"\n","        \"You have a list of improvements to address.\\n\"\n","        \"Use them to produce a revised, more detailed discussion for this criterion, \"\n","        \"providing clarity, depth, and actionable insights.\\n\\n\"\n","        \"Return the refined explanation in plain text (no JSON).\"\n","    )\n","    user_prompt_2 = (\n","        f\"Criterion to refine: '{criterion}'\\n\\n\"\n","        f\"Improvement points:\\n{improvement_points}\\n\\n\"\n","        f\"Here is the context again:\\n{all_context}\\n\\n\"\n","        \"Incorporate the listed improvements into the final refined text.\"\n","    )\n","    refined_text = llm_call(system_prompt_2, user_prompt_2, temperature=0.7)\n","\n","    return refined_text\n","\n","def analyze_and_visualize(all_context: str) -> dict:\n","    \"\"\"\n","    CodeInterpreter로 하여금 3C 관점 (e.g., Company, Customer and Competitors)에서 시장을 분석하고, 이를 시각화 하도록 함.\n","    \"\"\"\n","\n","    # 1) LLM으로부터 visualization을 위한 프롬프트를 받아오기\n","    system_prompt_1 = (\n","    \"You are an AI assistant tasked with supporting the creation of a business report.\\n\"\n","    \"Your focus is on evaluating the market perspective within the 3C framework (Customer, Competitor, Company).\\n\"\n","    \"Your goal is to identify relevant data points that should be explored and recommend prompts for further analysis and data visualization.\\n\\n\"\n","    \"Structure your response using the following format:\\n\"\n","    \"[Task] A brief description of the specific analysis or insight to be developed.\\n\\n\"\n","    \"[Data] A bullet-point list of the key data elements required to support the analysis.\\n\\n\"\n","    \"[Chart Specs] A bullet-point list of suggested visualizations, including the type of chart and what variables to compare.\"\n","    )\n","    all_context = \"AI Healthcare startup in the U.S.A. In series A, the item is analzing users' biometrics using medical mobiel devices\"\n","    user_prompt_1 = (\n","    f\"Here is the current context and information gathered about a startup company:\\n{all_context}\\n\\n\"\n","    \"Based on this context, please identify areas that need to be improved, clarified, or expanded in order to strengthen the market analysis under the 3C framework.\"\n","    )\n","    user_input = llm_call(system_prompt_1, user_prompt_1, temperature=0.7)\n","    user_input += \"\\n[Output] A high‑resolution PNG (≈ 1920×1080) suitable for presentations.\"\n","\n","\n","    PROMPT_1 = (\n","        \"You are a highly skilled data analyst assigned to address the user's query using reliable, authoritative, and verifiable data sources.\\n\\n\"\n","        \"Your objectives:\\n\"\n","        \"- Acquire accurate, relevant, and reputable datasets that directly support the user’s inquiry.\\n\"\n","        \"- Structure the data in a clean, well-formatted pandas DataFrame with appropriate data types and labels.\\n\"\n","        \"- Conduct a meaningful, insight-driven analysis that provides direct, data-backed answers to the user’s question.\\n\"\n","        \"- Create compelling, well-labeled visualizations using matplotlib to effectively communicate your findings.\\n\\n\"\n","        \"Visualization Requirements:\\n\"\n","        \"- Every chart must include:\\n\"\n","        \"  • A clear and descriptive title.\\n\"\n","        \"  • Properly labeled axes and legends, where applicable.\\n\"\n","        \"  • Exact names of companies, institutions, or reports referenced in the data.\\n\"\n","        \"  • Visible citation of the data source with URL.(e.g., in a corner of the plot).\\n\\n\"\n","        \"Analysis Explanation:\\n\"\n","        \"- Write a concise and insightful narrative summarizing:\\n\"\n","        \"  • The methodology and key findings.\\n\"\n","        \"  • Any observed trends, comparisons, or outliers.\\n\"\n","        \"  • The broader implications of the analysis.\\n\"\n","        \"- Provide full URLs to all data sources used in your analysis to ensure traceability and transparency.\\n\\n\"\n","        \"Important Notes:\\n\"\n","        \"- Only use data from trustworthy, recognized sources (e.g., official government portals, academic institutions, reputable organizations).\\n\"\n","        \"- Ensure the analysis is self-contained, reproducible, and directly aligned with the user’s request.\\n\\n\"\n","        \"User Query: {user_input}\\n\"\n","    )\n","\n","    # # (2) Tavily search API를 통해서 이미 retrieval한 데이터를 기반으로, 이를 시각화 하는 경우\n","    # PROMPT_2 = (\n","    # \"You are a data analyst. Based on the dataset below, analyze the topic '{query}' and create a clear visualization. \\n\"\n","    # \"\\t- The dataset is in pandas DataFrame format and contains the following: {response} \\n\"\n","    # \"\\t- Provide a concise explanation of your analysis. \\n\"\n","    # \"\\t- Generate the visualization using matplotlib. \\n\"\n","    # \"\\t- Make sure to include font settings in the code to properly display Korean characters (e.g., use 'Malgun Gothic' on Windows or 'AppleGothic' on macOS). \\n\"\n","    # \"\\t- Also include the setting to prevent minus signs from breaking when rendering Korean text in matplotlib. \\n\"\n","    # )\n","\n","    with CodeInterpreterSession() as session:\n","        # generate a response based on user input\n","        response = session.generate_response(\n","            PROMPT_1.format(user_input = user_input)\n","        )\n","        # output the response\n","        response.show()\n","\n","    # # (2) Tavily search API를 통해서 이미 retrieval한 데이터를 기반으로, 이를 시각화 하는 경우\n","    # # query = \"AI 헬스케어 시장 성장률\"\n","    # query = \"AI healthcare market growth\"\n","    # response = search_internet(query)\n","    # print(response)\n","\n","    # with CodeInterpreterSession() as session:\n","    #     response = session.generate_response(\n","    #         PROMPT_2.format(query = query, response = response)\n","    #     )\n","    #     response.show()\n","\n","\n","    # save visualized images\n","    response_txt = response.content  # collected_contexts에 추가 가능\n","    response_img = response.files[0]  # 최종 레포트 생성 시 파싱\n","\n","    save_dir = \"./figures\"\n","    os.makedirs(save_dir, exist_ok=True)  # 경로가 없으면 생성\n","\n","    save_path = os.path.join(save_dir, \"figure.png\")\n","    response_img.save(save_path)\n","\n","    # figure 자체 대신 figure 경로를 반환해 최종 보고서에서 활용\n","    return {\n","        \"analysis\": response_txt,\n","        \"figure_path\": save_path\n","    }\n","\n","def generate_db_query(criterion: str, all_context: str, db_type: str) -> str:\n","    \"\"\"\n","    LLM에게 해당 criterion과 컨텍스트 기반으로 DB에 사용할 적절한 검색 쿼리를 생성하게 함.\n","    \"\"\"\n","    db_desc = \"real-world Korean startup company examples\" if db_type == \"startup\" else \"AI technology trends and statistics\"\n","\n","    system_prompt = (\n","        \"You are an AI assistant generating database search queries for a business report.\\n\"\n","        f\"The database is focused on {db_desc}.\\n\"\n","        \"Given the criterion and the context so far, generate a specific search query that will help retrieve relevant documents.\\n\"\n","        \"Only return the search query. No explanations, no JSON.\"\n","    )\n","\n","    user_prompt = (\n","        f\"Criterion: {criterion}\\n\\n\"\n","        f\"Context:\\n{all_context}\\n\\n\"\n","        \"Search query:\"\n","    )\n","\n","    query = llm_call(system_prompt, user_prompt, temperature=0.3)\n","    return query.strip()\n","\n","def generate_user_question_for_criterion(criterion: str, all_context: str) -> str:\n","    \"\"\"\n","    LLM에게:\n","      '해당 criterion을 개선하기 위해 사용자에게 어떤 세부 정보를 물어봐야 하는지'\n","    를 묻는다. LLM이 구체적인 질문 문장을 반환.\n","    \"\"\"\n","    system_prompt = (\n","        \"You are an AI assistant helping gather specific user input. \"\n","        \"Given the context and the chosen criterion, generate a short list of specific questions \"\n","        \"the user should answer in detail. The output should be plain text (no JSON).\"\n","    )\n","    user_prompt = (\n","        f\"Criterion of focus: '{criterion}'\\n\\n\"\n","        f\"Context so far:\\n{all_context}\\n\\n\"\n","        \"Based on what is missing or uncertain for this criterion, \"\n","        \"create a short set of bullet-point questions for the user to answer. \"\n","        \"Be as concrete as possible.\"\n","    )\n","    question_text = llm_call(system_prompt, user_prompt, temperature=0.7)\n","    return question_text\n","\n","\n","def generate_internet_search_query(criterion: str, all_context: str) -> str:\n","    \"\"\"\n","    LLM에게: '해당 criterion 관련해서 인터넷에서 어떤 키워드를 검색해야\n","    필요한 정보를 얻을 수 있는지'를 물어봄.\n","    \"\"\"\n","    system_prompt = (\n","        \"You are an AI assistant that decides the best internet search query \"\n","        \"to gather more information about a certain criterion in a startup business report.\\n\"\n","        \"Return ONLY the recommended search query in plain text (no JSON).\"\n","    )\n","    user_prompt = (\n","        f\"Criterion of focus: '{criterion}'\\n\\n\"\n","        f\"Context so far:\\n{all_context}\\n\\n\"\n","        \"Based on what's missing or uncertain for this criterion, propose a concise search query \"\n","        \"that would help gather the most relevant insights or data from the internet.\"\n","    )\n","    suggested_query = llm_call(system_prompt, user_prompt, temperature=0.7)\n","    return suggested_query.strip()\n","\n","def perform_action(action: str, target_criteria: str, collected_contexts: list) -> str:\n","    \"\"\"\n","    LLM이 결정한 action을 실제 수행하여 결과 텍스트를 반환.\n","    결과 텍스트는 그대로 collected_contexts에 추가되어\n","    이후 보고서 업데이트/분석에 활용된다.\n","\n","    * 여기서 반환 문자열 앞에 식별자를 붙여줌으로써,\n","      나중에 generate_business_report에서 구조적으로 활용 가능하도록 함.\n","    \"\"\"\n","    if action == \"AskUser\":\n","        # 1) LLM에게 '무엇을 구체적으로 물어봐야 하는가'를 요청\n","        full_context_str = \"\\n\".join(collected_contexts)\n","        question_prompt = generate_user_question_for_criterion(target_criteria, full_context_str)\n","\n","        # 2) 질문을 화면에 출력\n","        print(\"\\n[LLM Generated Questions]\")\n","        print(question_prompt)\n","        print(\"\\n아래 질문에 대한 답을 입력해주세요.\")\n","\n","        # 3) 사용자 입력 받기\n","        user_answer = input(\"Your Answer: \")\n","\n","        # 4) 반환 문자열 구성 (식별자: USER_INPUT)\n","        return f\"USER_INPUT: (User Provided Info about {target_criteria})\\nQuestions:\\n{question_prompt}\\nUser's Answer:\\n{user_answer}\"\n","\n","    elif action == \"SearchDB_startup\":\n","        full_context_str = \"\\n\".join(collected_contexts)\n","        query = generate_db_query(target_criteria, full_context_str, db_type=\"startup\")\n","        db_result = search_db(query, db_type=\"startup\")\n","        return f\"DB_SUMMARY: {db_result}\"\n","\n","    elif action == \"SearchDB_report\":\n","        full_context_str = \"\\n\".join(collected_contexts)\n","        query = generate_db_query(target_criteria, full_context_str, db_type=\"stanford\")\n","        db_result = search_db(query, db_type=\"stanford\")\n","        return f\"DB_SUMMARY: {db_result}\"\n","\n","    elif action == \"SearchInternet\":\n","        # 1) LLM에게 '인터넷에서 검색할 query'를 생성해달라고 요청\n","        full_context_str = \"\\n\".join(collected_contexts)\n","        suggested_query = generate_internet_search_query(target_criteria, full_context_str)\n","\n","        # 2) 실제 인터넷 검색 수행\n","        net_result = search_internet(suggested_query)\n","\n","        # 3) 결과를 반환 (검색어 + 검색 결과) (식별자: INTERNET_SUMMARY)\n","        return f\"INTERNET_SUMMARY: (Internet Search Query: '{suggested_query}')\\n{net_result}\"\n","\n","    elif action == \"RefineOutput\":\n","        # RefineOutput 시, LLM 추가 호출\n","        full_context_str = \"\\n\".join(collected_contexts)\n","        refined_text = refine_criterion_output(target_criteria, full_context_str)\n","        # 식별자: REFINED_OUTPUT\n","        return f\"REFINED_OUTPUT: (Refined Output about {target_criteria})\\n{refined_text}\"\n","\n","    elif action == \"AnalyzeAndVisualize\":\n","        full_context_str = \"\\n\".join(collected_contexts)\n","        analysis_with_figure = analyze_and_visualize(collected_contexts)\n","        # 이제 figure_path도 함께 반환\n","        return (\n","            \"AnalyzeAndVisualize:\\n\"\n","            f\"3C_ANALYSIS: {analysis_with_figure['analysis']}\\n\"\n","            f\"FIGURE_PATH: {analysis_with_figure['figure_path']}\"\n","        )\n","\n","    elif action == \"NoActionNeeded\":\n","        return \"(No further actions required.)\"\n","    else:\n","        return \"(알 수 없는 액션)\"\n","\n","\n","def ask_llm_for_next_action(\n","    report: dict,\n","    collected_texts: list,\n","    action_history: list\n",") -> dict:\n","    \"\"\"\n","    LLM에게 “다음 액션” + “어느 항목(criterion)인지” + \"왜 그 액션을 골랐는지(rationale)\"를\n","    JSON 형식으로 받는다.\n","    \"\"\"\n","    system_prompt = (\n","        \"You are an AI assistant finalizing a startup's business report.\\n\\n\"\n","        \"You have 7 possible actions:\\n\"\n","        \" 1) AskUser       : Need more specific details from user\\n\"\n","        \" 2) SearchDB_startup     : Need real-world Korean startup company examples\\n\"\n","        \" 3) SearchDB_report    : Need AI technology trend, statistics information\\n\"\n","        \" 4) SearchInternet: Need external info from the web\\n\"\n","        \" 5) RefineOutput  : Have enough info, want to refine/improve writing\\n\"\n","        \" 6) AnalyzeAndVisualize : Perform data analysis and generate visualizations using retrieved user and market information.\\n\"\n","        \" 7) NoActionNeeded: Everything is sufficiently addressed\\n\\n\"\n","        \"When deciding, consider any info gaps or low confidence in the 10 criteria.\\n\\n\"\n","        \"Return your decision in JSON with EXACTLY these three keys:\\n\"\n","        \"  \\\"criterion\\\"  -> one of the 10 criteria, or \\\"None\\\" if no focus\\n\"\n","        \"  \\\"action\\\"     -> one of [AskUser, SearchDB_startup, SearchDB_report, SearchInternet, RefineOutput, NoActionNeeded]\\n\"\n","        \"  \\\"rationale\\\"  -> a short sentence explaining why you chose this action.\\n\\n\"\n","        \"No extra keys, no disclaimers, no additional text. ONLY JSON.\"\n","    )\n","\n","    def sc_str(d):\n","        return f\"Score={d['score'] if d['score'] is not None else 'N/A'}, Confidence={d['confidence'] if d['confidence'] is not None else 'N/A'}%\"\n","\n","    report_summary = \"\\n\".join([\n","        f\"{k}: {sc_str(v)}\"\n","        for k, v in report.items()\n","    ])\n","\n","    accumulated_context = \"\\n---\\n\".join(collected_texts)\n","\n","    # 액션 히스토리를 텍스트로 합침\n","    action_history_text = \"\\n\".join([\n","        f\"[{i+1}] {entry}\"\n","        for i, entry in enumerate(action_history)\n","    ])\n","\n","    user_prompt = (\n","        f\"Current report state:\\n{report_summary}\\n\\n\"\n","        f\"Action history so far:\\n{action_history_text}\\n\\n\"\n","        f\"Collected contexts:\\n{accumulated_context}\\n\\n\"\n","        \"Which single criterion is the biggest priority now, and which action is most appropriate?\\n\"\n","        \"Also provide a short rationale explaining your choice.\\n\"\n","        \"Important: Output EXACTLY and ONLY JSON in the following format:\\n\\n\"\n","        \"{\\n\"\n","        \"  \\\"criterion\\\": \\\"<one_of_the_10_criteria_or_None>\\\",\\n\"\n","        \"  \\\"action\\\": \\\"<AskUser_or_SearchDB_startup_or_SearchDB_report_or_SearchInternet_or_RefineOutput_or_NoActionNeeded>\\\",\\n\"\n","        \"  \\\"rationale\\\": \\\"<short_reason>\\\"\\n\"\n","        \"}\\n\"\n","    )\n","\n","    max_tries = 3\n","    for attempt in range(max_tries):\n","        raw = llm_call(system_prompt, user_prompt, temperature=0.0)\n","        print(\"[ask_llm_for_next_action] Raw LLM Output:\\n\", raw)  # 디버그 출력\n","\n","        try:\n","            action_data = json.loads(raw.strip())\n","            # JSON 키 검사\n","            if (\"criterion\" in action_data) and (\"action\" in action_data) and (\"rationale\" in action_data):\n","                valid_actions = [\"AskUser\", \"SearchDB_startup\", \"SearchDB_report\", \"SearchInternet\", \"RefineOutput\", \"AnalyzeAndVisualize\", \"NoActionNeeded\"]\n","                if action_data[\"action\"] in valid_actions:\n","                    return action_data\n","        except Exception:\n","            pass\n","\n","        print(f\"⚠️ 액션 JSON 형식 오류(시도 {attempt+1}/{max_tries}), 재시도합니다...\")\n","\n","    return None\n","\n","\n","def generate_business_report(report: dict, collected_texts: list) -> str:\n","    \"\"\"\n","    단계 요약:\n","      1) 전체 맥락(DB, 인터넷, 유저 입력 등)을 활용해 '보고서 텍스트(설명 부분)'를 생성\n","      2) 최종 점수(Score)/신뢰도(Confidence)는 오직 user input만 근거하여 산출\n","      3) 마크다운 형식으로 최종 보고서 작성\n","\n","    핵심:\n","      - 보고서 텍스트(설명)는 DB나 인터넷 요약도 참고해 좀 더 풍부하게 작성한다.\n","      - 하지만, 10개 기준별 점수는 \"user input\"만 근거로 한다.\n","    \"\"\"\n","\n","    # -- (1) collected_texts에서 식별자로 분류 --\n","    user_inputs = []\n","    db_summaries = []\n","    net_summaries = []\n","    refined_outputs = []\n","    analysis_outputs = []\n","    general_contexts = []\n","    figure_paths = []\n","\n","    for c in collected_texts:\n","        if c.startswith(\"USER_INPUT:\"):\n","            user_inputs.append(c[len(\"USER_INPUT:\"):].strip())\n","        elif c.startswith(\"DB_SUMMARY:\"):\n","            db_summaries.append(c[len(\"DB_SUMMARY:\"):].strip())\n","        elif c.startswith(\"INTERNET_SUMMARY:\"):\n","            net_summaries.append(c[len(\"INTERNET_SUMMARY:\"):].strip())\n","        elif c.startswith(\"REFINED_OUTPUT:\"):\n","            refined_outputs.append(c[len(\"REFINED_OUTPUT:\"):].strip())\n","        elif c.startswith(\"AnalyzeAndVisualize\"):\n","            lines = c.split(\"\\n\")\n","            analysis_txt = []\n","            for line in lines:\n","                if line.startswith(\"3C_ANALYSIS:\"):\n","                    analysis_txt.append(line.replace(\"3C_ANALYSIS:\", \"\").strip())\n","                elif line.startswith(\"FIGURE_PATH:\"):\n","                    figure_paths.append(line.replace(\"FIGURE_PATH:\", \"\").strip())\n","            analysis_outputs.append(\"\\n\".join(analysis_txt))\n","        else:\n","            general_contexts.append(c)\n","\n","    # 참고용으로 구조화된 전체 맥락(설명용)\n","    structured_context = (\n","        f\"**User Input**:\\n{''.join(user_inputs)}\\n\\n\"\n","        f\"**DB Summaries**:\\n{''.join(db_summaries)}\\n\\n\"\n","        f\"**Internet Summaries**:\\n{''.join(net_summaries)}\\n\\n\"\n","        f\"**Refined Outputs**:\\n{''.join(refined_outputs)}\\n\\n\"\n","        f\"**3C Analysis Outputs\\n{''.join(analysis_outputs)}\\n\\n\"\n","        f\"**Other Contexts**:\\n{''.join(general_contexts)}\"\n","    )\n","\n","    # report_card 요약 문자열 (디스플레이용)\n","    def sc_str(d):\n","        s = d['score'] if d['score'] is not None else 'N/A'\n","        c = d['confidence'] if d['confidence'] is not None else 'N/A'\n","        return f\"Score={s}, Confidence={c}%\"\n","\n","    report_summary = \"\\n\".join([\n","        f\"{k}: {sc_str(v)}\"\n","        for k, v in report.items()\n","    ])\n","\n","    # ------------------------------------------------------\n","    # (1) 보고서 설명 텍스트 생성 (DB/인터넷도 참고)\n","    # ------------------------------------------------------\n","    system_prompt_1 = (\n","        \"You are an AI assistant that creates business reports for startups.\\n\"\n","        \"You have access to user input, as well as references from DB and the internet.\\n\"\n","        \"Use ALL of that context to refine or improve the textual explanation of the report.\\n\"\n","        \"However, do NOT provide any new scores or confidences here.\\n\"\n","        \"Just generate the improved discussion/explanation in plain text.\"\n","    )\n","    user_prompt_1 = (\n","        f\"Current report state:\\n{report_summary}\\n\\n\"\n","        \"Below is the structured context collected so far:\\n\"\n","        f\"{structured_context}\\n\\n\"\n","        \"Please provide an updated, more detailed explanation of the business report, \"\n","        \"incorporating any relevant insights from the references.\"\n","    )\n","    refined_report_text = llm_call(system_prompt_1, user_prompt_1, temperature=0.7)\n","\n","    # ------------------------------------------------------\n","    # (2) 점수(Score)/신뢰도(Confidence) 산출 (오직 user input만 사용)\n","    # ------------------------------------------------------\n","    # user input들을 하나로 합침\n","    user_only_input_text = \"\\n\".join(user_inputs).strip()\n","    if not user_only_input_text:\n","        user_only_input_text = \"(No user input provided.)\"\n","\n","    system_prompt_2 = (\n","        \"You are an AI assistant that updates the score and confidence of EXACTLY these 10 criteria:\\n\"\n","        \"1) \\\"Clarity of Vision\\\"\\n\"\n","        \"2) \\\"Product-Market Fit\\\"\\n\"\n","        \"3) \\\"Competitive Advantage\\\"\\n\"\n","        \"4) \\\"Team Competency\\\"\\n\"\n","        \"5) \\\"Go-to-Market Strategy\\\"\\n\"\n","        \"6) \\\"Customer Understanding\\\"\\n\"\n","        \"7) \\\"Financial Readiness\\\"\\n\"\n","        \"8) \\\"Scalability Potential\\\"\\n\"\n","        \"9) \\\"Traction & KPIs\\\"\\n\"\n","        \"10) \\\"Fundraising Preparedness\\\"\\n\\n\"\n","        \"IMPORTANT: For scoring and confidence, you must rely ONLY on the user's input below.\\n\"\n","        \"Ignore any DB or internet data for the actual scoring.\\n\\n\"\n","        \"You MUST ONLY output valid JSON with these EXACT 10 keys. No more, no less, no renaming.\\n\"\n","        \"Each key => {\\\"score\\\": (1~5), \\\"confidence\\\": (0~100)}. No extra text.\"\n","    )\n","    user_prompt_2 = (\n","        \"Below is the user's input (the only source for your scoring):\\n\"\n","        f\"{user_only_input_text}\\n\\n\"\n","        \"Now output ONLY JSON for the updated score/confidence. \"\n","        \"Use exactly the 10 keys listed. No extra keys or text.\"\n","    )\n","\n","    new_report_data = None\n","    max_tries = 3\n","    for attempt in range(max_tries):\n","        raw_json_output = llm_call(system_prompt_2, user_prompt_2, temperature=0.0)\n","        print(\"[generate_business_report] Raw JSON from LLM:\\n\", raw_json_output)  # 디버그 로그\n","\n","        parsed = parse_report_card_json(raw_json_output)\n","        if parsed is not None:\n","            new_report_data = parsed\n","            break\n","        else:\n","            print(f\"⚠️ JSON 형식 오류(시도 {attempt+1}/{max_tries}), 재요청합니다...\")\n","\n","    if new_report_data:\n","        update_report_card(report, new_report_data)\n","    else:\n","        print(\"❌ 3회 시도 후에도 JSON 파싱 실패. report_card 업데이트를 건너뜁니다.\")\n","\n","    # ------------------------------------------------------\n","    # (3) 최종 '마크다운' 형태의 보고서 생성\n","    # ------------------------------------------------------\n","    system_prompt_3 = (\n","        \"You are an AI assistant creating a final business report in Markdown format.\\n\"\n","        \"We have 10 criteria, each with an updated Score and Confidence.\\n\\n\"\n","        \"The final report structure should be:\\n\"\n","        \"# Startup Diagnostic Report\\n\"\n","        \"## Introduction\\n\"\n","        \"(A short overview of the startup's current status)\\n\\n\"\n","        \"## 3C Analysis\\n\"\n","        \"### Company\\n\"\n","        \"(Team, resources, culture, etc.)\\n\\n\"\n","        \"### Competitors\\n\"\n","        \"(Competitive landscape)\\n\\n\"\n","        \"### Customers\\n\"\n","        \"(Target segments, user needs, insights)\\n\\n\"\n","        \"## Criteria Evaluation\\n\"\n","        \"For each of the 10 criteria, create a subsection:\\n\"\n","        \"### {Criterion Name}\\n\"\n","        \"- Score: X/5\\n\"\n","        \"- Confidence: Y%\\n\"\n","        \"- Rationale:\\n\"\n","        \"  (Short explanation)\\n\\n\"\n","        \"## Conclusion\\n\"\n","        \"(Summarize key findings and next steps)\\n\\n\"\n","        \"Only output valid Markdown.\"\n","    )\n","\n","    updated_report_summary = \"\\n\".join([\n","        f\"{k}: {sc_str(v)}\"\n","        for k, v in report.items()\n","    ])\n","\n","    references_md = \"## References\\n\"\n","    if user_inputs:\n","        references_md += \"\\n**User Input**\\n\"\n","        for i, ui in enumerate(user_inputs, 1):\n","            references_md += f\"- User Input #{i}: {ui}\\n\"\n","    if db_summaries:\n","        references_md += \"\\n**DB Summaries (RAG)**\\n\"\n","        for i, dbs in enumerate(db_summaries, 1):\n","            references_md += f\"- DB Ref #{i}: {dbs}\\n\"\n","    if net_summaries:\n","        references_md += \"\\n**Internet Summaries**\\n\"\n","        for i, ns in enumerate(net_summaries, 1):\n","            references_md += f\"- Net Ref #{i}: {ns}\\n\"\n","    if refined_outputs:\n","        references_md += \"\\n**Refined Outputs**\\n\"\n","        for i, ro in enumerate(refined_outputs, 1):\n","            references_md += f\"- Refined #{i}: {ro}\\n\"\n","    if analysis_outputs:\n","        references_md += \"\\n**3C Analysis Texts**\\n\"\n","        for i, ao in enumerate(analysis_outputs, 1):\n","            references_md += f\"- Analysis #{i}: {ao}\\n\"\n","\n","    system_prompt_4 = (\n","        \"You are an AI assistant. You have a preliminary references list from user, DB, internet, etc.\\n\"\n","        \"You also have the final business report context.\\n\"\n","        \"Your task: read all references, decide which are most relevant or supportive for the final report, and return them in bullet format.\\n\"\n","        \"If certain references are not directly relevant or redundant, you may omit them.\\n\\n\"\n","        \"Output only the references you consider relevant for the final report.\\n\"\n","        \"For each item, provide a concise explanation (1~2 lines) of why it is relevant.\\n\"\n","    )\n","\n","    user_prompt_4 = (\n","        f\"Final Report (draft):\\n{refined_report_text}\\n\\n\"\n","        f\"Full references:\\n{references_md}\\n\\n\"\n","        \"Please filter out any references that are not relevant or are repetitive.\\n\"\n","        \"Return only the references you think are important for understanding or supporting this business report.\\n\"\n","    )\n","\n","    filtered_references = llm_call(system_prompt_4, user_prompt_4, temperature=0.7)\n","\n","    user_prompt_3 = (\n","        f\"Updated report card:\\n{updated_report_summary}\\n\\n\"\n","        \"Refined text:\\n\"\n","        f\"{refined_report_text}\\n\\n\"\n","        \"Please produce a comprehensive markdown report with the structure above. \"\n","        \"Make sure to include the 3C Analysis and the 10 criteria.\"\n","    )\n","\n","    final_markdown_report = llm_call(system_prompt_3, user_prompt_3, temperature=0.7)\n","\n","    if figure_paths:\n","        final_markdown_report += \"\\n\\n## Generated Figures\\n\"\n","        for fp in figure_paths:\n","            final_markdown_report += f\"![Analysis Figure]({fp})\\n\"\n","\n","    final_markdown_report += \"\\n\\n## Relevant References\\n\"\n","    final_markdown_report += filtered_references\n","\n","    return final_markdown_report\n","\n","def discussion_loop(final_report: str, all_user_inputs: list):\n","    \"\"\"\n","    (새로 추가됨)\n","    최종 보고서와 유저 입력들을 바탕으로 자유롭게 대화할 수 있는 함수.\n","    \"\"\"\n","    print(\"\\n=== [Discussion Mode] ===\")\n","    print(\"최종 보고서 및 유저 입력을 바탕으로 자유롭게 대화가 가능합니다.\")\n","    print(\"종료하려면 'quit'를 입력하세요.\\n\")\n","\n","    while True:\n","        user_ask = input(\"User: \")\n","        if user_ask.strip().lower() == \"quit\":\n","            print(\"Discussion 종료.\")\n","            break\n","\n","        # LLM 호출 (예시)\n","        system_prompt = (\n","            \"You are an AI assistant discussing the final startup report.\\n\"\n","            \"You have the final markdown report and all user inputs.\\n\"\n","            \"Answer any user questions or discuss further improvements.\\n\"\n","        )\n","        user_prompt = (\n","            f\"Final Report:\\n{final_report}\\n\\n\"\n","            f\"All User Inputs:\\n{all_user_inputs}\\n\\n\"\n","            f\"User's question:\\n{user_ask}\"\n","        )\n","        answer = llm_call(system_prompt, user_prompt, temperature=0.7)\n","        print(f\"Assistant: {answer}\\n\")\n","\n","def main_business_report_loop():\n","    iteration_count = 0\n","    max_iterations = 10\n","\n","    # 모든 정보 누적 리스트\n","    collected_contexts = []\n","    # 액션 이력 추적 리스트\n","    action_history = []\n","\n","    # 1) 사용자 초기 정보\n","    initial_input = input(\"초기 스타트업 정보를 간략히 입력하세요: \")\n","    # 식별자: USER_INPUT (최초 입력)\n","    collected_contexts.append(f\"USER_INPUT: {initial_input}\")\n","\n","    # 2) 첫 보고서 생성\n","    final_markdown = generate_business_report(report_card, collected_contexts)\n","    print(\"[초기 보고서]\\n\", final_markdown)\n","\n","    while iteration_count < max_iterations:\n","        iteration_count += 1\n","        print(f\"\\n=== [Iteration {iteration_count}] ===\")\n","        print_report(report_card)\n","\n","        # (A) 모든 항목이 threshold 이상이면 종료\n","        if all_criteria_above_threshold(report_card, CONFIDENCE_THRESHOLD):\n","            print(\"✅ 모든 항목이 threshold를 달성했습니다. 최종 보고서를 출력합니다.\")\n","            break\n","\n","        # (B) LLM에게 “다음 액션” 질의\n","        action_data = ask_llm_for_next_action(report_card, collected_contexts, action_history)\n","        if action_data is None:\n","            print(\"❌ 3회 시도 후에도 액션 JSON 파싱 실패. 루프를 종료합니다.\")\n","            break\n","\n","        chosen_criterion = action_data[\"criterion\"]\n","        chosen_action = action_data[\"action\"]\n","        rationale = action_data[\"rationale\"]\n","\n","        print(f\"[LLM 결정] 다음에 집중할 항목: {chosen_criterion}\")\n","        print(f\"[LLM 결정] 선택된 액션: {chosen_action}\")\n","        print(f\"[LLM 결정] 사유(rationale): {rationale}\")\n","\n","        if chosen_action == \"NoActionNeeded\":\n","            print(\"LLM이 NoActionNeeded를 선택했습니다. 보고서를 종료합니다.\")\n","            break\n","\n","        # (C) 액션 수행 → 새 정보 획득\n","        # if iteration_count == 1:\n","        #     chosen_action = \"AnalyzeAndVisualize\"\n","        action_result = perform_action(chosen_action, chosen_criterion, collected_contexts)\n","        print(f\"[Action 결과] {action_result}\")\n","\n","        # 액션 이력에 추가\n","        action_log_text = (\n","            f\"Iteration={iteration_count}, \"\n","            f\"Action={chosen_action}, \"\n","            f\"Criterion={chosen_criterion}, \"\n","            f\"Rationale={rationale}, \"\n","            f\"Result={action_result}\"\n","        )\n","        action_history.append(action_log_text)\n","\n","        # 결과를 context에도 추가\n","        collected_contexts.append(action_result)\n","\n","        # (D) LLM으로 보고서 재작성\n","        final_markdown = generate_business_report(report_card, collected_contexts)\n","        print(\"[LLM 최종 보고서(마크다운)]\\n\", final_markdown)\n","\n","    # 반복 종료 시점, 최종 출력\n","    print(\"\\n=== 최종 스타트업 보고서 ===\")\n","    print_report(report_card)\n","    print(\"보고서 생성이 완료되었습니다. ✅\")\n","\n","    # (F) 모든 작업 후, discussion_loop() 진입 (새 기능)\n","    all_user_inputs = []\n","    for ctx in collected_contexts:\n","        if ctx.startswith(\"USER_INPUT:\"):\n","            all_user_inputs.append(ctx[len(\"USER_INPUT:\"):].strip())\n","    discussion_loop(final_markdown, all_user_inputs)\n","\n","\n","if __name__ == \"__main__\":\n","    main_business_report_loop()\n"]}],"metadata":{"colab":{"collapsed_sections":["2XcZntNVzV6d"],"provenance":[]},"kernelspec":{"display_name":"p4ds_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.22"},"widgets":{"application/vnd.jupyter.widget-state+json":{"600a415037314e06b57a0ce798d6c230":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a964feab52ab484d8db68b692851ad06","IPY_MODEL_bea59c5b734f479c8dcfd75a421d796a","IPY_MODEL_13032c0ec45c40869a7fec4be505c4ea"],"layout":"IPY_MODEL_549babcffdb948d4961aeeaab252574a"}},"a964feab52ab484d8db68b692851ad06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a714065b1424b739ecce86766713f61","placeholder":"​","style":"IPY_MODEL_96b4378d18bb4a0fbdb6e6155d1d7549","value":"modules.json: 100%"}},"bea59c5b734f479c8dcfd75a421d796a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d9b8450507c47cbb28370ea49091f58","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96fb8c04f70f4d1ea1c3f9883b50bbbe","value":349}},"13032c0ec45c40869a7fec4be505c4ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fb583241fa2477c96d613a21d590f55","placeholder":"​","style":"IPY_MODEL_a15877064f8947dd93220f40a135ffe0","value":" 349/349 [00:00&lt;00:00, 11.4kB/s]"}},"549babcffdb948d4961aeeaab252574a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a714065b1424b739ecce86766713f61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96b4378d18bb4a0fbdb6e6155d1d7549":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d9b8450507c47cbb28370ea49091f58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96fb8c04f70f4d1ea1c3f9883b50bbbe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fb583241fa2477c96d613a21d590f55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a15877064f8947dd93220f40a135ffe0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfb8ab675222413e97503120fdf4c4a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10732e41b9e74460b3d7c629fa8c2428","IPY_MODEL_66ba54017d134eb48ba2bd01290b1ec0","IPY_MODEL_6dc6dcf5d50c45eab81bdd4c667ae967"],"layout":"IPY_MODEL_6cf0fa949272497c869905740793efe4"}},"10732e41b9e74460b3d7c629fa8c2428":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_209fc913d1cf4cf0a933f2f3921c81ee","placeholder":"​","style":"IPY_MODEL_107f9642d5754bcda7db3662e6840637","value":"config_sentence_transformers.json: 100%"}},"66ba54017d134eb48ba2bd01290b1ec0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6373f3939b5d4e5b97b470a0fde58891","max":123,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ebce95b471d49709c8c41fceaa8501a","value":123}},"6dc6dcf5d50c45eab81bdd4c667ae967":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c58a0284c024affb86c55b7304df860","placeholder":"​","style":"IPY_MODEL_50f1bea04c1742468fd95fb8bb8c6fd1","value":" 123/123 [00:00&lt;00:00, 5.55kB/s]"}},"6cf0fa949272497c869905740793efe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"209fc913d1cf4cf0a933f2f3921c81ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"107f9642d5754bcda7db3662e6840637":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6373f3939b5d4e5b97b470a0fde58891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ebce95b471d49709c8c41fceaa8501a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c58a0284c024affb86c55b7304df860":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50f1bea04c1742468fd95fb8bb8c6fd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d32875fa422d453d9359c29b1b4c3b51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a51e7b3be914e13add06625fe7f5862","IPY_MODEL_b54d4fcc34ba4678af4ffad182a7d29a","IPY_MODEL_d2b045525b3647f3822906e1112a6322"],"layout":"IPY_MODEL_2a3a009b94ef41c6a19f239d59353c00"}},"1a51e7b3be914e13add06625fe7f5862":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ce767769b8045588c08aa94447f232e","placeholder":"​","style":"IPY_MODEL_69d9022d0d2e406f8338d6cf48e99f28","value":"README.md: 100%"}},"b54d4fcc34ba4678af4ffad182a7d29a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34576fc5fe6e482f9b5ed20013cbbd09","max":15822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e79e9438d5d4eeea84ed998d07c29d4","value":15822}},"d2b045525b3647f3822906e1112a6322":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28a57afb183346989ab43757b1f330fd","placeholder":"​","style":"IPY_MODEL_8a8ab708014e4f92842da6ed1b6df811","value":" 15.8k/15.8k [00:00&lt;00:00, 1.26MB/s]"}},"2a3a009b94ef41c6a19f239d59353c00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ce767769b8045588c08aa94447f232e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69d9022d0d2e406f8338d6cf48e99f28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34576fc5fe6e482f9b5ed20013cbbd09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e79e9438d5d4eeea84ed998d07c29d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28a57afb183346989ab43757b1f330fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a8ab708014e4f92842da6ed1b6df811":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b93c818fa16943f48dbc2bb697c4d68f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3eee72c85b3a4445b81c04477acc2ab5","IPY_MODEL_06496abade2d4113b1d88882364c47f2","IPY_MODEL_d781412b81c647b59f8eec098b0eb422"],"layout":"IPY_MODEL_8c361b7d66d64157a7fd1eb0421085c9"}},"3eee72c85b3a4445b81c04477acc2ab5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e09eede46450481893fc4da57cdb4508","placeholder":"​","style":"IPY_MODEL_c4ba87b9de804275859c028862fc2887","value":"sentence_bert_config.json: 100%"}},"06496abade2d4113b1d88882364c47f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51c4677992d94d1d8ee601830f98c518","max":54,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d32ff55266a4e3d93f33c6ec9961ea2","value":54}},"d781412b81c647b59f8eec098b0eb422":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55a5362f8d144a14aaad4d6692755fb4","placeholder":"​","style":"IPY_MODEL_af6070c0d9bc40dcb8546360cc22231c","value":" 54.0/54.0 [00:00&lt;00:00, 2.63kB/s]"}},"8c361b7d66d64157a7fd1eb0421085c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e09eede46450481893fc4da57cdb4508":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ba87b9de804275859c028862fc2887":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51c4677992d94d1d8ee601830f98c518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d32ff55266a4e3d93f33c6ec9961ea2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55a5362f8d144a14aaad4d6692755fb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af6070c0d9bc40dcb8546360cc22231c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"682aea7658f24dc69067d4de961cfc7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac2230fbda0f453ea527c08b86cc2bae","IPY_MODEL_d8cda96a50c94ec8ba3774d31489e7d1","IPY_MODEL_911dbd53be164db794854ea25fb452ff"],"layout":"IPY_MODEL_584721cb54ca470587ee032eb5ba8285"}},"ac2230fbda0f453ea527c08b86cc2bae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95326724267b40ba9add71f9c6afb760","placeholder":"​","style":"IPY_MODEL_c25f390997d64ab88bb0d67ad0711973","value":"config.json: 100%"}},"d8cda96a50c94ec8ba3774d31489e7d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8693c69003e7449289f2b17c2dce3064","max":687,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fc256b861c04dcc8df2253e6c070c5b","value":687}},"911dbd53be164db794854ea25fb452ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b7ebc4116f54c4488cd12876c2d66de","placeholder":"​","style":"IPY_MODEL_a7536997d0c84c9aa3265ba6d1c96ef2","value":" 687/687 [00:00&lt;00:00, 58.1kB/s]"}},"584721cb54ca470587ee032eb5ba8285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95326724267b40ba9add71f9c6afb760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c25f390997d64ab88bb0d67ad0711973":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8693c69003e7449289f2b17c2dce3064":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fc256b861c04dcc8df2253e6c070c5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b7ebc4116f54c4488cd12876c2d66de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7536997d0c84c9aa3265ba6d1c96ef2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bacf922848af4214a64a45c2f16f1a69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_196dac5c6cd04bb3b63a001c98f44c6b","IPY_MODEL_3821ff647e624ee3b0381458b589339c","IPY_MODEL_20e08ec731ff4129b5726c4892ba8abc"],"layout":"IPY_MODEL_ea8116ee2d2543cdb1dc62a6df6b50c6"}},"196dac5c6cd04bb3b63a001c98f44c6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be7eaa152bbe4f0d97e140f6327ba0c4","placeholder":"​","style":"IPY_MODEL_01f70fdc29e845299b0f0639e314ec34","value":"pytorch_model.bin: 100%"}},"3821ff647e624ee3b0381458b589339c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ab1a20770ad4d9fa096779a3086a2c0","max":2271145830,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cb18950529444bb9d522612a1bb7fe3","value":2271145830}},"20e08ec731ff4129b5726c4892ba8abc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf1e9f36a0a2404fb60a5501ee925baf","placeholder":"​","style":"IPY_MODEL_3022f1b3818d47618b9e5562eaf77fe0","value":" 2.27G/2.27G [00:19&lt;00:00, 187MB/s]"}},"ea8116ee2d2543cdb1dc62a6df6b50c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be7eaa152bbe4f0d97e140f6327ba0c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01f70fdc29e845299b0f0639e314ec34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ab1a20770ad4d9fa096779a3086a2c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cb18950529444bb9d522612a1bb7fe3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf1e9f36a0a2404fb60a5501ee925baf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3022f1b3818d47618b9e5562eaf77fe0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99f701cc642945dc92be7a6218f78b0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06c3c4fda16546b3bd53ed1d68b86f01","IPY_MODEL_9f7d2fbe32ef4633a44220473ecc86bf","IPY_MODEL_0730afe82a934e958996ff26ea75e456"],"layout":"IPY_MODEL_a1e13bd0c0de4b088c7a51d81b9e2f1e"}},"06c3c4fda16546b3bd53ed1d68b86f01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebcb34cbb8d441d2a424668a2eea992d","placeholder":"​","style":"IPY_MODEL_25d1dcb6c2804059a3254607366f3974","value":"model.safetensors: 100%"}},"9f7d2fbe32ef4633a44220473ecc86bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35b405e0b3c54e2aa047efe40106c60d","max":2271064456,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ad2f43cc1fc426fbaf4e01456e67a42","value":2271064456}},"0730afe82a934e958996ff26ea75e456":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_beb532ce3dec451f926cb617df3d63d3","placeholder":"​","style":"IPY_MODEL_3350c00e5b274b5e9a15e70bacb41a39","value":" 2.27G/2.27G [00:21&lt;00:00, 156MB/s]"}},"a1e13bd0c0de4b088c7a51d81b9e2f1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebcb34cbb8d441d2a424668a2eea992d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d1dcb6c2804059a3254607366f3974":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35b405e0b3c54e2aa047efe40106c60d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ad2f43cc1fc426fbaf4e01456e67a42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"beb532ce3dec451f926cb617df3d63d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3350c00e5b274b5e9a15e70bacb41a39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57a97049ed3b4f4d8cd80f5f3ce33625":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_079fcfa333104468b974d2636c7794b0","IPY_MODEL_236d698924564772984776cea6db5f70","IPY_MODEL_ccc39d22d8654482ae74c51c0e6155d1"],"layout":"IPY_MODEL_09639dc6736748e8ad0bb7b9c05eee34"}},"079fcfa333104468b974d2636c7794b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a2f0f5599664bb48d8511bf6ae1bad6","placeholder":"​","style":"IPY_MODEL_e47727ea25fa44fcab234a29332d5212","value":"tokenizer_config.json: 100%"}},"236d698924564772984776cea6db5f70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e93675ff17e54f86842c3a47b104c054","max":444,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ddb6cfa3c74848be8fb7f1b4a176e820","value":444}},"ccc39d22d8654482ae74c51c0e6155d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70d21346a31f4d198178e08e3eddc4ad","placeholder":"​","style":"IPY_MODEL_4bad9f9c0cb84047886618d81512a5b3","value":" 444/444 [00:00&lt;00:00, 16.4kB/s]"}},"09639dc6736748e8ad0bb7b9c05eee34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a2f0f5599664bb48d8511bf6ae1bad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e47727ea25fa44fcab234a29332d5212":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e93675ff17e54f86842c3a47b104c054":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddb6cfa3c74848be8fb7f1b4a176e820":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70d21346a31f4d198178e08e3eddc4ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bad9f9c0cb84047886618d81512a5b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46e2338f2edc4fb5b0ef0ae0023332c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53dfae37e831462fa96a0a21902580dd","IPY_MODEL_f09b8832ec0e426e8faa9d88038cf30b","IPY_MODEL_f38743f75a1145e19ccd44024bfbc3c4"],"layout":"IPY_MODEL_b7231c6485094e0084a3825b7acb3380"}},"53dfae37e831462fa96a0a21902580dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2a9f693eb034d719a6e233673abe3ac","placeholder":"​","style":"IPY_MODEL_3a08bcfcea5c420c9db964aad265915d","value":"sentencepiece.bpe.model: 100%"}},"f09b8832ec0e426e8faa9d88038cf30b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8c49f454c6f4bdbbb84350873a2d520","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3503fafed90641f7a3abcca7711f8d03","value":5069051}},"f38743f75a1145e19ccd44024bfbc3c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58c3a91580fa46e2902a8cded6e5e0c8","placeholder":"​","style":"IPY_MODEL_09b13975cc40493a818a9c0f30c23b45","value":" 5.07M/5.07M [00:00&lt;00:00, 80.3MB/s]"}},"b7231c6485094e0084a3825b7acb3380":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2a9f693eb034d719a6e233673abe3ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a08bcfcea5c420c9db964aad265915d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8c49f454c6f4bdbbb84350873a2d520":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3503fafed90641f7a3abcca7711f8d03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58c3a91580fa46e2902a8cded6e5e0c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b13975cc40493a818a9c0f30c23b45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc1638308cff4af5a67df68b157d06e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92e75ea54c8248488f6b5743bd2a8686","IPY_MODEL_922fa5285a9548c8b552ee2eb3ed4b69","IPY_MODEL_24e5c86c2e40417dabc7306373b0a53e"],"layout":"IPY_MODEL_c3de7c693d804b8197946488381b2f78"}},"92e75ea54c8248488f6b5743bd2a8686":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd223aa252684546a8165a21540b3117","placeholder":"​","style":"IPY_MODEL_2addf02dac7b483fbd9d3693866c12d4","value":"tokenizer.json: 100%"}},"922fa5285a9548c8b552ee2eb3ed4b69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_195796649ddb493d90d5a9c008fcdabd","max":17098108,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed6c640129504941bc713974eb8e10dd","value":17098108}},"24e5c86c2e40417dabc7306373b0a53e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02101deb982842d6a84ac0e8f76d71cc","placeholder":"​","style":"IPY_MODEL_ffd3d8a79ba34d879871ef0ebd92ab69","value":" 17.1M/17.1M [00:00&lt;00:00, 85.1MB/s]"}},"c3de7c693d804b8197946488381b2f78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd223aa252684546a8165a21540b3117":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2addf02dac7b483fbd9d3693866c12d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"195796649ddb493d90d5a9c008fcdabd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed6c640129504941bc713974eb8e10dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02101deb982842d6a84ac0e8f76d71cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffd3d8a79ba34d879871ef0ebd92ab69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a232eb8786b84588922d2f50eaf7dc8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3df8ae4189b346a3960d289a14c92625","IPY_MODEL_3062e4036cc0458284f2807a4ec4d308","IPY_MODEL_46cbf87b50284858948cbff18a56c6fa"],"layout":"IPY_MODEL_da710d0c043f412ea84c6c0c737198ad"}},"3df8ae4189b346a3960d289a14c92625":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9154af3d3ccd49bdafd3451f38c7b68e","placeholder":"​","style":"IPY_MODEL_2731be6c9d5d4fc8b8ce20cad842fb25","value":"special_tokens_map.json: 100%"}},"3062e4036cc0458284f2807a4ec4d308":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad3a437ac0914ccaab22cbb387400e67","max":964,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad06b23dfb2e47cab9c8085c8d233ae3","value":964}},"46cbf87b50284858948cbff18a56c6fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef2d371de1944008bbdde1853d7bb4d2","placeholder":"​","style":"IPY_MODEL_492b24417394472191f936e57e711f6f","value":" 964/964 [00:00&lt;00:00, 26.0kB/s]"}},"da710d0c043f412ea84c6c0c737198ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9154af3d3ccd49bdafd3451f38c7b68e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2731be6c9d5d4fc8b8ce20cad842fb25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad3a437ac0914ccaab22cbb387400e67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad06b23dfb2e47cab9c8085c8d233ae3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef2d371de1944008bbdde1853d7bb4d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"492b24417394472191f936e57e711f6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"697b291a7b93457c98810c30329640aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33b0f6edf5d34c8ea412dc01b4618637","IPY_MODEL_de9b24c40c444f198bddefbb42471142","IPY_MODEL_3765cd38ae49473ba923c73a551344af"],"layout":"IPY_MODEL_0b324b226e424289a347a40ea4a2623d"}},"33b0f6edf5d34c8ea412dc01b4618637":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0122e33fbb5749f9a19a00c2916847c1","placeholder":"​","style":"IPY_MODEL_a886a7cfa76e44e7a984c5644bafca34","value":"config.json: 100%"}},"de9b24c40c444f198bddefbb42471142":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8760fa60cfa645a4986b79f84165df61","max":191,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31533a6c192d4fb0ab910b5e1aa7cc4d","value":191}},"3765cd38ae49473ba923c73a551344af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b65ba6ef8dc94155894055cab4a581c7","placeholder":"​","style":"IPY_MODEL_1d2c86f07f264bc385e6e6a86f401a4c","value":" 191/191 [00:00&lt;00:00, 5.52kB/s]"}},"0b324b226e424289a347a40ea4a2623d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0122e33fbb5749f9a19a00c2916847c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a886a7cfa76e44e7a984c5644bafca34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8760fa60cfa645a4986b79f84165df61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31533a6c192d4fb0ab910b5e1aa7cc4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b65ba6ef8dc94155894055cab4a581c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d2c86f07f264bc385e6e6a86f401a4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8e4b0b268c6462c95024eab93844efa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49bbce6130854d3ea82bb158562ea588","IPY_MODEL_3e753c39ddc147baafe1bcb381f66f27","IPY_MODEL_f132677b8ae04b56b809db9edf19ec54"],"layout":"IPY_MODEL_5964ae21869b4b87831826aaee2bd739"}},"49bbce6130854d3ea82bb158562ea588":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60c95f81ef8243eba4b12ace0260d6f9","placeholder":"​","style":"IPY_MODEL_19c0ad5f1e6a4d2eaabcd83e3e888043","value":"modules.json: 100%"}},"3e753c39ddc147baafe1bcb381f66f27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97dd08acbde84953b4fcf0025484fa03","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb054039739a4abeac863f8518908aa0","value":349}},"f132677b8ae04b56b809db9edf19ec54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bfea9c67a444b71aa657cecdd63cd3b","placeholder":"​","style":"IPY_MODEL_0173dad867174005bafc569383ec68cc","value":" 349/349 [00:00&lt;00:00, 16.6kB/s]"}},"5964ae21869b4b87831826aaee2bd739":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60c95f81ef8243eba4b12ace0260d6f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19c0ad5f1e6a4d2eaabcd83e3e888043":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97dd08acbde84953b4fcf0025484fa03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb054039739a4abeac863f8518908aa0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bfea9c67a444b71aa657cecdd63cd3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0173dad867174005bafc569383ec68cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de607847cc3a4b7aacd49129a4a532ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbb7a93252f247cfa75beb450339dd1a","IPY_MODEL_4938771c20b042c39b83e5566d48b077","IPY_MODEL_83ee5df64bf043b4a9ac6b277312522b"],"layout":"IPY_MODEL_536e38d5bcb64346a9b35518e942ca7f"}},"fbb7a93252f247cfa75beb450339dd1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec78480c66664736a7504f4ecb32de74","placeholder":"​","style":"IPY_MODEL_9c0b87ccafae4dedb8e4b03a71c34bf3","value":"config_sentence_transformers.json: 100%"}},"4938771c20b042c39b83e5566d48b077":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1b14b304353498dade828a808c45df4","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce8c0c7412234cff9a35102baf8d090c","value":116}},"83ee5df64bf043b4a9ac6b277312522b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db498a271dac49ffa676cbb3fc68a548","placeholder":"​","style":"IPY_MODEL_e8e2bae919f64039be2e00ebd8871ddf","value":" 116/116 [00:00&lt;00:00, 6.91kB/s]"}},"536e38d5bcb64346a9b35518e942ca7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec78480c66664736a7504f4ecb32de74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c0b87ccafae4dedb8e4b03a71c34bf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1b14b304353498dade828a808c45df4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce8c0c7412234cff9a35102baf8d090c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db498a271dac49ffa676cbb3fc68a548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8e2bae919f64039be2e00ebd8871ddf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fa713deaed34c13acaa89f558fd199c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a58ea755e95c4a1fa61000c0ba8679fa","IPY_MODEL_c5971b43cfbc47a1822f4226d8e95916","IPY_MODEL_09d4456beacd44f081fe7da9401a23d8"],"layout":"IPY_MODEL_69dc2b866fb94ec2a3e2b1e5fe978fd4"}},"a58ea755e95c4a1fa61000c0ba8679fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d5a435fc974e54aa6ff6772ac5982a","placeholder":"​","style":"IPY_MODEL_3944351120e249ce84b8dc64b007f18e","value":"README.md: 100%"}},"c5971b43cfbc47a1822f4226d8e95916":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6500a9a7661448049508a1345c6584f8","max":10454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14332a2c2bf84f56b6a1e311134e3657","value":10454}},"09d4456beacd44f081fe7da9401a23d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39d49c573d3944229d5a8390132ee36b","placeholder":"​","style":"IPY_MODEL_29c54104927649f3b873670fd9317f79","value":" 10.5k/10.5k [00:00&lt;00:00, 490kB/s]"}},"69dc2b866fb94ec2a3e2b1e5fe978fd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d5a435fc974e54aa6ff6772ac5982a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3944351120e249ce84b8dc64b007f18e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6500a9a7661448049508a1345c6584f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14332a2c2bf84f56b6a1e311134e3657":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39d49c573d3944229d5a8390132ee36b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c54104927649f3b873670fd9317f79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e9392e958f54763bc2f880c3d82ca7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93506fead32744f4afd3ffdfed454ffb","IPY_MODEL_7b873f1b92924963aad1c32a31f1af96","IPY_MODEL_30c25c383135433e8e94d84caf469419"],"layout":"IPY_MODEL_00467c718ffd4ecabb0e182faf385190"}},"93506fead32744f4afd3ffdfed454ffb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94588c33dbfa4076b9f56362883fc614","placeholder":"​","style":"IPY_MODEL_22b0262c358f487e9e0f3724b46a0bf5","value":"sentence_bert_config.json: 100%"}},"7b873f1b92924963aad1c32a31f1af96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc37c0165e6e434cabe637720241c73b","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c5b6229fe524233b48ceb001fce682f","value":53}},"30c25c383135433e8e94d84caf469419":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_749306b4180a48d9b68dcca70ff9cdda","placeholder":"​","style":"IPY_MODEL_a109d619acfd48739b610164317c5fe4","value":" 53.0/53.0 [00:00&lt;00:00, 1.82kB/s]"}},"00467c718ffd4ecabb0e182faf385190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94588c33dbfa4076b9f56362883fc614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22b0262c358f487e9e0f3724b46a0bf5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc37c0165e6e434cabe637720241c73b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c5b6229fe524233b48ceb001fce682f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"749306b4180a48d9b68dcca70ff9cdda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a109d619acfd48739b610164317c5fe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ef214cdfdfd4948b05d1b3d00750b88":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bf35574dff24294b1e097d05d4ffe83","IPY_MODEL_f3ebe700028d44738afd42e60579946f","IPY_MODEL_e131e607c3a7441da7bb027ea782e1ef"],"layout":"IPY_MODEL_5b640e74783347e1b71ee555ee6b4273"}},"3bf35574dff24294b1e097d05d4ffe83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d10cdd4f1e6f4fe9a3df73e84b52d4e3","placeholder":"​","style":"IPY_MODEL_d45f086a682d4e69b45b6ccafb363005","value":"config.json: 100%"}},"f3ebe700028d44738afd42e60579946f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8242e3bae84446dacbcfea979c5b546","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84fca0f42197466eaa91963b9b05f9af","value":612}},"e131e607c3a7441da7bb027ea782e1ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a69e5fd040f54cd5b07be74cb377c5eb","placeholder":"​","style":"IPY_MODEL_8a0da1e5fb2143dca16b11a087c27524","value":" 612/612 [00:00&lt;00:00, 33.4kB/s]"}},"5b640e74783347e1b71ee555ee6b4273":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d10cdd4f1e6f4fe9a3df73e84b52d4e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d45f086a682d4e69b45b6ccafb363005":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8242e3bae84446dacbcfea979c5b546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84fca0f42197466eaa91963b9b05f9af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a69e5fd040f54cd5b07be74cb377c5eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a0da1e5fb2143dca16b11a087c27524":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76690654f15a44e3bda95df1c1f5dde9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e914951b8a4c4db796b7e22b6db9bcca","IPY_MODEL_a80100061cdf4dcb9abad3b6afa45b6c","IPY_MODEL_f02180284cf441ab9c7d8ef0119f4598"],"layout":"IPY_MODEL_574544b666ea4cffb67f5440b43cc9fa"}},"e914951b8a4c4db796b7e22b6db9bcca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4678528eb7934cd782cfee05556ab817","placeholder":"​","style":"IPY_MODEL_689766776a6647fb8dbc5a324c0777da","value":"model.safetensors: 100%"}},"a80100061cdf4dcb9abad3b6afa45b6c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdbd8c0c565a4f27b4eaf477dc3c4c0f","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2944679d747f45c7bf7c48dc9a83fc2a","value":90868376}},"f02180284cf441ab9c7d8ef0119f4598":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf974ea5b15a4699a4fd9a56f6434e66","placeholder":"​","style":"IPY_MODEL_edb3d62b0bb34738bcbd39afb91dad4a","value":" 90.9M/90.9M [00:01&lt;00:00, 114MB/s]"}},"574544b666ea4cffb67f5440b43cc9fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4678528eb7934cd782cfee05556ab817":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"689766776a6647fb8dbc5a324c0777da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdbd8c0c565a4f27b4eaf477dc3c4c0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2944679d747f45c7bf7c48dc9a83fc2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf974ea5b15a4699a4fd9a56f6434e66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edb3d62b0bb34738bcbd39afb91dad4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4f8bfd68fbb4bbea1bed959938c957c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bf7a92dfbdd4cdf811f4422e3afbfc9","IPY_MODEL_8e2debd91e4e44a2b83859aa9f699c42","IPY_MODEL_76ae63113e544f96869e81891fb04153"],"layout":"IPY_MODEL_982dee3b79ed4f96862d8855d110cdf0"}},"2bf7a92dfbdd4cdf811f4422e3afbfc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d57f197a66c2476c8958851790525412","placeholder":"​","style":"IPY_MODEL_36a7e0b876684505b20a253a08e56f13","value":"tokenizer_config.json: 100%"}},"8e2debd91e4e44a2b83859aa9f699c42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab2e830286a14cd2a7b268979e9c1761","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3091079acc3a4fb8bd69ef4a936109ae","value":350}},"76ae63113e544f96869e81891fb04153":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a00d541272894ef0a5daab97abe78110","placeholder":"​","style":"IPY_MODEL_1a92d8edde99407f837af82605af67e8","value":" 350/350 [00:00&lt;00:00, 31.2kB/s]"}},"982dee3b79ed4f96862d8855d110cdf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d57f197a66c2476c8958851790525412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36a7e0b876684505b20a253a08e56f13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab2e830286a14cd2a7b268979e9c1761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3091079acc3a4fb8bd69ef4a936109ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a00d541272894ef0a5daab97abe78110":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a92d8edde99407f837af82605af67e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3919ee8426943198b2ebb8027a56204":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1497fbdd9b4d4d30b08b3e75323cb08d","IPY_MODEL_56ffa058eb0246d8bee875648ba479d9","IPY_MODEL_9bf1a11d04334f8d986a94c73bdf3e76"],"layout":"IPY_MODEL_24f27c4cab7a476eb13745fa49f3f907"}},"1497fbdd9b4d4d30b08b3e75323cb08d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6ce522161f7493190b12a17f8d0bb2b","placeholder":"​","style":"IPY_MODEL_a7a41f1add5f47f39bc396a6762c484d","value":"vocab.txt: 100%"}},"56ffa058eb0246d8bee875648ba479d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_708c3420f7f94183938d380910920325","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_141b57505f894d218870f00a7a08532a","value":231508}},"9bf1a11d04334f8d986a94c73bdf3e76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe5b3c8dd6e54d3fa470158d2587b248","placeholder":"​","style":"IPY_MODEL_b2d9cd973db748489153aeaddb0f0a16","value":" 232k/232k [00:00&lt;00:00, 8.22MB/s]"}},"24f27c4cab7a476eb13745fa49f3f907":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ce522161f7493190b12a17f8d0bb2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7a41f1add5f47f39bc396a6762c484d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"708c3420f7f94183938d380910920325":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"141b57505f894d218870f00a7a08532a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe5b3c8dd6e54d3fa470158d2587b248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2d9cd973db748489153aeaddb0f0a16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bba247ce27340eb974b0644b54b9541":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_323a5ff41ee84c6c94b18617a286a5e7","IPY_MODEL_f927c05df487440086e405ed3e06e8ef","IPY_MODEL_1c866d8d48ab411bab2a8af3804b4f20"],"layout":"IPY_MODEL_11ab8ad795b34b10bdb28bec7bdf006c"}},"323a5ff41ee84c6c94b18617a286a5e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac5fb21b49cc4d77973d5eed53d07dfa","placeholder":"​","style":"IPY_MODEL_5f156cd8ec5443f3be2b216a31d5e434","value":"tokenizer.json: 100%"}},"f927c05df487440086e405ed3e06e8ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9a0336c86b5480ea49085d354591a3b","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ddd70bffd1d740f4b4fa50faab5b14ef","value":466247}},"1c866d8d48ab411bab2a8af3804b4f20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b86687df81cd4344922af7f1508e52a7","placeholder":"​","style":"IPY_MODEL_81859edea6d34af08dc92ce87d0e920c","value":" 466k/466k [00:00&lt;00:00, 6.14MB/s]"}},"11ab8ad795b34b10bdb28bec7bdf006c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac5fb21b49cc4d77973d5eed53d07dfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f156cd8ec5443f3be2b216a31d5e434":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9a0336c86b5480ea49085d354591a3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddd70bffd1d740f4b4fa50faab5b14ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b86687df81cd4344922af7f1508e52a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81859edea6d34af08dc92ce87d0e920c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13a1d1d09e6d407983ca2105b8b033ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f73ac20ebced4c14bf60c360a0a78f8c","IPY_MODEL_f3cc392af7ee46eb8b327c9b94241488","IPY_MODEL_e8c639eb5764481ea6aed86000907b87"],"layout":"IPY_MODEL_cb13a609f7c74f30896fe7c68f85671a"}},"f73ac20ebced4c14bf60c360a0a78f8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3184856d838146ca8b86fd0b6064be64","placeholder":"​","style":"IPY_MODEL_f37ed3a74ff44947b53a9bc3dd26e906","value":"special_tokens_map.json: 100%"}},"f3cc392af7ee46eb8b327c9b94241488":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_248571dc2e274686bc91969b8ed1ecb1","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07c20504fb9c455cb2e7d84147a91229","value":112}},"e8c639eb5764481ea6aed86000907b87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f18d991480542daaf56e3cd3df00aa6","placeholder":"​","style":"IPY_MODEL_a29a330ab1d94b6aa4e7f5dae70b7dea","value":" 112/112 [00:00&lt;00:00, 8.30kB/s]"}},"cb13a609f7c74f30896fe7c68f85671a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3184856d838146ca8b86fd0b6064be64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37ed3a74ff44947b53a9bc3dd26e906":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"248571dc2e274686bc91969b8ed1ecb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07c20504fb9c455cb2e7d84147a91229":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f18d991480542daaf56e3cd3df00aa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a29a330ab1d94b6aa4e7f5dae70b7dea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c633a8f5086401598f7a3b3fcd0f9b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01046a9aea914ecbbc70faec5b26ce8f","IPY_MODEL_c0609d899c884d549789af893e782304","IPY_MODEL_1da74bb74ac646cdbba5cbced3e91466"],"layout":"IPY_MODEL_5f62395af92b48988b587d416f9f50cc"}},"01046a9aea914ecbbc70faec5b26ce8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_766a04e932d14a6683e9734bae571744","placeholder":"​","style":"IPY_MODEL_bec64fa3dd474de195d6d4dc8da52c04","value":"config.json: 100%"}},"c0609d899c884d549789af893e782304":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9842cc780224862a4ab56ceb88880f3","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40dedde4649f4cce8b9b4a263aace889","value":190}},"1da74bb74ac646cdbba5cbced3e91466":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfbac477137e48e098011df1e9207e5e","placeholder":"​","style":"IPY_MODEL_bc87044dab6c463392b1f736268e07d0","value":" 190/190 [00:00&lt;00:00, 12.3kB/s]"}},"5f62395af92b48988b587d416f9f50cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"766a04e932d14a6683e9734bae571744":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec64fa3dd474de195d6d4dc8da52c04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9842cc780224862a4ab56ceb88880f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40dedde4649f4cce8b9b4a263aace889":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dfbac477137e48e098011df1e9207e5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc87044dab6c463392b1f736268e07d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}